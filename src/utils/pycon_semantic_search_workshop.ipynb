{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60hEtLSrGXo0",
        "outputId": "8c122ce3-643a-4e8c-fb18-7b8dcaab9bcc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\"sudo\" no se reconoce como un comando interno o externo,\n",
            "programa o archivo por lotes ejecutable.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "     ---------------------------------------- 86.0/86.0 kB 1.6 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers)\n",
            "  Obtaining dependency information for transformers<5.0.0,>=4.6.0 from https://files.pythonhosted.org/packages/c1/bd/f64d67df4d3b05a460f281defe830ffab6d7940b7ca98ec085e94e024781/transformers-4.34.1-py3-none-any.whl.metadata\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl.metadata (121 kB)\n",
            "     -------------------------------------- 121.5/121.5 kB 7.0 MB/s eta 0:00:00\n",
            "Collecting tqdm (from sentence-transformers)\n",
            "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
            "     ---------------------------------------- 57.6/57.6 kB 3.2 MB/s eta 0:00:00\n",
            "Collecting torch>=1.6.0 (from sentence-transformers)\n",
            "  Obtaining dependency information for torch>=1.6.0 from https://files.pythonhosted.org/packages/67/0a/b6dddafbb64d3ca13078a2616a2ea02c595da832586898a7eb414cf7ad10/torch-2.1.0-cp39-cp39-win_amd64.whl.metadata\n",
            "  Downloading torch-2.1.0-cp39-cp39-win_amd64.whl.metadata (24 kB)\n",
            "Collecting torchvision (from sentence-transformers)\n",
            "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/ec/36/1ecc19249def521b3b948baee32903148b1f399d2dd5a9a5692942e8383c/torchvision-0.16.0-cp39-cp39-win_amd64.whl.metadata\n",
            "  Downloading torchvision-0.16.0-cp39-cp39-win_amd64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence-transformers) (1.22.4)\n",
            "Collecting scikit-learn (from sentence-transformers)\n",
            "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/1c/49/30ffcac5af06d08dfdd27da322ce31a373b733711bb272941877c1e4794a/scikit_learn-1.3.2-cp39-cp39-win_amd64.whl.metadata\n",
            "  Downloading scikit_learn-1.3.2-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: scipy in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence-transformers) (1.8.1)\n",
            "Collecting nltk (from sentence-transformers)\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "     ---------------------------------------- 1.5/1.5 MB 16.1 MB/s eta 0:00:00\n",
            "Collecting sentencepiece (from sentence-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp39-cp39-win_amd64.whl (977 kB)\n",
            "     -------------------------------------- 977.6/977.6 kB 7.7 MB/s eta 0:00:00\n",
            "Collecting huggingface-hub>=0.4.0 (from sentence-transformers)\n",
            "  Obtaining dependency information for huggingface-hub>=0.4.0 from https://files.pythonhosted.org/packages/ef/b5/b6107bd65fa4c96fdf00e4733e2fe5729bb9e5e09997f63074bb43d3ab28/huggingface_hub-0.18.0-py3-none-any.whl.metadata\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting filelock (from huggingface-hub>=0.4.0->sentence-transformers)\n",
            "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/5e/5d/97afbafd9d584ff1b45fcb354a479a3609bd97f912f8f1f6c563cb1fae21/filelock-3.12.4-py3-none-any.whl.metadata\n",
            "  Downloading filelock-3.12.4-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.4.0->sentence-transformers)\n",
            "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/e8/f6/3eccfb530aac90ad1301c582da228e4763f19e719ac8200752a4841b0b2d/fsspec-2023.10.0-py3-none-any.whl.metadata\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: requests in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\n",
            "Collecting pyyaml>=5.1 (from huggingface-hub>=0.4.0->sentence-transformers)\n",
            "  Obtaining dependency information for pyyaml>=5.1 from https://files.pythonhosted.org/packages/84/4d/82704d1ab9290b03da94e6425f5e87396b999fd7eb8e08f3a92c158402bf/PyYAML-6.0.1-cp39-cp39-win_amd64.whl.metadata\n",
            "  Downloading PyYAML-6.0.1-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: sympy in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (1.10.1)\n",
            "Collecting networkx (from torch>=1.6.0->sentence-transformers)\n",
            "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/f6/eb/5585c96636bbb2755865c31d83a19dd220ef88e716df4659dacb86e009cc/networkx-3.2-py3-none-any.whl.metadata\n",
            "  Downloading networkx-3.2-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.4)\n",
            "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
            "  Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/fc/85/0d1038f068900896a8590d6d0da198b90d31f731a39166a432aa2b92249b/regex-2023.10.3-cp39-cp39-win_amd64.whl.metadata\n",
            "  Downloading regex-2023.10.3-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
            "     ---------------------------------------- 42.0/42.0 kB ? eta 0:00:00\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
            "  Obtaining dependency information for tokenizers<0.15,>=0.14 from https://files.pythonhosted.org/packages/36/de/de1b1d7b191821cc2e6e84251cf9641e4fbd205fa5ec816d52fe42f97325/tokenizers-0.14.1-cp39-none-win_amd64.whl.metadata\n",
            "  Downloading tokenizers-0.14.1-cp39-none-win_amd64.whl.metadata (6.8 kB)\n",
            "Collecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
            "  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/a7/49/d43e967d427e78086980ec85af1afe0320becfc33b26903d3d0ce10b0ee5/safetensors-0.4.0-cp39-none-win_amd64.whl.metadata\n",
            "  Downloading safetensors-0.4.0-cp39-none-win_amd64.whl.metadata (3.8 kB)\n",
            "Collecting click (from nltk->sentence-transformers)\n",
            "  Obtaining dependency information for click from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting joblib (from nltk->sentence-transformers)\n",
            "  Obtaining dependency information for joblib from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
            "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence-transformers)\n",
            "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
            "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision->sentence-transformers) (9.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
            "Collecting huggingface-hub>=0.4.0 (from sentence-transformers)\n",
            "  Obtaining dependency information for huggingface-hub>=0.4.0 from https://files.pythonhosted.org/packages/aa/f3/3fc97336a0e90516901befd4f500f08d691034d387406fdbde85bea827cc/huggingface_hub-0.17.3-py3-none-any.whl.metadata\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.6.15)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.2.1)\n",
            "Downloading torch-2.1.0-cp39-cp39-win_amd64.whl (192.2 MB)\n",
            "   ---------------------------------------- 192.2/192.2 MB 4.3 MB/s eta 0:00:00\n",
            "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "   ---------------------------------------- 78.3/78.3 kB 4.3 MB/s eta 0:00:00\n",
            "Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "   ---------------------------------------- 7.7/7.7 MB 8.3 MB/s eta 0:00:00\n",
            "Downloading scikit_learn-1.3.2-cp39-cp39-win_amd64.whl (9.3 MB)\n",
            "   ---------------------------------------- 9.3/9.3 MB 8.8 MB/s eta 0:00:00\n",
            "Downloading torchvision-0.16.0-cp39-cp39-win_amd64.whl (1.3 MB)\n",
            "   ---------------------------------------- 1.3/1.3 MB 10.0 MB/s eta 0:00:00\n",
            "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "   ---------------------------------------- 166.4/166.4 kB 9.8 MB/s eta 0:00:00\n",
            "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
            "   ---------------------------------------- 302.2/302.2 kB 9.1 MB/s eta 0:00:00\n",
            "Downloading PyYAML-6.0.1-cp39-cp39-win_amd64.whl (152 kB)\n",
            "   ---------------------------------------- 152.8/152.8 kB 9.5 MB/s eta 0:00:00\n",
            "Downloading regex-2023.10.3-cp39-cp39-win_amd64.whl (269 kB)\n",
            "   ---------------------------------------- 269.6/269.6 kB 8.4 MB/s eta 0:00:00\n",
            "Downloading safetensors-0.4.0-cp39-none-win_amd64.whl (277 kB)\n",
            "   ---------------------------------------- 277.2/277.2 kB 8.6 MB/s eta 0:00:00\n",
            "Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
            "Downloading tokenizers-0.14.1-cp39-none-win_amd64.whl (2.2 MB)\n",
            "   ---------------------------------------- 2.2/2.2 MB 10.0 MB/s eta 0:00:00\n",
            "Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "   ---------------------------------------- 295.0/295.0 kB 9.2 MB/s eta 0:00:00\n",
            "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "   ---------------------------------------- 97.9/97.9 kB 5.5 MB/s eta 0:00:00\n",
            "Downloading filelock-3.12.4-py3-none-any.whl (11 kB)\n",
            "Downloading networkx-3.2-py3-none-any.whl (1.6 MB)\n",
            "   ---------------------------------------- 1.6/1.6 MB 9.5 MB/s eta 0:00:00\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (pyproject.toml): started\n",
            "  Building wheel for sentence-transformers (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125953 sha256=f971b6f6dbd1b16a883cbaa0c13f9fb09353905d01ba86a1e9b555197f13f2b3\n",
            "  Stored in directory: c:\\users\\stipg\\appdata\\local\\pip\\cache\\wheels\\71\\67\\06\\162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, tqdm, threadpoolctl, safetensors, regex, pyyaml, networkx, joblib, fsspec, filelock, click, torch, scikit-learn, nltk, huggingface-hub, torchvision, tokenizers, transformers, sentence-transformers\n",
            "Successfully installed click-8.1.7 filelock-3.12.4 fsspec-2023.10.0 huggingface-hub-0.17.3 joblib-1.3.2 networkx-3.2 nltk-3.8.1 pyyaml-6.0.1 regex-2023.10.3 safetensors-0.4.0 scikit-learn-1.3.2 sentence-transformers-2.2.2 sentencepiece-0.1.99 threadpoolctl-3.2.0 tokenizers-0.14.1 torch-2.1.0 torchvision-0.16.0 tqdm-4.66.1 transformers-4.34.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.66.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm) (0.4.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Collecting gdown"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gdown) (3.12.4)\n",
            "Requirement already satisfied: requests[socks] in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gdown) (2.28.1)\n",
            "Requirement already satisfied: six in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gdown) (4.11.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests[socks]->gdown) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests[socks]->gdown) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests[socks]->gdown) (1.26.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests[socks]->gdown) (2022.6.15)\n",
            "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown)\n",
            "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm->gdown) (0.4.4)\n",
            "Installing collected packages: PySocks, gdown\n",
            "Successfully installed PySocks-1.7.1 gdown-4.7.1\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "     ---------------------------------------- 57.6/57.6 kB 1.5 MB/s eta 0:00:00\n",
            "Installing collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pinecone-client\n",
            "  Obtaining dependency information for pinecone-client from https://files.pythonhosted.org/packages/df/d4/cffbb61236c6c1d7510e835c1ff843e4e7d705ed59d21c0e5b6dc1cb4fd8/pinecone_client-2.2.4-py3-none-any.whl.metadata\n",
            "  Downloading pinecone_client-2.2.4-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pinecone-client) (2.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.4 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pinecone-client) (6.0.1)\n",
            "Collecting loguru>=0.5.0 (from pinecone-client)\n",
            "  Obtaining dependency information for loguru>=0.5.0 from https://files.pythonhosted.org/packages/03/0a/4f6fed21aa246c6b49b561ca55facacc2a44b87d65b8b92362a8e99ba202/loguru-0.7.2-py3-none-any.whl.metadata\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pinecone-client) (4.3.0)\n",
            "Collecting dnspython>=2.0.0 (from pinecone-client)\n",
            "  Obtaining dependency information for dnspython>=2.0.0 from https://files.pythonhosted.org/packages/f6/b4/0a9bee52c50f226a3cbfb54263d02bb421c7f2adc136520729c2c689c1e5/dnspython-2.4.2-py3-none-any.whl.metadata\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pinecone-client) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pinecone-client) (1.26.11)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pinecone-client) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pinecone-client) (1.22.4)\n",
            "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (0.4.4)\n",
            "Collecting win32-setctime>=1.0.0 (from loguru>=0.5.0->pinecone-client)\n",
            "  Downloading win32_setctime-1.1.0-py3-none-any.whl (3.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\stipg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (2022.6.15)\n",
            "Downloading pinecone_client-2.2.4-py3-none-any.whl (179 kB)\n",
            "   ---------------------------------------- 179.4/179.4 kB 5.3 MB/s eta 0:00:00\n",
            "Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "   --------------------------------------- 300.4/300.4 kB 18.1 MB/s eta 0:00:00\n",
            "Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "   ---------------------------------------- 62.5/62.5 kB 3.5 MB/s eta 0:00:00\n",
            "Installing collected packages: win32-setctime, dnspython, loguru, pinecone-client\n",
            "Successfully installed dnspython-2.4.2 loguru-0.7.2 pinecone-client-2.2.4 win32-setctime-1.1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update &&  sudo apt install ffmpeg -y\n",
        "!pip install -U sentence-transformers\n",
        "!pip install tqdm\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install --upgrade --no-cache-dir gdown\n",
        "!pip install pytube\n",
        "!pip install pinecone-client\n",
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bugd3mJ0Hoa_",
        "outputId": "b3f9ec7d-42ae-4b5e-fb37-48ad74bc279c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/PyCon-co audios/all_transcribes.csv',\n",
              " '/content/PyCon-co audios/audios/Andres Giraldo Carvajal - Interactive Data Visualization in Python - PyCon Colombia 2019 [WDVgJmW9OUA].mp3',\n",
              " '/content/PyCon-co audios/audios/Andrés Torres - Programación en paralelo con Python： sácale jugo a los núcleos de tu computadora [Wv4R7H-HPTo].mp3',\n",
              " '/content/PyCon-co audios/audios/Andrew Godwin - Keynote - PyCon Colombia 2020 [862xL6jm_PQ].mp3',\n",
              " '/content/PyCon-co audios/audios/Carlos Patiño - Probabilistic Programming： Using Python to Simplify Statistical Inference (Inglés) [offng66PhcM].mp3',\n",
              " '/content/PyCon-co audios/audios/David Delgado Ruiz - Story of an junior engineer - PyCon Colombia 2019 [c8y2yS_p8wM].mp3',\n",
              " '/content/PyCon-co audios/audios/Felipe Dos Santos - AfroPython： Empowering black people using Python in Brazil - PyCon Colombia 2020 [n-IS_2LyMck].mp3',\n",
              " \"/content/PyCon-co audios/audios/Flavio Percoco - Inheriting code, and I don't mean classes - PyCon Colombia 2020 [3zDNMiHmVmI].mp3\",\n",
              " '/content/PyCon-co audios/audios/Gonzalo Quiroga - IGNIS - PyCon Colombia 2019 [f8XF_HYdZks].mp3',\n",
              " '/content/PyCon-co audios/audios/Interview Andrew Godwin - PyCon Colombia 2020 [0ZNMZdFk_WY].mp3',\n",
              " '/content/PyCon-co audios/audios/Interview Flavio Percoco - Elastic - PyCon Colombia 2020 [wfWzKnILBVs].mp3',\n",
              " '/content/PyCon-co audios/audios/Interview Lorena Mesa  - Keynote Speaker - PyCon Colombia 2018 [OHzhNr2_Cpc].mp3',\n",
              " '/content/PyCon-co audios/audios/Interview Mauricio Giraldo - Playvox - PyCon Colombia 2020 [Gjq4PvgWVco].mp3',\n",
              " '/content/PyCon-co audios/audios/Interview Naomi Ceder - Keynote Speaker - PyCon Colombia 2018 [dBsnv87fZGw].mp3',\n",
              " '/content/PyCon-co audios/audios/Interview Natalia Múnera - Autonomic Mind - PyCon Colombia 2020 [dhU4tLvv-cg].mp3',\n",
              " '/content/PyCon-co audios/audios/Interview Rodolfo Edelmann & Carlos de la Torre - Mercado Libre - PyCon Colombia 2020 [IvKQkp2CYqs].mp3',\n",
              " '/content/PyCon-co audios/audios/Interview Russel Keith Magee - Keynote Speaker - PyCon Colombia 2019 [wSa28y7Z5Iw].mp3',\n",
              " '/content/PyCon-co audios/audios/Javier Mansilla - Python and data Science in E-Commerce： A sucess story - PyCon Colombia 2018 [waxwYZSqYbw].mp3',\n",
              " '/content/PyCon-co audios/audios/Jonathan Diaz - Sanic StorageService. Usando Sanic vas a poder soportar gran cantidad de tráfico [d1Dz5oHE6PU].mp3',\n",
              " '/content/PyCon-co audios/audios/Jorge Gonzalez - Real driving data to improve road safety in bogota - PyCon Colombia 2019 [E_rPy0h5fXI].mp3',\n",
              " '/content/PyCon-co audios/audios/Jorge Luis Galvis - Going serverless with python - PyCon Colombia 2019 [YkI-B8cArRI].mp3',\n",
              " '/content/PyCon-co audios/audios/Jorge Martínez - Detection vs Tracking： A computer vision approach - PyCon Colombia 2018 [0f1VQ2GKmXw].mp3',\n",
              " '/content/PyCon-co audios/audios/José Benitez - The road so far on building a web platform for drones - PyCon Colombia 2020 [7NlKbzz1y0M].mp3',\n",
              " '/content/PyCon-co audios/audios/Juan David Alzate - Build a serverless API in AWS in minutes： Boosting your stack with Chalice & CDK [froYK-qcSuw].mp3',\n",
              " '/content/PyCon-co audios/audios/Kevin Hernández - Behave yourself! A better way to do testing [b4yYrp9nBsI].mp3',\n",
              " '/content/PyCon-co audios/audios/Kevin Hernández - Y is X but X is not always Y： An introduction to Python internals [_SQR9Z15FH0].mp3',\n",
              " '/content/PyCon-co audios/audios/Lorena Aldana - Using Python to listen to your heart [YrCSME1jT6U].mp3',\n",
              " '/content/PyCon-co audios/audios/María José Meneses - Restauración de imágenes multiespectrales con GAN [sne-d-YsMZY].mp3',\n",
              " '/content/PyCon-co audios/audios/Navid Shelkhol - FBJE is a framework used at Facebook for developing workflows in Python [5rgZQw0F0w0].mp3',\n",
              " '/content/PyCon-co audios/audios/Nick Sweeting - Archiving the Internet Before it All Rots Away  - PyCon Colombia 2020 [LZ7TNQjG74g].mp3',\n",
              " '/content/PyCon-co audios/audios/Rafael Carrascosa - Software engineering for machine learning at Mercado Libre [OVe1GzubDP8].mp3',\n",
              " \"/content/PyCon-co audios/audios/Rocky Bernstein - Decompilation and Pandora's box - PyCon Colombia 2018 [bRQr1OroXUM].mp3\",\n",
              " '/content/PyCon-co audios/audios/Rodolfo Edelmann & Carlos de la Torre - Conectando microservicios con Python [N3czkxo2JJw].mp3',\n",
              " '/content/PyCon-co audios/audios/Sebastián Arango - Enhancing Data Privacy through Federated (Machine) Learning - Pycon Colombia 2020 [mEPw36JE_8w].mp3',\n",
              " '/content/PyCon-co audios/audios/Sergio Flórez Galeano - Deep learning： From academia to practice using micro services [_jxpZr803vI].mp3',\n",
              " '/content/PyCon-co audios/audios/Wes McKinney  - Keynote - PyCon Colombia 2020 [ZTXFQ2sEarQ].mp3',\n",
              " '/content/PyCon-co audios/pycon workshop.ipynb',\n",
              " '/content/PyCon-co audios/Vector search on embeddings.pptx']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gdown\n",
        "gdrive_folder_link='https://drive.google.com/drive/folders/1f3v_CKRVecCqpdX07PQg5mg19mWRaVJC?usp=sharing'\n",
        "gdown.download_folder(gdrive_folder_link, quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFkRPMUcH4tW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S21xNgQpIdt2"
      },
      "outputs": [],
      "source": [
        "title = []\n",
        "url = []\n",
        "path = []\n",
        "patron = r'\\[(.*?)\\]'\n",
        "for _ in os.listdir('/content/PyCon-co audios/audios'):\n",
        "    title.append(_.split('[')[0])\n",
        "    url.append(re.findall(patron,_)[0])\n",
        "    path.append('/content/PyCon-co audios/audios/'+_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0IeYxkoJSGD"
      },
      "outputs": [],
      "source": [
        "df_video = pd.DataFrame({'title':title,'url':url,'path':path})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ezQOmskJmvI"
      },
      "outputs": [],
      "source": [
        "df_video['url'] = df_video['url'].apply(lambda x : 'https://www.youtube.com/watch?v='+x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaZUXPHHKIoc"
      },
      "outputs": [],
      "source": [
        "from pytube import YouTube\n",
        "def get_metadata(url):\n",
        "    yt = YouTube(url)\n",
        "    return pd.Series([yt.views, yt.author, yt.publish_date, yt.keywords])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Sry14nALsLq"
      },
      "outputs": [],
      "source": [
        "df_video[['views','author','publish_date','keywords']] = df_video['url'].apply(lambda x :get_metadata(x) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "6rVQbmYaMGmr",
        "outputId": "09102390-8b93-4d51-af17-3fc9f678fb50"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/PyCon-co audios/audios/Rodolfo Edelmann & Carlos de la Torre - Conectando microservicios con Python [N3czkxo2JJw].mp3'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_video['path'][4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8NWVlwDM9CE",
        "outputId": "750480cb-bdd8-4228-c0ec-1ec1ee6cf599"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:01<00:00, 106MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Bueno, quién soy Rodolfo Edelman, me van a escuchar ahí que me dicen Rudy. Tiengan cuidado si me llaman Digan Rudy con Deno con B. Larga, porque con Ferencia Python se pueden ojar a alguien. Hace 5 años estoy trabajando con Python antes de trabajar con Ruby, eso no lo voy a contermas. Trabajé mucho tiempo a la Universidad Nacional de Córdoba, a esa foto en el Cláster de la Universidad Nacional de Córdoba. Hace mucho de Robots, después abancé a Bakken, de Bakken, empezó a hacer Machine Learning y actualmente estoy como técnica al Manaller en Mercado de Libre, desarrollando productos, servicios internos de la compañía que nos sirven para poner modelos de Machine Learning en producción. Hola, yo soy Litox, Carlos de la Torre, me dicen Litox en la Uroschatz y en las comunidades de Python y en la tele, pero eso todavía no se se llenó nunca. Trabajo con Ruy hace muchos años, también soy técnica al Manaller, tengo un recorrido de su licencia informática y de desarrollador, técnica leader, retabajado en empresas nacionales, en Argentina, en Pymes, pequeñas empresas, ahora en Mercado de Libre estamos como hizo Rudy armando la infraestructura para ejecutar. Machine Learning en producción y a escala. Bueno, queremos entonces contarles un poquito de qué va a ser la charla. Primero que todos para entender el motivo de la charla tenemos que entender porque creamos microsや servicios, ¿cómo hacemos esto en Python? Está normalmente, ¿cuáles son los insas que fuimos sacando, teniendo en estos años de desarrollo, un poco eso y algunos casos de uso que vamos a ver. Monalito, ¿todo saben qué es monalito? Levanta la mano. Normalmente bueno, por accidente. Normalmente una cuando empieza a construir el primer producto, empieza, no quiere hacer algo complejo, quiere empezar por algo que sea fácil de poner en producción rápido para validar una idea. De esta manera es que empezamos a hacer un monalito. En la arquitectura monalito es construcción sobre un solo material. Se hace una analogía cuando el diseño de software que tiene que ver con un estat tecnológico. El ejeimo en estat tecnológico y construimos sobre ese estat. ¿Qué quiere decir? El ejeimo Python, Django, MySQL y alguna cola de mensajes. Pero esto paría producción fantástico. Vamos rápido, pero empiezan a ocurrir problemas. Cuando crece son miles y miles de líneas de códigos y esta línea de códigos se vuelven a complejas, hay una interdependencia. Si queremos modificar una parte seguramente tengamos que tocar otra parte del código o romper cosas, los test son gigantescos y empezamos a encontrarnos con que viene el mano y nos dice che, ahora queremos hacer Machine Learning y nosotros estamos trabajando en God, por ejemplo. Y sabemos que integrar algo de Python dentro de un monolito en God es muy complicado. Entonces por estos motivos es que las compañías cuando crecen y empiezan a hacer software mucho más complejo, empiezan a tomar decisiones de separar este monolito en pequeñas piezas. Estas pequeñas piezas que hoy les llamamos micros servicios, nos dan la inventaja de que podemos elegir el stack que nos interesa para resolver el problema. O sea el martizo para clavar, el serrucho para cortan madera. Este imagen que se ve acá, que no se ve mucho detalle, pero son muchos puntitos y muchas líneas azul. Esos puntitos representan micros servicios. Son cada uno de esos puntitos de micros servicios y cada línea azul es una comunicación. Entonces si bien resolvimos problemas de escalidad, resolimos problemas que hay. Ahora tenemos equipo dedicados para los problemas que necesitamos resolver, podemos hacer mucho más diplóvimas rápido, se empiezan a aparecer otros problemas, que es el problema de la comunicación. ¿Qué significa? Ante una comunicación era una llamada una función, una llamada un método, era un 2 o 3 ciclo de CPU y ya teníamos una respuesta. Ahora tenemos un cable de red, una placa de red, tenemos de NS, tenemos un sistema mucho más complejo para poder sacar un mensaje de un micros servicio al otro. Nosotros cuando empezamos a trabajar con Python en mercado de libre fuerte, que empezamos a hacer Machine Learning, nos dimos cuenta que en las performan de todas las APIs o los micros servicios, que hacíamos en Python, no se comparaban con lo que ya estaba hecho un go, por ejemplo. Y pero no tenía mucho sentido porque estábamos haciendo cosas sencillas del principio. Entonces empezamos a investigar un poquito y hay un poco de esta charla de los insens que sacamos. Entonces les queremos contar un poquito que hicimos y en general que se hace para conectar micros servicios con Python. En realidad conectar micros servicios a este nivel es hacer una llamada HTTP, es hacer un request como el que hace el navegador, cuando no entra una página, hace un request, ha sido un servidor, eso va a vuelve y en la degarlo renériz algo, en nuestro caso, mandamos un mensaje y recibimos una respuesta y trabajamos. El caso de una arquitectura de micros servicios, cuando nosotros montamos nuestra solución con este diseño, por lo que real corremos en infraestructura de red que está optimizada para esto. No es lo mismo yo acá entrando a Google que tengo que atravesar un montón de continentes hasta que llegue el rico, es el servidor y vuelva, cuando yo el mi empresa voy a armar en infraestructura de micros servicios, por lo general voy a intentar que la capa de tráfico, la capa de red, se ha óptima chica, velos, entonces voy a montar por ejemplo todo en AWS para que el tráfico esté contenido adentro de tráfico de fibra y de backbone, eso es super eficientes. Entonces lo que realmente pasa a nivel código pasa hacer relevante, ¿eh? Entonces típicamente que hacemos el mundo Python para hacer un request HTTP, quieren conocer a librería requests, levanten la mano por favor, casi todos bien, perfecto, el 78,29%. Casi todo, sí, request es lo que se usa en Python y tiene sentido porque la librería request nos abstracte los BMoles, el protocol HTTP, ¿qué significa un request HTTP? Hay cierto estrin formateado con un formalismo que tiene que viajar hacia un servidor que lo vas a recibir y que me va a devolver con cierta formalidad o mensaje. Eso es un protocolo que se monta sobre un montón de cosas, sobre en particular la red. Entonces por ejemplo que yo quiero en mi aplicación que calcula el tiempo de envío y un paquete, estípicamente voy a depender de otros servicios, voy a depender de servicios externos, porque yo voy a querer calcular para determinado usuario y determinado producto, bueno, ¿cuánto tal ese producto en llegar a su casa? Entonces yo voy a tener que pedirle a la API de direcciones de usuarios que me diga las direcciones de usuario y voy a querer pedir a otro endpoint que es la información de los vendedores, que me de información y después a la información de las direcciones de los vendedores. Entonces en una esquema de microservicios típicamente vamos a tener una serie de llamadas, una serie de requests a otros servicios, posiblemente aún mismo servicio, yo le quiero pegar muchas veces. Este código cada vez que llegó request ustedes de entrar al mercado libre al marketplace, entre la verulítem y en algún momento le dice por ejemplo cuánto mataró a llegar aproximadamente el sistema a su casa. Eso significa que con cada rico es que llega al mercado libre, este código se ejecuta y al mercado libre tenemos cientos de miles de ricos por minuto. Y significa que este endpoint se va a llamar cientos de miles de veces por minuto. Entonces estas llamadas mi microservicio le va a estar pegando los otros microservicios de una manera exponencial con respecto al tráfico que recibo. Entonces ¿qué pasa cada vez que yo le pego otro microservicio? ¿Bien esto que en mi computadora se desmejor? Esta tiene que ver más o menos con la explicación del protocolo tcp, la capa de red. ¿Qué pasa cuando yo le envío desde mi cliente a un mensaje al servidor? Se establece una comunicación a nivel red donde primero hay que ir al DNS para ver cuál es la IP del servidor que tiene que llegar porque yo le digo una URL, una string. Entonces da de ese IP tengo que empezar a mandar ciertos mensajes de conexión a ese otro servidor. Entonces esos son un montón de mensajes entre mi entre la máquina original y la máquina de destino. Le va a tu mensaje para que se conecte y una vez que se conecta tiene que haber si estoy en un esquema de ese cl o de seguridad, hay todo un intercambio de protocolos, asociado a que voy a asegurarme de que está protegida, la conexión, esto se unir y vueltas de mensajes. Para que finalmente yo le pueda mandar el payload de mi mensaje, para que fíjense que nosotros en Python le dijimos mandar un get y traer este resultado, internamente que nos resolvió request y hizo toda esta comunicación, mandó el mensaje y cerró la conexión. Y eso lo hizo cada vez resolución de DNS, ese se conectó, ese cl, le mandó el payload y la cerró. Con cada vez y los cientos de miles de veces que yo me conecto con el otro servidor, request aseto. Porque bueno, porque el que se hace es fácil, con muy poco, hace mucho. Ahora yo estoy en una esquema de micro-serizo, yo voy a conectar muchas veces con el mismo servidor, era un esquema seguro. Yo no quisiera estar abriendo y cerrando esta conexión cada vez, yo no quisiera estar intercambiando, certificado, ese cl. Entonces en realidad yo me gustaría quedarme con una partecita muy chiquita todo lo que está haciendo, request. Entonces la librería request con muy poco me permite ganar esa optimización. Uno tiene que leer la documentación de request, tiene que pasar del getting start, de quick start de request y empezar a ver los features como en todas las librerías que estamos usando en general. Tenemos un quick start pero después tenemos que ver cuáles son los parámetros un poquito más avanzados. Fíjense que con muy pocos cambios, yo request le puedo decir no quiero usar la de top level, request le digo che de alguna sesión. Che. Bueno, no sé. Hola. Riqueste. La buena sesión. Y después yo puedo usar esa sesión. Esa sesión significa justamente ganar todas esas optimizaciones. Riquest establece una sesión de comunicación con un servidor y ya mantiene abierta la conexión. Entonces yo después cada vez que mando un mensaje solamente envía el payload. Para ahí agrego algo, esto está escalando. Que realmente cuando uno hace micro servicio el payload es una ID, es un string, es muy chiquito, no estás pasando un imagen de dos digas. Entonces es realmente es muchísimo lo que uno gana si puede hacer use of optimo de los tiempos esto que estamos haciendo. Y si yo lo único que voy a hacer en aplicaciones, una vez por ahora peguirle algo a Google y volver, no esté queriendo activizar esto. Y luego pensemos en la escala en la que mi arquitectura entera los miles de ricos que atiendo por segundo se transforman en cientos de miles de ricos adentro de mis istevas. Cada mil y segundo que yo le gane va a ser un mil y segundo menos de cómputo, mil y segundo menos de tráfico y eso se transforma por lo que creen costos. Bien, el mejor es en costos. Entonces los otros vivimos que se estaba usando de forma naive, Riquest, trabajamos con múltiples equipos entre la organización. Veamos que estaban usando Riquest así no más como Quick Start y hicimos algunos benchmarks usando session y en particular el happy que hacemos con Rudy empezamos a usar sessions. Claro. Y vimos mejoras impresionantes con realmente como poco cambio. Por ejemplo, la cantidad de ricos que puedo hacer eso por segundo con el primer vea su eco, digo, son alrededor de 500. Usando sessions se duplicó, se duplicó la cantidad de ricos que puedo hacer eso en un segundo haciendo tres líneas de código de cambio. Bien, acá bueno el vea no me quiero hacer refoco en el benchmark si pero bueno hicimos esto es una prueba local, obviamente la cantidad de ricos que puedan hacer por segundo va a vender 1 millón de cosas. Cuando probas R, tratas de australerte de la RID y usas tu propia interfaz de tu máquina como para tener algo consistente. Entonces realmente por hacer tres líneas de código de cambio ganamos una performance en cuanto a la cantidad rico que podemos hacer por segundo del doble. También es más impresionante en una esquema chiste de TPS donde toda la negociación de certificados de SCL, metetanto a Vergette, que yo podía hacer 146 ricos por segundo, habría desarrollándolo con acción y pasando sesiones, pasó a mil, o sea el cambio y la gana se realmente impresionante. Entonces bueno y también todo el que priori no habíamos pensado pero que terminó sucediendo es que el uso de CPU, el mi aplicación, casi pasó la mitad. Porque todas estas cosas que estaban haciendo ricos por abajo no las tiene que hacer más y si estamos pagando por CPU, por ejemplo comprando instancias en la 9, tal vez si tengo múltiples instancias, bueno usarla menos significa costo, mejoras en costos, o si tienen datos entre en su pieza, no sé menos calor, algo pero... La ventaja para todos, entonces bueno a ver por qué estamos usando ricos, porque estábamos usando ricos, tiene una interfaz espectacular, realmente muy amigable, muy simple hacer un llamado de Jueves, después tiene un montón de ventajas asociadas a las aplicaciones web tradicionales, no necesariamente a micro-servings, entonces manejos de cookies, verificaciones de cosas de seguridad, decodificación de contenido, streaming, chunking de vio de datos, tiene un montón de ventajas que están buenísimas, de las cuales a nosotros prácticamente no nos interesa ninguna. Está bien, te va a ir a empezar muy rápido, pero en el fondo usa un relícter. Hay alguna aclaración, esto no se trata de comparar cosas, no queremos hacer comparaciones, las comparaciones son odiosas, en realidad estamos tratando de ver distintas herramientas, yo oí lo veo como rico es una herramienta para resolver algunos tipos problemas y Jueves relíctres, que es lo que voy a hablar un poquito ahora, es una herramienta para resolver otro tipo de problema, que estamos comparando que una es mejor que otra, son cosas diferentes, en el caso de web relíctres, lo primero que fuimos a analizar es ¿qué tan diferente es la interfaz? Porque esto lo tenemos a replicar en 300 equipos, tenemos aligo un mensaje a 300 equipos de heche, deberíamos empezar a utilizar este herramienta porque ahí lo vamos a ver más adelante, y nos encontramos que si bien no están amigables, acá no puede utilizar como hacia con rico es de no hacer una sesión, acá realmente hay que hacer un pull, lo sision de rico es en el fondo, hacer un pull de web relíctres, hay que ser más explícito en los parámetros, no es tan que los adivino mágicamente, igual son dos parámetros, uno dice a cuántos dominios diferente va a mantener una conexión, por ejemplo si me conecto a 5 microservicios, el número de pull es 5, el maxize que está ahí como 10 es la cantidad de hilos que vamos a tener abierto por cada pull, entonces si estamos trabajando con un y corbudo lsg y estamos haciendo Tridin y vamos a poner 10 hilos, sabemos que ahí tenemos que poner un número 10 o más, esto no es un número duro, no es que si de repente hay más hilos corriendo insestables en más conexiones, no nos va a permitir lo que va a pasar, que cuando se cumple un timeout va a ir eliminando conexiones y siempre va a dejar 10 establecidas, y las otras se van a tener establecer cuando siguen inicion, después en el uso y es un poco raro en realidad el get no es un método y es un parámetro, los fields, hay cosas que realmente el interfaz rico es tan buenísima y no la tenemos en un número de 3, pero haciendo un análisis rápido tampoco es inentendible, no es que hoy vemos esto todo lo que estamos acá y vamos a entender que eso quiere hacer un get a esta URL y que le quiere pasar esta parámetros, y simolas mivas pruebas que veníamos haciendo exactamente el mismo escenario y encontramos que con solo esos cambios que no son menores, si uno ya tiene un proveo de acto que está establecido, que es grande y tiene muchos testes, escritos con ricos y ricos más son cambios importantes, pero ya teníamos un 30% de alancia y no es poco un 30%, 30% es un montón cuando tienen millones de ricos que se están ejecutando, entonces pasamos de 1000 que le teníamos antes a 1300, en ese momento ya estamos en Canchila, habíamos pasado de un mes, no sé si algo que usan acá o una mala palabra que van a Cualombia, si no, no lo es, habíamos trabajado un mes aproximadamente haciendo estas pruebas y estos cambios probándolos en API y ya estamos al doble y un poquito más del doble y vamos a investigar un poquito más, vamos más, ya somos una compañía grande, tenemos muchas APIs que escribimos en Python, tenemos tiempo para hacer estas cosas, entonces bueno jugemos, empecemos investigar y obviamente ir de Python a C, a C, que es PyCool y está hecho en C, sabíamos que vamos a tener alguna ventaja en tiempo, ahora teníamos enalizar cuáles son las desventajas de usar PyCool, porque no todo de gratis en la vida, entonces empezamos a investigar Cool, lo primero que vimos en la documentación es que es para usuarios avanzados, para hacer docena de conexiones con currentes, feature sustificado y la documentación está escrito en HTML1.0, yo que venía de Rit de Doc, si tuviste estas cosas bonitas y con buscador en pese a leer esa documentación y dije no, o porque me estoy metiendo acá, pero bueno, nada, tenía el tiempo, somos informáticos, nos gusta hacer estas cosas, investe un poquito más, empecé a jugar y dije bueno voy a hacer mi primer get in PyCool. Esto es copy page de la documentación de PyCool, de disclaimer en la web page, está buenísimo, el que habéis anotradición, y está muy bien, ¿por qué? ¿quién usted usa PyCool? Un valiente, o un relíptr, ¿qué nos usa? Ahí está, ahí va lo, ahí está trabajando con los servicios, hablemos en un rato. Pero sí, acá PyCool está diciendo sin encitas docenas de llamadas, concurrente y era un, con feature sustificado, entonces ya está avisando que, también si lo que único que queréis hacerle un post a la lista de, no sé qué pública, no hace falta, pero capaz de una vez que más microsaricios, donde queréis hacer docenas de concurrentes ricos, si tenés advanced developers que se la banquen, puede llegar a tener sentido. Igual vamos a llegar a esa parte, avance de viva, pero sí, vamos a hacer falta. Lo primero que vimos cuando hicimos las pruebas es que ya duplicamos lo que habíamos duplicado, la verdad estamos súper contentos, eso tenía muchísimas ganas de implementar esto, decirlo a todo el mundo, por favor, es en PyCool, es la que va, me junté con listos, con Javi, un poco analizar el Javi, es un batto chivo de trabajo con nosotros, analizar esto y empezamos a ver un poco cómo se hace el greek y cómo se usa y no nos convencía mucho. Esto es importantísimo, el uso de CPU se fue al 0.73%, la gente que está usando mucho Python y en mercado libre hace machine learning, cada porcentaje de CPU que le liberamos son jugo para eso, entonces tenemos que salir con esto rápido producción, ¿cómo hacemos? Eso es un get in PyCool, se recuerdan, bueno, todo usan un rico de rico.get y ya estás haciendo un get. Y acá hay tan color al tovardo 1, no sé si un color ambia bardo significa lo mismo que significa de Argentina. Un gran problema 1. Un gran problema 1, un gran problema 2. La forma que uno le tiene que pasar los parámetros, no es un diccionario común, realmente es súper complejo, súper confuso, yo hace 5 años estoy con Python y venía a esto y decía por qué, por favor, ¿por qué es así? Pero bueno, tiene sus ventajas, tiene la ventaja de duplicar la cantidad rico de Google, de USB3, de uso de CPU, tenemos que ver que así, creo que el post no se lo puse, bueno, el post, un get in PyCool es doblemente lo arduo, imagínense te esté a adreso, es como te esté a este empera ese código, como reparto este código en 300, 400 aplicaciones, es muy difícil. Te he ganado de cuesta que todos conoce rico, nosotros también conociamos rico. Entonces, ¿cuándo tienes que hacer una solución? ¿Ustedes rico? El momento 0, no te lo preguntaste, lo cual es un problema en un contexto productivo, si están haciendo un apoc, si están haciendo un prototipo, si están haciendo una prueba, hay preguntas que no necesitamos hacernos. Pero cuando vamos a un entorno productivo, sobre todo de escala, tenemos que ser mucho más detalladas. Entonces, haber elegido rico es como librería de comunicación entre procesos, es de dotesca. Es cierto, bien, es un riesgo que estamos tomando y que en algún momento lo puede costar y que en algún momento, ese costo, como cualquier devuda, con sus hitéres se va a hacer más caro. Y nosotros no nos dimos cuenta. Y nos dimos cuenta cuando nos dimos cuenta que hay que implementar esto, con cada rico es que teníamos en cada una de los, hoy por hoy cientos de microsavicios despliegos en Python que tenemos. Son muchos equipos de trabajo trabajando y si cada uno de esos equipos se le digo, ¿Esa línea? No, no, reclasa las por estas 75 que tenemos acá. Y listo. Otra cosa que teníamos en Python y que era súper interesante y no logramos hacer con rico y borrelip 3. En un entorno productivo hacer monitoring es súper importante medir, hay que medir todo lo que se pueda. En mercado de libre nos gusta medir mucho y medimos cada cosa que sucede. Por ejemplo, si va el DNS, nos queremos medir por cada rico, es que sale cuánto tiempo tardó y en ir y volver al DNS. Si hay una conexión cuánto tiempo se tardó en establecer esa conexión. Si el payload cuánto tiempo tardó todos esos detalles en librerías de bajo nivel como pari-cult podíamos obtener las y en las de alto nivel, realmente teníamos de entrar a muyificar el código en la librería y era bastante complejo. Entonces hay un poco gran y veíamos como la ventaja de poder monitorear muchísimo mejor los microsavicios que te veníamos y era otra cosa a favor que nos decías che tenemos aquí por este camino. ¿Sígato? Insay, un poco lo que veníamos charlando, lo que veníamos contando. Rico es de alto nivel, está buenísimo para empezar, está buenísimo si una cedata science y tiene que hacer algunas búsqueda. No quiero un mail que me diga después che, me dijiste paico de buenísimo, mirad, tenía que hacer un rico de Google para sacar algo estuve 3 días. No estamos vendiendo eso. Rico es un excelente herramienta para utilizarla en el contexto que se tiene que utilizar. Hay opciones de optimizaciones, hay que leerla, a mí me he dado mucho la atención que la opción de optimización de esto decision en Rico es, está en uso avanzado. Personalmente considero que no están avanzados, me parece bastante sencillo poder utilizar un feature como eso, capaz que entender en el fondo que lo que hace puede ser complejo, pero como feature de la librería es algo relativamente básico. Como toda optimización, siempre, avoy de early optimization, early optimization, is the root of all evil, dijo algún viejo pop de la informática. Bueno, no acabamos de optimizar la entrada, entonces sí, a camismo estamos viendo que informas de optimizar la manera de hacer rico, tengo la en cuenta de función de su caso de uso. Después, las buenas prácticas en que nierías aplican para todos, las prácticas que conocemos, de no optimizar antes de tiempo, de empezar, esto es algo que me lo discuta, a mí me gusta empezar a desarrollar pensando que está todo bien y después pensar en las cosas que pueden fallar, creo que una charla hace unos días, de 100 todos los contrarios, a mí me gusta hacer optimista y después ir agregando complejidad. Entonces, esas buenas prácticas que hay que hemos estudiado sirven para los macros y para los micros también, en este caso. Entonces bueno, les mostramos lo que estamos haciendo, les contamos que encontramos formas de optimizarlo, entonces ahora le queremos contarlo el próximo paso, no el final, sino el próximo paso, que hicimos en Mercado Libre con todo esto o por lo menos en el marco nuestros equipos, primero lo queremos esta filmina de marketing, es un poco para que entienda la cuestión de envergadura y de escala, que realmente en nuestro caso, porque tiene sentido hacer lo que hicimos, lo que lo podemos demostrar, en Mercado Libre hay 6 mil busques por segundo, una búsqueda desde el browser dispara un montón de ricos, y cada uno de esos ricos adentro nuestro sistema se multiplica, entonces imagínese el volumen de transacciones con los envíos, con las compras, con cada uno de los pagos a través de mercados pagos cada item que se crea cada usuario que entra, son literalmente millones de ricos por segundo, que se multiplica dentro nuestro sistema, probablemente se no sea el caso de uso de todos ustedes, lo cual no significa que les cala, la que esté trabajando, no sea importante considerar esto lo mismo, pero para nosotros que veníamos de la empresa más chica, que en Mercado Libre del Quirio nos encontramos con esta escala y el día de hoy sigue siendo impresionante, porque lo vemos en el día de día, entonces quéis hicimos con todo esto de sabemos que podemos optimizar la forma de conectar microciarizos en Python, básicamente hicimos una librería, una rest client, una abstractión de la capa de comunicación HTTP, hay que poder que podriamos haber hecho desde el inicio, lo que pasa es que esa rico es tan fácil, no veíamos la necesidad de hacerlo raper. Sí, a partir de eso yo recuerdo entre en un proyecto el primer día y dije, bueno, cinco mil ricos, voy a tener dos mil ricos, esto lo hizo una prueba en mi máquina esta bandar, después salió producción, tenía 200 mil ricos por segundo, entonces ahí me di cuenta que ahí me va a discutirme el che para, hay que hacer cosas con esto, no es tan senciso, El happy, en Mercado Libre no funciona, el approach naive de entrada, no funciona nunca, de entrada tienes que pensar entre 10 mil y 50 mil ricos por minuto, el 10KRPB, el 50KRPB, es algo que para nosotros todavía es chico, cuando queremos probar infraestructuras, por ejemplo, haremos un happy de 600, 700KRPB, son happy que se les está pegando fuerte, pero no son la más grande del sitio, se nos va a meter el escalje grande, cuando estamos en esta máquina, nos metemos al medio de casi todos los flujos importantes del negocio, perdiciendo, categorizando, recomendando, entonces por más que hay mucho go dando vuelta en la compañía, pero utilizar estas cosas es mucho jable en el lógica de negocios, Python de repente con una capillaria muy grande, apalancado por el Machine Learning, se ve a ti, entonces lo que hicimos hace poco es esta hora librería para que los desarrolladores ahora instancia en una librería un res client, que esconder todos los detalles de implementación y toda la lógica de negocios relacionada a conectar microservices de la compañía y obviamente ya que nos gustaba tanto el interfaz rico, si intentamos hacer algo, realmente parecido y ahí varios desafíos, toda la comunidad patónica que está trabajando, están muy familiarizadas con rico, entonces no fue solamente hacer una buena interfaz parecida a la de rico, es para esta herramienta, sino que después nos encontramos que todas las herramientas que hay alrededor de rico es como rico es mo, para testiarla nos dejaban de servir, entonces también tuvimos que desarrollar herramientas para testiar nuestro res client que sean parecidas, porque la comunidad estaba acostumbrada, no fue trivial de sentarse una, dos semanas y grabiéral algo, sino que realmente hubo que sentarse, hacer ni que ni hería, diseñarlo, pensarlo, probarlo ir y volver y algunas cosas interesantes que sucedieron, hoy por una cuestión de que uno no puede aplicar un cambio masivamente en toda la compañía, porque es muy riesgoso, el res client nosotros vamos agregando lo que llamamos en jeans, que básicamente empezamos con un rico es en el fondo, que estamos seguro que andaba con sesión, despagaramos un relipter y de a poquito fuimos migrando algunas apicas, usan esta implementación y después anpaiculi, simulos mismos fuimos migrando, y fue muy interesante ver como equipos hacían los diploi y decían, mira no sé qué hicimos, no es súper rapidora, nosotros estamos haciendo todo a H, me parece que está funcionando esto, pero esto que se lo cuento como chiste es, es el valor de por poder tener herramientas de la compañía que impacten en toda la compañía con un solo cambio, nosotros hacemos una nueva versión de esta librería y estamos impactando en todos los microservicios que están en Python, que si no lo hubiéramos hecho tendríamos que haber hecho que decía delito que decir che bueno esta línea ahora la cambia en por esta 70, entonces tomar decisión y adicuñar es parte de comunicar microservicio, no es solamente una cuestión de optimizar la performance. Bueno luego que llevamos con partidos este es un caso de uso propio es parte de lo que lo que nos sirvió tiene sus prois sus contras, porque ahora esta librería le tiene que mantener a alguien, si el sistema de recomendaciones de mercado libre encuentro un vaga o una limitación de esta librería obviamente alguien lo tiene que resolver y ese alguien en este caso somos nosotros, entonces de nuevo depende el caso de uso hay que responsabilizarse por las herramientas que hacemos, como dice Rudy los pros son muchísimos, las contras no tantas como para que nos animamos, lo que tenemos fue el mar de 2019 para isolated no no tienes no hay trainer, no hay marcha,APPLAUSEny\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"/content/PyCon-co audios/audios/Rodolfo Edelmann & Carlos de la Torre - Conectando microservicios con Python [N3czkxo2JJw].mp3\")\n",
        "print(result[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82Vy9W4UN0JR",
        "outputId": "72eff207-b549-442e-976b-f7f9c90b8964"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': ' Bueno, quién soy Rodolfo Edelman, me van a escuchar ahí que me dicen Rudy. Tiengan cuidado si me llaman Digan Rudy con Deno con B. Larga, porque con Ferencia Python se pueden ojar a alguien. Hace 5 años estoy trabajando con Python antes de trabajar con Ruby, eso no lo voy a contermas. Trabajé mucho tiempo a la Universidad Nacional de Córdoba, a esa foto en el Cláster de la Universidad Nacional de Córdoba. Hace mucho de Robots, después abancé a Bakken, de Bakken, empezó a hacer Machine Learning y actualmente estoy como técnica al Manaller en Mercado de Libre, desarrollando productos, servicios internos de la compañía que nos sirven para poner modelos de Machine Learning en producción. Hola, yo soy Litox, Carlos de la Torre, me dicen Litox en la Uroschatz y en las comunidades de Python y en la tele, pero eso todavía no se se llenó nunca. Trabajo con Ruy hace muchos años, también soy técnica al Manaller, tengo un recorrido de su licencia informática y de desarrollador, técnica leader, retabajado en empresas nacionales, en Argentina, en Pymes, pequeñas empresas, ahora en Mercado de Libre estamos como hizo Rudy armando la infraestructura para ejecutar. Machine Learning en producción y a escala. Bueno, queremos entonces contarles un poquito de qué va a ser la charla. Primero que todos para entender el motivo de la charla tenemos que entender porque creamos microsや servicios, ¿cómo hacemos esto en Python? Está normalmente, ¿cuáles son los insas que fuimos sacando, teniendo en estos años de desarrollo, un poco eso y algunos casos de uso que vamos a ver. Monalito, ¿todo saben qué es monalito? Levanta la mano. Normalmente bueno, por accidente. Normalmente una cuando empieza a construir el primer producto, empieza, no quiere hacer algo complejo, quiere empezar por algo que sea fácil de poner en producción rápido para validar una idea. De esta manera es que empezamos a hacer un monalito. En la arquitectura monalito es construcción sobre un solo material. Se hace una analogía cuando el diseño de software que tiene que ver con un estat tecnológico. El ejeimo en estat tecnológico y construimos sobre ese estat. ¿Qué quiere decir? El ejeimo Python, Django, MySQL y alguna cola de mensajes. Pero esto paría producción fantástico. Vamos rápido, pero empiezan a ocurrir problemas. Cuando crece son miles y miles de líneas de códigos y esta línea de códigos se vuelven a complejas, hay una interdependencia. Si queremos modificar una parte seguramente tengamos que tocar otra parte del código o romper cosas, los test son gigantescos y empezamos a encontrarnos con que viene el mano y nos dice che, ahora queremos hacer Machine Learning y nosotros estamos trabajando en God, por ejemplo. Y sabemos que integrar algo de Python dentro de un monolito en God es muy complicado. Entonces por estos motivos es que las compañías cuando crecen y empiezan a hacer software mucho más complejo, empiezan a tomar decisiones de separar este monolito en pequeñas piezas. Estas pequeñas piezas que hoy les llamamos micros servicios, nos dan la inventaja de que podemos elegir el stack que nos interesa para resolver el problema. O sea el martizo para clavar, el serrucho para cortan madera. Este imagen que se ve acá, que no se ve mucho detalle, pero son muchos puntitos y muchas líneas azul. Esos puntitos representan micros servicios. Son cada uno de esos puntitos de micros servicios y cada línea azul es una comunicación. Entonces si bien resolvimos problemas de escalidad, resolimos problemas que hay. Ahora tenemos equipo dedicados para los problemas que necesitamos resolver, podemos hacer mucho más diplóvimas rápido, se empiezan a aparecer otros problemas, que es el problema de la comunicación. ¿Qué significa? Ante una comunicación era una llamada una función, una llamada un método, era un 2 o 3 ciclo de CPU y ya teníamos una respuesta. Ahora tenemos un cable de red, una placa de red, tenemos de NS, tenemos un sistema mucho más complejo para poder sacar un mensaje de un micros servicio al otro. Nosotros cuando empezamos a trabajar con Python en mercado de libre fuerte, que empezamos a hacer Machine Learning, nos dimos cuenta que en las performan de todas las APIs o los micros servicios, que hacíamos en Python, no se comparaban con lo que ya estaba hecho un go, por ejemplo. Y pero no tenía mucho sentido porque estábamos haciendo cosas sencillas del principio. Entonces empezamos a investigar un poquito y hay un poco de esta charla de los insens que sacamos. Entonces les queremos contar un poquito que hicimos y en general que se hace para conectar micros servicios con Python. En realidad conectar micros servicios a este nivel es hacer una llamada HTTP, es hacer un request como el que hace el navegador, cuando no entra una página, hace un request, ha sido un servidor, eso va a vuelve y en la degarlo renériz algo, en nuestro caso, mandamos un mensaje y recibimos una respuesta y trabajamos. El caso de una arquitectura de micros servicios, cuando nosotros montamos nuestra solución con este diseño, por lo que real corremos en infraestructura de red que está optimizada para esto. No es lo mismo yo acá entrando a Google que tengo que atravesar un montón de continentes hasta que llegue el rico, es el servidor y vuelva, cuando yo el mi empresa voy a armar en infraestructura de micros servicios, por lo general voy a intentar que la capa de tráfico, la capa de red, se ha óptima chica, velos, entonces voy a montar por ejemplo todo en AWS para que el tráfico esté contenido adentro de tráfico de fibra y de backbone, eso es super eficientes. Entonces lo que realmente pasa a nivel código pasa hacer relevante, ¿eh? Entonces típicamente que hacemos el mundo Python para hacer un request HTTP, quieren conocer a librería requests, levanten la mano por favor, casi todos bien, perfecto, el 78,29%. Casi todo, sí, request es lo que se usa en Python y tiene sentido porque la librería request nos abstracte los BMoles, el protocol HTTP, ¿qué significa un request HTTP? Hay cierto estrin formateado con un formalismo que tiene que viajar hacia un servidor que lo vas a recibir y que me va a devolver con cierta formalidad o mensaje. Eso es un protocolo que se monta sobre un montón de cosas, sobre en particular la red. Entonces por ejemplo que yo quiero en mi aplicación que calcula el tiempo de envío y un paquete, estípicamente voy a depender de otros servicios, voy a depender de servicios externos, porque yo voy a querer calcular para determinado usuario y determinado producto, bueno, ¿cuánto tal ese producto en llegar a su casa? Entonces yo voy a tener que pedirle a la API de direcciones de usuarios que me diga las direcciones de usuario y voy a querer pedir a otro endpoint que es la información de los vendedores, que me de información y después a la información de las direcciones de los vendedores. Entonces en una esquema de microservicios típicamente vamos a tener una serie de llamadas, una serie de requests a otros servicios, posiblemente aún mismo servicio, yo le quiero pegar muchas veces. Este código cada vez que llegó request ustedes de entrar al mercado libre al marketplace, entre la verulítem y en algún momento le dice por ejemplo cuánto mataró a llegar aproximadamente el sistema a su casa. Eso significa que con cada rico es que llega al mercado libre, este código se ejecuta y al mercado libre tenemos cientos de miles de ricos por minuto. Y significa que este endpoint se va a llamar cientos de miles de veces por minuto. Entonces estas llamadas mi microservicio le va a estar pegando los otros microservicios de una manera exponencial con respecto al tráfico que recibo. Entonces ¿qué pasa cada vez que yo le pego otro microservicio? ¿Bien esto que en mi computadora se desmejor? Esta tiene que ver más o menos con la explicación del protocolo tcp, la capa de red. ¿Qué pasa cuando yo le envío desde mi cliente a un mensaje al servidor? Se establece una comunicación a nivel red donde primero hay que ir al DNS para ver cuál es la IP del servidor que tiene que llegar porque yo le digo una URL, una string. Entonces da de ese IP tengo que empezar a mandar ciertos mensajes de conexión a ese otro servidor. Entonces esos son un montón de mensajes entre mi entre la máquina original y la máquina de destino. Le va a tu mensaje para que se conecte y una vez que se conecta tiene que haber si estoy en un esquema de ese cl o de seguridad, hay todo un intercambio de protocolos, asociado a que voy a asegurarme de que está protegida, la conexión, esto se unir y vueltas de mensajes. Para que finalmente yo le pueda mandar el payload de mi mensaje, para que fíjense que nosotros en Python le dijimos mandar un get y traer este resultado, internamente que nos resolvió request y hizo toda esta comunicación, mandó el mensaje y cerró la conexión. Y eso lo hizo cada vez resolución de DNS, ese se conectó, ese cl, le mandó el payload y la cerró. Con cada vez y los cientos de miles de veces que yo me conecto con el otro servidor, request aseto. Porque bueno, porque el que se hace es fácil, con muy poco, hace mucho. Ahora yo estoy en una esquema de micro-serizo, yo voy a conectar muchas veces con el mismo servidor, era un esquema seguro. Yo no quisiera estar abriendo y cerrando esta conexión cada vez, yo no quisiera estar intercambiando, certificado, ese cl. Entonces en realidad yo me gustaría quedarme con una partecita muy chiquita todo lo que está haciendo, request. Entonces la librería request con muy poco me permite ganar esa optimización. Uno tiene que leer la documentación de request, tiene que pasar del getting start, de quick start de request y empezar a ver los features como en todas las librerías que estamos usando en general. Tenemos un quick start pero después tenemos que ver cuáles son los parámetros un poquito más avanzados. Fíjense que con muy pocos cambios, yo request le puedo decir no quiero usar la de top level, request le digo che de alguna sesión. Che. Bueno, no sé. Hola. Riqueste. La buena sesión. Y después yo puedo usar esa sesión. Esa sesión significa justamente ganar todas esas optimizaciones. Riquest establece una sesión de comunicación con un servidor y ya mantiene abierta la conexión. Entonces yo después cada vez que mando un mensaje solamente envía el payload. Para ahí agrego algo, esto está escalando. Que realmente cuando uno hace micro servicio el payload es una ID, es un string, es muy chiquito, no estás pasando un imagen de dos digas. Entonces es realmente es muchísimo lo que uno gana si puede hacer use of optimo de los tiempos esto que estamos haciendo. Y si yo lo único que voy a hacer en aplicaciones, una vez por ahora peguirle algo a Google y volver, no esté queriendo activizar esto. Y luego pensemos en la escala en la que mi arquitectura entera los miles de ricos que atiendo por segundo se transforman en cientos de miles de ricos adentro de mis istevas. Cada mil y segundo que yo le gane va a ser un mil y segundo menos de cómputo, mil y segundo menos de tráfico y eso se transforma por lo que creen costos. Bien, el mejor es en costos. Entonces los otros vivimos que se estaba usando de forma naive, Riquest, trabajamos con múltiples equipos entre la organización. Veamos que estaban usando Riquest así no más como Quick Start y hicimos algunos benchmarks usando session y en particular el happy que hacemos con Rudy empezamos a usar sessions. Claro. Y vimos mejoras impresionantes con realmente como poco cambio. Por ejemplo, la cantidad de ricos que puedo hacer eso por segundo con el primer vea su eco, digo, son alrededor de 500. Usando sessions se duplicó, se duplicó la cantidad de ricos que puedo hacer eso en un segundo haciendo tres líneas de código de cambio. Bien, acá bueno el vea no me quiero hacer refoco en el benchmark si pero bueno hicimos esto es una prueba local, obviamente la cantidad de ricos que puedan hacer por segundo va a vender 1 millón de cosas. Cuando probas R, tratas de australerte de la RID y usas tu propia interfaz de tu máquina como para tener algo consistente. Entonces realmente por hacer tres líneas de código de cambio ganamos una performance en cuanto a la cantidad rico que podemos hacer por segundo del doble. También es más impresionante en una esquema chiste de TPS donde toda la negociación de certificados de SCL, metetanto a Vergette, que yo podía hacer 146 ricos por segundo, habría desarrollándolo con acción y pasando sesiones, pasó a mil, o sea el cambio y la gana se realmente impresionante. Entonces bueno y también todo el que priori no habíamos pensado pero que terminó sucediendo es que el uso de CPU, el mi aplicación, casi pasó la mitad. Porque todas estas cosas que estaban haciendo ricos por abajo no las tiene que hacer más y si estamos pagando por CPU, por ejemplo comprando instancias en la 9, tal vez si tengo múltiples instancias, bueno usarla menos significa costo, mejoras en costos, o si tienen datos entre en su pieza, no sé menos calor, algo pero... La ventaja para todos, entonces bueno a ver por qué estamos usando ricos, porque estábamos usando ricos, tiene una interfaz espectacular, realmente muy amigable, muy simple hacer un llamado de Jueves, después tiene un montón de ventajas asociadas a las aplicaciones web tradicionales, no necesariamente a micro-servings, entonces manejos de cookies, verificaciones de cosas de seguridad, decodificación de contenido, streaming, chunking de vio de datos, tiene un montón de ventajas que están buenísimas, de las cuales a nosotros prácticamente no nos interesa ninguna. Está bien, te va a ir a empezar muy rápido, pero en el fondo usa un relícter. Hay alguna aclaración, esto no se trata de comparar cosas, no queremos hacer comparaciones, las comparaciones son odiosas, en realidad estamos tratando de ver distintas herramientas, yo oí lo veo como rico es una herramienta para resolver algunos tipos problemas y Jueves relíctres, que es lo que voy a hablar un poquito ahora, es una herramienta para resolver otro tipo de problema, que estamos comparando que una es mejor que otra, son cosas diferentes, en el caso de web relíctres, lo primero que fuimos a analizar es ¿qué tan diferente es la interfaz? Porque esto lo tenemos a replicar en 300 equipos, tenemos aligo un mensaje a 300 equipos de heche, deberíamos empezar a utilizar este herramienta porque ahí lo vamos a ver más adelante, y nos encontramos que si bien no están amigables, acá no puede utilizar como así con rico es de no hacer una sesión, acá realmente hay que hacer un pull, lo sision de rico es en el fondo, hacer un pull de web relíctres, hay que ser más explícito en los parámetros, no es tan que los adivino más quicamente, igual son dos parámetros, no más, uno dice a cuántos dominios diferente va mantener una conexión, por ejemplo si me conecto a 5 microservicios, el número de pull es 5, y el max size que está ahí como 10, el es la cantidad de ídios que vamos a tener abierto por cada pull, entonces si estamos trabajando con un unicórbudo lsg y estamos haciendo 3d y vamos a poner 10 cilos, sabemos que ahí tenemos poner un número 10 o más, esto no es un número duro, no es que si de repente hay más hilos corriendo insestables en más conexiones no nos va a permitir lo que va a pasar, que cuando se cumple un timeout va ir eliminando conexiones y siempre va a dejar 10 establecidas, y las otras se van a tener establecer cuando se inician, después en el uso, y es un poco raro en realidad el get no es un método y es un parámetro, los fields, hay cosas que realmente el interfaz rico, están buenísimas y no la tenemos en un lugar real entre 3, pero haciendo un análisis rápido tampoco es inentendible, no es que hoy va a haber mejor esto todo lo que estamos acá y más o menos podemos entender que eso quiere hacer un get a esta URL y que le quiere pasar estas parámetros y simulas mivas pruebas que veníamos haciendo exactamente el mismo escenario y encontramos que con solo esos cambios que no son menores, si uno ya tiene un proveo de acto que está establecido, que es grande y tiene muchos test, escritos con ricos y ricos mos son cambios importantes pero ya teníamos un 30% de aarancia y no es poco un 30% 30% es un montón cuando tienen millones de ricos que se están ejecutando, entonces pasamos de 1000 que le teníamos antes a 1300 en ese momento ya estamos en canchila, habíamos pasado de un mes, no sé si algo que usan acá o una mala palabra que van a Cualombia si no va a la palabra, no es la palabra o sea habíamos trabajado un mes aproximadamente haciendo estas pruebas y estos cambios probándolo en API y ya estamos al doble y un poquito más del doble y es que muy bueno, investimos un poquito más, vamos más ya, somos una compañía grande, tenemos muchas apes que escrita en Python, tenemos tiempos para hacer estas cosas, entonces bueno juguemos, empecemos, investigar y obviamente ir de Python a C, que es paicul, está hecho en C sabíamos que vamos a tener alguna ventaja en tiempo, ahora teníamos enalizar cuel son las desventajas de usar paicul, porque no todo de gratis en la vida, entonces empezamos a investigar Cual lo primero que vimos en la documentación es que es para usuarios avanzados, para hacer docena de conexiones con currrentes, feature sustificados y la documentación está escrito en HTML1.0 Yo que venía de ritme de doc, si tuviste estas cosas bonitas y con buscadores en pese a leer esa documentación y dije no, porque me estoy metiendo acá, pero bueno, nada, tenía el tiempo, somos informático, nos gusta hacer estas cosas, investimos un poquito más, empecé a jugar y dije bueno voy a hacer mi primer get in paicul. Esto es copy page de la documentación de paicul, que es que la web page está buenísimo, el que avisa no tradiciona, ¿eh? Y está muy bien, ¿por qué, ¿quién usted usa paicul? Una, un valiente, o relíptr, o relíptr, ¿qué no usa? Ahí está, pa, ahí va, ¿cómo? Hay que trabajar con los microsaricios, hablemos en un rato. Pero sí, pero acá paicul está diciendo, sin necesitas docenas de llamadas con currrentes y erones, con feature sustificados, entonces ya está avisando que, también si lo que único que queréis hacerle un post a la lista de, no sé qué pública, no hace falta, pero capaz de una vez que más microsaricios, donde queréis hacer docenas de concurrentes ricos, si tenés advanced developers que se la banquen, puede llegar a tener sentido. Igual vamos a llegar a esa parte, avance de viguelo, pero sí, vamos a faltar. Lo primero que vimos cuando hicimos las pruebas es que ya duplicamos lo que habíamos duplicado. La verdad está, súper contento, eso tenía muchísimas ganas de implementar esto, decirlo a todo el mundo, por favor, uso paicul, es la que va, me junté con listos, con Javi, un poco analizar el Javi, es un batuchivo de trabajo con nosotros, analizar esto y empezamos a ver un poco cómo se hace el gays y cómo se usa y no los convencilla mucho. Esto es importantísimo, el uso de CPU se fue al 0.73%, ¿no? Entonces, la gente que está usando mucho Python hoy en Mercado de Libre hace Machine Learning cada porcentaje de CPU que le liberamos, es jugo para eso. Entonces, tenemos que salir con esto rápido producción, ¿cómo hacemos? Eso es un get en paicul. Se recuerdan, bueno, todo usa un rico de rico es punto get y ya estás haciendo un get. Y acá hay tan color al tovard 1, no sé si un color o un bíavardo significa lo mismo que significa de Argentina. Un gran problema, uno. Un gran problema, uno, un gran problema, la forma que uno le tiene que pasar los parámetros, no es un diccionario común, realmente es súper complejo, súper confuso. Yo hace cinco años estoy con Python y venía que veía esto y decía por qué, por favor, ¿por qué es así? Pero bueno, tiene sus ventaja, tiene la ventaja de duplicar la cantidad rico de URL.3 de uso de CPU, tenemos que ver que así vamos. Creo que el post no se lo puse, bueno, el post, un get en un bardo, el post es doblemente lo ardo. Imagínense te estía a éso, es como te estío este de pedase código, como reparto este código en 300, 400 aplicaciones. Es muy difícil. Te he ganado de cuenta de que todos conocen ricos, nosotros también conocemos ricos. Entonces, ¿cómo tienes que hacer una solución? ¿Ustedes ricos? El momento 0, no te lo preguntaste, lo cual es un problema en un contexto productivo, si están haciendo un apoc, si están haciendo un prototipo, si están haciendo una prueba, hay preguntas que no necesitan trabajarnos. Pero cuando vamos a un entorno productivo, sobre todo de escala, tenemos que ser mucho más detallados. Entonces, haber el ejido rico es como librería de comunicación entre procesos, es de dotécquia. Es cierto. Bien, es un riesgo que estamos tomando y que en algún momento nos puede costar y que en algún momento ese costo, como cualquier deuda, con sus hitéres se va a hacer más caro. Bien, y nosotros no nos dimos cuenta. Y nos dimos cuenta cuando nos dimos cuenta que hay que implementar esto. Con cada rico es que teníamos en cada una de los, hoy por hoy, cientos de microsavicios desplegados en Python que tenemos. Son muchos equipos de trabajo trabajando y si cada una de esos equipos se le digo, ¿es Alinea? No, no, reclasas las por estas 75 que tenemos acá. Y listo. O otra cosa que teníamos en Python y que era súper interesante y no logramos hacer con ricos y vos relic tres. En un entorno productivo hacer monitoring es súper importante medir. Hay que medir todo lo que se pueda. En mercado de libre nos gusta medir mucho y medimos cada cosa que sucede. Si val de NES, nos queremos medir por cada rico, es que sale cuánto tiempo tardó en ir y volver al NES. Si hay una conexión cuánto tiempo se tardó en establecer esa conexión. Si el Payload cuánto tiempo tardó, todos esos detalles en librerías de bajo nivel como parical podíamos obtener las y en el de alto nivel, realmente teníamos de entrar a muyificar el código en la librería y era bastante complejo. Entonces hay un poco gran y veíamos como la ventaja de poder monitorir muchísimo mejor los microservicios que te veníamos y era otra cosa a favor que nos decíamos que tenemos aquí por este camino. Si oto. Insay, un poco lo que veníamos charlando, lo que veníamos contando. Ricos desde alto nivel, está buenísimo para empezar. Está buenísimo si una cedata science tiene que hacer algunas búsqueda. No quiero un mail que me diga después che, mi giste paico de buenísimo, mirad, tenía que hacer un rico google para sacar algo estuve tres días. No estamos vendiendo eso. Ricos es un excelente herramienta para utilizarla en el contexto que se tiene que utilizar. Hay opciones de optimizaciones, hay que leerla, a mí me he dado mucho la atención que la opción de optimización de esto decision en Ricos está en uso avanzado. Personalmente considero que no están avanzados, me parece bastante sencillo poder utilizar un feature como eso, capaz que entender en el fondo que lo que hace puede ser complejo, pero como feature de la librería es algo relativamente básico. Como toda optimización, siempre, avoy de early optimization, early optimization, is the root of all evil, dijo algún viejo pop de la informática. Bueno, no acabamos de optimizar la entrada, entonces si a camismo estamos viendo que hay formas de optimizar las maneras de ricos, tengo la en cuenta de función de su caso de uso. Después las buenas prácticas ingenierías aplican para todos, las prácticas que conocemos, de no optimizar antes de tiempo, de empezar, esto es algo que me lo discuta, a mí me gusta empezar a desarrollar pensando que está todo bien y después pensar en las cosas que pueden fallar, creo que una charla hace unos días, de 100 todos los contrarios, a mí me gusta hacer optimista y después ir agregando complejidad. Entonces, esas buenas prácticas que hay que hemos estudiado sirven para los macros y para los micros también, en este caso. Entonces bueno, les mostramos lo que estamos haciendo, les contamos que encontramos formas de optimizarlo, entonces ahora le queremos contarlo el próximo paso, no el final, sino el próximo paso, que hicimos en Mercado Libre con todo esto o por lo menos en el marco nuestros equipos, primero lo queremos esta filmina de marketing, es un poco para que entienda la cuestión de envergadura y de escala, que realmente en nuestro caso, porque tiene sentido hacer lo que hicimos, lo que lo podemos demostrar, en Mercado Libre hay 6 mil busques por segundo, una búsqueda desde el browser dispara un montón de ricos, una de esos ricos, adentro nuestro sistema se multiplica, entonces imagínese el volumen de transacciones con los envíos, con las compras, con cada uno de los pago a través de milones de Mercado Pago, cada item que se crea cada usuario que entra, son literalmente millones de ricos por segundo, que se multiplican dentro nuestro sistema, probablemente se no sea el caso de uso de todos ustedes, lo cual no significa que les escala, la que esté trabajando, no sea importante considerar esto lo mismo, pero para nosotros que venimos en el empresa más chica, que en Mercado Libre del Quirio nos encontramos con este escala y el día de hoy sigue siendo impresionante, porque lo vemos en el día de día, entonces quédimos con todo esto, sabemos que podemos optimizar la forma de conectar microsaricios en Python, básicamente hicimos una librería, una rest client, una abstractión de la capa de comunicación HTTP, algo que podría haber hecho desde el inicio, lo que pasa es que esa rico es tan fácil, no veíamos la necesidad de hacerlo raper. Yo recuerdo entre en un proyecto el primer día y dije, bueno, 5 mil ricos, voy a tener 2 mil ricos, esto lo hizo una prueba en mi máquina esta bandar, después salió a producción, tenía 200 mil ricos por segundo, entonces ahí me di cuenta que ahí me va a discutirme el che para hay que hacer cosas con esto, no es tan sencillo. En Mercado Libre no funciona el approach naive de entrada, no funciona nunca, de entrada tienes que pensar entre 10 mil y 50 mil ricos por minuto, el 10K de repb, el 50K de repb, es algo que para nosotros todavía es chico, cuando queremos probar infraestructuras, por ejemplo, ahora un API de 600, 700K de repb, son APIs que se les está pegando fuerte, pero no son la más grande del sitio, se nos meten las escalas grandes, cuando estamos en la máquina de la ring nos metemos al medio de casi todos los flujos importantes del negocio, perdiciendo, categorizando, recomendando, entonces por más que hay mucho go dando vuelta en la compañía, pero utilizar estas cosas es mucho jable en el lógica de negocios, Python de repente con una capitalía muy grande, apalancado por la máquina de la ring, entonces lo que hicimos hace poco es esta una librería para que los desarrolladores, ahora instancia una librería un res client que es conder todos los detalles de implementación y toda la lógica de negocios relacionada a conectar micro servicios de la compañía y obviamente ya que nos gustaba tanto el interfaz rico, si intentamos hacer algo, realmente parecido. Oúo, hay varios desafíos, toda la comunidad patónica que está trabajando, están muy familiarizadas con rico, entonces no fue solamente hacer una buena interfaz parecida a la de rico, es para esta herramienta, sino que después nos encontramos que todas las herramientas que hay alrededor de rico es como rico es mo, para testiarla nos dejaban de servir, entonces también tuvimos que desarrollar herramientas para testiar nuestro res client que sean parecidas en lo que la comunidad estaba acostumbrada, o sea, no fue trivial de sentarse una, dos semanas y grabía algo, sino que realmente hubo que sentarse, hacer y queñaría, diseñarlo, pensarlo, probarlo ir y volver, y algunas cosas interesantes que sucedieron, hoy por una cuestión de que uno no puede aplicar un cambio masivamente en toda la compañía, porque es muy riesgoso, el res client, nosotros vamos agregando lo que llamamos en jeans, que básicamente empezamos con un rico es en el fondo, que estamos seguro que andaba con sesión, despagaramos un relipter y de a poquito fuimos migrando algunas apicas, usan esta implementación y después anpaiculi, simulos mismos, fuimos migrando, y fue muy interesante ver como equipos hacían los diploi y decían, mira no sé que hicimos, no es súper súper rápidora, nosotros estamos haciendo de a H, me parece que está funcionando esto, pero esto que se lo cuento como chiste es el valor de poder tener herramientas de la compañía que impacten en toda la compañía con un solo cambio, nosotros hacemos una nueva versión de esta librería y estamos impactando en todos los micros servicios que están en Python, que si no lo hubiéramos hecho tendríamos que haber hecho que decía delito que decir che bueno esta línea ahora cambia por esta 70, entonces tomar decisión y diseñar y queñaría es parte de comunicar micros a servicio, no es solamente una cuestión de optimizar la performance. Bueno luego que llevamos con partidos este es un caso de uso propio es parte de lo que lo que nos sirvió, tiene sus prois sus contras, porque ahora esta librería le tiene que mantener a alguien, si el sistema de recomendación en el mercado libre encuentro un bug o una limitación de esta librería obviamente alguien lo tiene que resolver y ese alguien en este caso somos nosotros, entonces de nuevo depende el caso de uso hay que responsabilizarse por las herramientas que hacemos y como dice Rudy los pros son muchísimos, las contras no tantas como para que nos animamos, lo pues la tenemos en marcha. Muchas gracias.',\n",
              " 'segments': [{'id': 0,\n",
              "   'seek': 0,\n",
              "   'start': 0.0,\n",
              "   'end': 24.400000000000002,\n",
              "   'text': ' Bueno, quién soy Rodolfo Edelman, me van a escuchar ahí que me dicen Rudy.',\n",
              "   'tokens': [50364,\n",
              "    16046,\n",
              "    11,\n",
              "    35327,\n",
              "    8812,\n",
              "    11097,\n",
              "    7491,\n",
              "    78,\n",
              "    3977,\n",
              "    338,\n",
              "    1601,\n",
              "    11,\n",
              "    385,\n",
              "    3161,\n",
              "    257,\n",
              "    22483,\n",
              "    289,\n",
              "    12571,\n",
              "    631,\n",
              "    385,\n",
              "    33816,\n",
              "    38690,\n",
              "    13,\n",
              "    51584],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5263050886300894,\n",
              "   'compression_ratio': 0.9382716049382716,\n",
              "   'no_speech_prob': 0.06435789912939072},\n",
              "  {'id': 1,\n",
              "   'seek': 2440,\n",
              "   'start': 24.4,\n",
              "   'end': 32.4,\n",
              "   'text': ' Tiengan cuidado si me llaman Digan Rudy con Deno con B. Larga, porque con Ferencia Python se pueden ojar a alguien.',\n",
              "   'tokens': [50364,\n",
              "    314,\n",
              "    1053,\n",
              "    1275,\n",
              "    31891,\n",
              "    1511,\n",
              "    385,\n",
              "    4849,\n",
              "    6147,\n",
              "    413,\n",
              "    9552,\n",
              "    38690,\n",
              "    416,\n",
              "    6458,\n",
              "    78,\n",
              "    416,\n",
              "    363,\n",
              "    13,\n",
              "    11569,\n",
              "    3680,\n",
              "    11,\n",
              "    4021,\n",
              "    416,\n",
              "    479,\n",
              "    5170,\n",
              "    2755,\n",
              "    15329,\n",
              "    369,\n",
              "    14714,\n",
              "    277,\n",
              "    10150,\n",
              "    257,\n",
              "    25814,\n",
              "    13,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4298181339186065,\n",
              "   'compression_ratio': 1.5363636363636364,\n",
              "   'no_speech_prob': 0.5033178925514221},\n",
              "  {'id': 2,\n",
              "   'seek': 2440,\n",
              "   'start': 33.4,\n",
              "   'end': 39.4,\n",
              "   'text': ' Hace 5 años estoy trabajando con Python antes de trabajar con Ruby, eso no lo voy a contermas.',\n",
              "   'tokens': [50814,\n",
              "    389,\n",
              "    617,\n",
              "    1025,\n",
              "    11424,\n",
              "    15796,\n",
              "    40473,\n",
              "    416,\n",
              "    15329,\n",
              "    11014,\n",
              "    368,\n",
              "    30793,\n",
              "    416,\n",
              "    19907,\n",
              "    11,\n",
              "    7287,\n",
              "    572,\n",
              "    450,\n",
              "    7552,\n",
              "    257,\n",
              "    660,\n",
              "    966,\n",
              "    296,\n",
              "    13,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4298181339186065,\n",
              "   'compression_ratio': 1.5363636363636364,\n",
              "   'no_speech_prob': 0.5033178925514221},\n",
              "  {'id': 3,\n",
              "   'seek': 2440,\n",
              "   'start': 40.4,\n",
              "   'end': 45.4,\n",
              "   'text': ' Trabajé mucho tiempo a la Universidad Nacional de Córdoba, a esa foto en el Cláster de la Universidad Nacional de Córdoba.',\n",
              "   'tokens': [51164,\n",
              "    314,\n",
              "    5305,\n",
              "    1805,\n",
              "    526,\n",
              "    9824,\n",
              "    11772,\n",
              "    257,\n",
              "    635,\n",
              "    14052,\n",
              "    4580,\n",
              "    36623,\n",
              "    368,\n",
              "    41306,\n",
              "    7800,\n",
              "    19481,\n",
              "    11,\n",
              "    257,\n",
              "    11342,\n",
              "    19176,\n",
              "    465,\n",
              "    806,\n",
              "    2033,\n",
              "    842,\n",
              "    3120,\n",
              "    368,\n",
              "    635,\n",
              "    14052,\n",
              "    4580,\n",
              "    36623,\n",
              "    368,\n",
              "    41306,\n",
              "    7800,\n",
              "    19481,\n",
              "    13,\n",
              "    51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4298181339186065,\n",
              "   'compression_ratio': 1.5363636363636364,\n",
              "   'no_speech_prob': 0.5033178925514221},\n",
              "  {'id': 4,\n",
              "   'seek': 4540,\n",
              "   'start': 45.4,\n",
              "   'end': 62.4,\n",
              "   'text': ' Hace mucho de Robots, después abancé a Bakken, de Bakken, empezó a hacer Machine Learning y actualmente estoy como técnica al Manaller en Mercado de Libre, desarrollando productos, servicios internos de la compañía que nos sirven para poner modelos de Machine Learning en producción.',\n",
              "   'tokens': [50364,\n",
              "    389,\n",
              "    617,\n",
              "    9824,\n",
              "    368,\n",
              "    5424,\n",
              "    1971,\n",
              "    11,\n",
              "    15283,\n",
              "    410,\n",
              "    282,\n",
              "    13523,\n",
              "    257,\n",
              "    12063,\n",
              "    2653,\n",
              "    11,\n",
              "    368,\n",
              "    12063,\n",
              "    2653,\n",
              "    11,\n",
              "    18730,\n",
              "    812,\n",
              "    257,\n",
              "    6720,\n",
              "    22155,\n",
              "    15205,\n",
              "    288,\n",
              "    3539,\n",
              "    4082,\n",
              "    15796,\n",
              "    2617,\n",
              "    45411,\n",
              "    419,\n",
              "    2458,\n",
              "    336,\n",
              "    260,\n",
              "    465,\n",
              "    18897,\n",
              "    1573,\n",
              "    368,\n",
              "    15834,\n",
              "    265,\n",
              "    11,\n",
              "    32501,\n",
              "    1806,\n",
              "    46363,\n",
              "    11,\n",
              "    42722,\n",
              "    2154,\n",
              "    329,\n",
              "    368,\n",
              "    635,\n",
              "    29953,\n",
              "    2686,\n",
              "    631,\n",
              "    3269,\n",
              "    4735,\n",
              "    553,\n",
              "    1690,\n",
              "    19149,\n",
              "    2316,\n",
              "    329,\n",
              "    368,\n",
              "    22155,\n",
              "    15205,\n",
              "    465,\n",
              "    48586,\n",
              "    13,\n",
              "    51214],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.49465243917115975,\n",
              "   'compression_ratio': 1.4427860696517414,\n",
              "   'no_speech_prob': 0.15044036507606506},\n",
              "  {'id': 5,\n",
              "   'seek': 6240,\n",
              "   'start': 62.4,\n",
              "   'end': 74.4,\n",
              "   'text': ' Hola, yo soy Litox, Carlos de la Torre, me dicen Litox en la Uroschatz y en las comunidades de Python y en la tele, pero eso todavía no se se llenó nunca.',\n",
              "   'tokens': [50364,\n",
              "    22637,\n",
              "    11,\n",
              "    5290,\n",
              "    8812,\n",
              "    441,\n",
              "    3528,\n",
              "    87,\n",
              "    11,\n",
              "    19646,\n",
              "    368,\n",
              "    635,\n",
              "    7160,\n",
              "    265,\n",
              "    11,\n",
              "    385,\n",
              "    33816,\n",
              "    441,\n",
              "    3528,\n",
              "    87,\n",
              "    465,\n",
              "    635,\n",
              "    624,\n",
              "    2635,\n",
              "    339,\n",
              "    10300,\n",
              "    288,\n",
              "    465,\n",
              "    2439,\n",
              "    11040,\n",
              "    10284,\n",
              "    368,\n",
              "    15329,\n",
              "    288,\n",
              "    465,\n",
              "    635,\n",
              "    4304,\n",
              "    11,\n",
              "    4768,\n",
              "    7287,\n",
              "    28388,\n",
              "    572,\n",
              "    369,\n",
              "    369,\n",
              "    4849,\n",
              "    268,\n",
              "    812,\n",
              "    13768,\n",
              "    13,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.39367282838749706,\n",
              "   'compression_ratio': 1.5533980582524272,\n",
              "   'no_speech_prob': 0.41979941725730896},\n",
              "  {'id': 6,\n",
              "   'seek': 6240,\n",
              "   'start': 75.4,\n",
              "   'end': 91.4,\n",
              "   'text': ' Trabajo con Ruy hace muchos años, también soy técnica al Manaller, tengo un recorrido de su licencia informática y de desarrollador, técnica leader, retabajado en empresas nacionales, en Argentina, en Pymes, pequeñas empresas, ahora en Mercado de Libre estamos como hizo Rudy armando la infraestructura para ejecutar.',\n",
              "   'tokens': [51014,\n",
              "    314,\n",
              "    5305,\n",
              "    13440,\n",
              "    416,\n",
              "    497,\n",
              "    7493,\n",
              "    10032,\n",
              "    17061,\n",
              "    11424,\n",
              "    11,\n",
              "    6407,\n",
              "    8812,\n",
              "    45411,\n",
              "    419,\n",
              "    2458,\n",
              "    336,\n",
              "    260,\n",
              "    11,\n",
              "    13989,\n",
              "    517,\n",
              "    850,\n",
              "    24362,\n",
              "    2925,\n",
              "    368,\n",
              "    459,\n",
              "    6169,\n",
              "    10974,\n",
              "    1356,\n",
              "    23432,\n",
              "    288,\n",
              "    368,\n",
              "    32501,\n",
              "    5409,\n",
              "    11,\n",
              "    45411,\n",
              "    5263,\n",
              "    11,\n",
              "    319,\n",
              "    1328,\n",
              "    9338,\n",
              "    1573,\n",
              "    465,\n",
              "    26433,\n",
              "    29836,\n",
              "    279,\n",
              "    11,\n",
              "    465,\n",
              "    18336,\n",
              "    11,\n",
              "    465,\n",
              "    430,\n",
              "    4199,\n",
              "    279,\n",
              "    11,\n",
              "    19132,\n",
              "    32448,\n",
              "    26433,\n",
              "    11,\n",
              "    9923,\n",
              "    465,\n",
              "    18897,\n",
              "    1573,\n",
              "    368,\n",
              "    15834,\n",
              "    265,\n",
              "    10382,\n",
              "    2617,\n",
              "    28803,\n",
              "    38690,\n",
              "    3726,\n",
              "    1806,\n",
              "    635,\n",
              "    23654,\n",
              "    43056,\n",
              "    2991,\n",
              "    1690,\n",
              "    39564,\n",
              "    6672,\n",
              "    289,\n",
              "    13,\n",
              "    51814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.39367282838749706,\n",
              "   'compression_ratio': 1.5533980582524272,\n",
              "   'no_speech_prob': 0.41979941725730896},\n",
              "  {'id': 7,\n",
              "   'seek': 9240,\n",
              "   'start': 92.4,\n",
              "   'end': 99.4,\n",
              "   'text': ' Machine Learning en producción y a escala. Bueno, queremos entonces contarles un poquito de qué va a ser la charla.',\n",
              "   'tokens': [50364,\n",
              "    22155,\n",
              "    15205,\n",
              "    465,\n",
              "    48586,\n",
              "    288,\n",
              "    257,\n",
              "    4721,\n",
              "    5159,\n",
              "    13,\n",
              "    16046,\n",
              "    11,\n",
              "    26813,\n",
              "    13003,\n",
              "    27045,\n",
              "    904,\n",
              "    517,\n",
              "    28229,\n",
              "    368,\n",
              "    8057,\n",
              "    2773,\n",
              "    257,\n",
              "    816,\n",
              "    635,\n",
              "    1290,\n",
              "    875,\n",
              "    13,\n",
              "    50714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.31025491976270486,\n",
              "   'compression_ratio': 1.537037037037037,\n",
              "   'no_speech_prob': 0.007691541220992804},\n",
              "  {'id': 8,\n",
              "   'seek': 9240,\n",
              "   'start': 101.4,\n",
              "   'end': 110.4,\n",
              "   'text': ' Primero que todos para entender el motivo de la charla tenemos que entender porque creamos microsや servicios, ¿cómo hacemos esto en Python?',\n",
              "   'tokens': [50814,\n",
              "    19671,\n",
              "    2032,\n",
              "    631,\n",
              "    6321,\n",
              "    1690,\n",
              "    20054,\n",
              "    806,\n",
              "    35804,\n",
              "    368,\n",
              "    635,\n",
              "    1290,\n",
              "    875,\n",
              "    9914,\n",
              "    631,\n",
              "    20054,\n",
              "    4021,\n",
              "    1197,\n",
              "    2151,\n",
              "    15547,\n",
              "    7355,\n",
              "    42722,\n",
              "    11,\n",
              "    3841,\n",
              "    46614,\n",
              "    33839,\n",
              "    7433,\n",
              "    465,\n",
              "    15329,\n",
              "    30,\n",
              "    51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.31025491976270486,\n",
              "   'compression_ratio': 1.537037037037037,\n",
              "   'no_speech_prob': 0.007691541220992804},\n",
              "  {'id': 9,\n",
              "   'seek': 9240,\n",
              "   'start': 110.4,\n",
              "   'end': 118.4,\n",
              "   'text': ' Está normalmente, ¿cuáles son los insas que fuimos sacando, teniendo en estos años de desarrollo, un poco eso y algunos casos de uso que vamos a ver.',\n",
              "   'tokens': [51264,\n",
              "    4410,\n",
              "    842,\n",
              "    38217,\n",
              "    11,\n",
              "    3841,\n",
              "    12032,\n",
              "    842,\n",
              "    904,\n",
              "    1872,\n",
              "    1750,\n",
              "    1028,\n",
              "    296,\n",
              "    631,\n",
              "    8536,\n",
              "    8372,\n",
              "    4899,\n",
              "    1806,\n",
              "    11,\n",
              "    2064,\n",
              "    7304,\n",
              "    465,\n",
              "    12585,\n",
              "    11424,\n",
              "    368,\n",
              "    38295,\n",
              "    11,\n",
              "    517,\n",
              "    10639,\n",
              "    7287,\n",
              "    288,\n",
              "    21078,\n",
              "    25135,\n",
              "    368,\n",
              "    22728,\n",
              "    631,\n",
              "    5295,\n",
              "    257,\n",
              "    1306,\n",
              "    13,\n",
              "    51664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.31025491976270486,\n",
              "   'compression_ratio': 1.537037037037037,\n",
              "   'no_speech_prob': 0.007691541220992804},\n",
              "  {'id': 10,\n",
              "   'seek': 11840,\n",
              "   'start': 119.4,\n",
              "   'end': 124.4,\n",
              "   'text': ' Monalito, ¿todo saben qué es monalito? Levanta la mano.',\n",
              "   'tokens': [50414,\n",
              "    4713,\n",
              "    304,\n",
              "    3528,\n",
              "    11,\n",
              "    3841,\n",
              "    83,\n",
              "    17423,\n",
              "    36670,\n",
              "    8057,\n",
              "    785,\n",
              "    1108,\n",
              "    304,\n",
              "    3528,\n",
              "    30,\n",
              "    1456,\n",
              "    5219,\n",
              "    64,\n",
              "    635,\n",
              "    18384,\n",
              "    13,\n",
              "    50664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.29526551564534503,\n",
              "   'compression_ratio': 1.476923076923077,\n",
              "   'no_speech_prob': 0.016391964629292488},\n",
              "  {'id': 11,\n",
              "   'seek': 11840,\n",
              "   'start': 127.4,\n",
              "   'end': 140.4,\n",
              "   'text': ' Normalmente bueno, por accidente. Normalmente una cuando empieza a construir el primer producto, empieza, no quiere hacer algo complejo, quiere empezar por algo que sea fácil de poner en producción rápido para validar una idea.',\n",
              "   'tokens': [50814,\n",
              "    21277,\n",
              "    4082,\n",
              "    11974,\n",
              "    11,\n",
              "    1515,\n",
              "    6398,\n",
              "    68,\n",
              "    13,\n",
              "    21277,\n",
              "    4082,\n",
              "    2002,\n",
              "    7767,\n",
              "    44577,\n",
              "    257,\n",
              "    38445,\n",
              "    806,\n",
              "    12595,\n",
              "    47583,\n",
              "    11,\n",
              "    44577,\n",
              "    11,\n",
              "    572,\n",
              "    23877,\n",
              "    6720,\n",
              "    8655,\n",
              "    44424,\n",
              "    5134,\n",
              "    11,\n",
              "    23877,\n",
              "    31168,\n",
              "    1515,\n",
              "    8655,\n",
              "    631,\n",
              "    4158,\n",
              "    17474,\n",
              "    368,\n",
              "    19149,\n",
              "    465,\n",
              "    48586,\n",
              "    24893,\n",
              "    1690,\n",
              "    7363,\n",
              "    289,\n",
              "    2002,\n",
              "    1558,\n",
              "    13,\n",
              "    51464],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.29526551564534503,\n",
              "   'compression_ratio': 1.476923076923077,\n",
              "   'no_speech_prob': 0.016391964629292488},\n",
              "  {'id': 12,\n",
              "   'seek': 14040,\n",
              "   'start': 141.4,\n",
              "   'end': 148.4,\n",
              "   'text': ' De esta manera es que empezamos a hacer un monalito. En la arquitectura monalito es construcción sobre un solo material.',\n",
              "   'tokens': [50414,\n",
              "    1346,\n",
              "    5283,\n",
              "    13913,\n",
              "    785,\n",
              "    631,\n",
              "    18730,\n",
              "    2151,\n",
              "    257,\n",
              "    6720,\n",
              "    517,\n",
              "    1108,\n",
              "    304,\n",
              "    3528,\n",
              "    13,\n",
              "    2193,\n",
              "    635,\n",
              "    40258,\n",
              "    5739,\n",
              "    2991,\n",
              "    1108,\n",
              "    304,\n",
              "    3528,\n",
              "    785,\n",
              "    12946,\n",
              "    14735,\n",
              "    5473,\n",
              "    517,\n",
              "    6944,\n",
              "    2527,\n",
              "    13,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2465373363691507,\n",
              "   'compression_ratio': 1.5168067226890756,\n",
              "   'no_speech_prob': 0.017695236951112747},\n",
              "  {'id': 13,\n",
              "   'seek': 14040,\n",
              "   'start': 149.4,\n",
              "   'end': 154.4,\n",
              "   'text': ' Se hace una analogía cuando el diseño de software que tiene que ver con un estat tecnológico.',\n",
              "   'tokens': [50814,\n",
              "    1100,\n",
              "    10032,\n",
              "    2002,\n",
              "    16660,\n",
              "    2686,\n",
              "    7767,\n",
              "    806,\n",
              "    3814,\n",
              "    7716,\n",
              "    368,\n",
              "    4722,\n",
              "    631,\n",
              "    7066,\n",
              "    631,\n",
              "    1306,\n",
              "    416,\n",
              "    517,\n",
              "    30883,\n",
              "    20105,\n",
              "    27629,\n",
              "    2789,\n",
              "    13,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2465373363691507,\n",
              "   'compression_ratio': 1.5168067226890756,\n",
              "   'no_speech_prob': 0.017695236951112747},\n",
              "  {'id': 14,\n",
              "   'seek': 14040,\n",
              "   'start': 154.4,\n",
              "   'end': 162.4,\n",
              "   'text': ' El ejeimo en estat tecnológico y construimos sobre ese estat. ¿Qué quiere decir? El ejeimo Python, Django, MySQL y alguna cola de mensajes.',\n",
              "   'tokens': [51064,\n",
              "    2699,\n",
              "    39564,\n",
              "    6934,\n",
              "    465,\n",
              "    30883,\n",
              "    20105,\n",
              "    27629,\n",
              "    2789,\n",
              "    288,\n",
              "    12946,\n",
              "    8372,\n",
              "    5473,\n",
              "    10167,\n",
              "    30883,\n",
              "    13,\n",
              "    3841,\n",
              "    15137,\n",
              "    23877,\n",
              "    10235,\n",
              "    30,\n",
              "    2699,\n",
              "    39564,\n",
              "    6934,\n",
              "    15329,\n",
              "    11,\n",
              "    33464,\n",
              "    17150,\n",
              "    11,\n",
              "    1222,\n",
              "    39934,\n",
              "    288,\n",
              "    20651,\n",
              "    40495,\n",
              "    368,\n",
              "    10923,\n",
              "    29362,\n",
              "    13,\n",
              "    51464],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2465373363691507,\n",
              "   'compression_ratio': 1.5168067226890756,\n",
              "   'no_speech_prob': 0.017695236951112747},\n",
              "  {'id': 15,\n",
              "   'seek': 16240,\n",
              "   'start': 163.4,\n",
              "   'end': 177.4,\n",
              "   'text': ' Pero esto paría producción fantástico. Vamos rápido, pero empiezan a ocurrir problemas. Cuando crece son miles y miles de líneas de códigos y esta línea de códigos se vuelven a complejas, hay una interdependencia.',\n",
              "   'tokens': [50414,\n",
              "    9377,\n",
              "    7433,\n",
              "    971,\n",
              "    2686,\n",
              "    48586,\n",
              "    4115,\n",
              "    44855,\n",
              "    13,\n",
              "    10894,\n",
              "    24893,\n",
              "    11,\n",
              "    4768,\n",
              "    4012,\n",
              "    18812,\n",
              "    282,\n",
              "    257,\n",
              "    26430,\n",
              "    10949,\n",
              "    20720,\n",
              "    13,\n",
              "    21907,\n",
              "    1197,\n",
              "    384,\n",
              "    1872,\n",
              "    6193,\n",
              "    288,\n",
              "    6193,\n",
              "    368,\n",
              "    16118,\n",
              "    716,\n",
              "    296,\n",
              "    368,\n",
              "    40210,\n",
              "    13348,\n",
              "    288,\n",
              "    5283,\n",
              "    37452,\n",
              "    368,\n",
              "    40210,\n",
              "    13348,\n",
              "    369,\n",
              "    20126,\n",
              "    553,\n",
              "    257,\n",
              "    44424,\n",
              "    19221,\n",
              "    11,\n",
              "    4842,\n",
              "    2002,\n",
              "    728,\n",
              "    36763,\n",
              "    10974,\n",
              "    13,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.26554446750217015,\n",
              "   'compression_ratio': 1.62987012987013,\n",
              "   'no_speech_prob': 0.03204371780157089},\n",
              "  {'id': 16,\n",
              "   'seek': 16240,\n",
              "   'start': 177.4,\n",
              "   'end': 191.4,\n",
              "   'text': ' Si queremos modificar una parte seguramente tengamos que tocar otra parte del código o romper cosas, los test son gigantescos y empezamos a encontrarnos con que viene el mano y nos dice che, ahora queremos hacer Machine Learning y nosotros estamos trabajando en God, por ejemplo.',\n",
              "   'tokens': [51114,\n",
              "    4909,\n",
              "    26813,\n",
              "    1072,\n",
              "    25625,\n",
              "    2002,\n",
              "    6975,\n",
              "    22179,\n",
              "    3439,\n",
              "    10370,\n",
              "    2151,\n",
              "    631,\n",
              "    35631,\n",
              "    13623,\n",
              "    6975,\n",
              "    1103,\n",
              "    44195,\n",
              "    277,\n",
              "    7438,\n",
              "    610,\n",
              "    12218,\n",
              "    11,\n",
              "    1750,\n",
              "    1500,\n",
              "    1872,\n",
              "    8741,\n",
              "    9327,\n",
              "    6877,\n",
              "    288,\n",
              "    18730,\n",
              "    2151,\n",
              "    257,\n",
              "    10176,\n",
              "    81,\n",
              "    24979,\n",
              "    416,\n",
              "    631,\n",
              "    19561,\n",
              "    806,\n",
              "    18384,\n",
              "    288,\n",
              "    3269,\n",
              "    10313,\n",
              "    947,\n",
              "    11,\n",
              "    9923,\n",
              "    26813,\n",
              "    6720,\n",
              "    22155,\n",
              "    15205,\n",
              "    288,\n",
              "    13863,\n",
              "    10382,\n",
              "    40473,\n",
              "    465,\n",
              "    1265,\n",
              "    11,\n",
              "    1515,\n",
              "    13358,\n",
              "    13,\n",
              "    51814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.26554446750217015,\n",
              "   'compression_ratio': 1.62987012987013,\n",
              "   'no_speech_prob': 0.03204371780157089},\n",
              "  {'id': 17,\n",
              "   'seek': 19240,\n",
              "   'start': 192.4,\n",
              "   'end': 197.4,\n",
              "   'text': ' Y sabemos que integrar algo de Python dentro de un monolito en God es muy complicado.',\n",
              "   'tokens': [50364,\n",
              "    398,\n",
              "    27200,\n",
              "    631,\n",
              "    3572,\n",
              "    289,\n",
              "    8655,\n",
              "    368,\n",
              "    15329,\n",
              "    10856,\n",
              "    368,\n",
              "    517,\n",
              "    1108,\n",
              "    401,\n",
              "    3528,\n",
              "    465,\n",
              "    1265,\n",
              "    785,\n",
              "    5323,\n",
              "    49850,\n",
              "    13,\n",
              "    50614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.14352378138789423,\n",
              "   'compression_ratio': 1.6349809885931559,\n",
              "   'no_speech_prob': 0.0029342363122850657},\n",
              "  {'id': 18,\n",
              "   'seek': 19240,\n",
              "   'start': 197.4,\n",
              "   'end': 208.4,\n",
              "   'text': ' Entonces por estos motivos es que las compañías cuando crecen y empiezan a hacer software mucho más complejo, empiezan a tomar decisiones de separar este monolito en pequeñas piezas.',\n",
              "   'tokens': [50614,\n",
              "    15097,\n",
              "    1515,\n",
              "    12585,\n",
              "    5426,\n",
              "    329,\n",
              "    785,\n",
              "    631,\n",
              "    2439,\n",
              "    29953,\n",
              "    10025,\n",
              "    7767,\n",
              "    1197,\n",
              "    13037,\n",
              "    288,\n",
              "    4012,\n",
              "    18812,\n",
              "    282,\n",
              "    257,\n",
              "    6720,\n",
              "    4722,\n",
              "    9824,\n",
              "    3573,\n",
              "    44424,\n",
              "    5134,\n",
              "    11,\n",
              "    4012,\n",
              "    18812,\n",
              "    282,\n",
              "    257,\n",
              "    22048,\n",
              "    3537,\n",
              "    279,\n",
              "    368,\n",
              "    3128,\n",
              "    289,\n",
              "    4065,\n",
              "    1108,\n",
              "    401,\n",
              "    3528,\n",
              "    465,\n",
              "    19132,\n",
              "    32448,\n",
              "    1730,\n",
              "    24561,\n",
              "    13,\n",
              "    51164],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.14352378138789423,\n",
              "   'compression_ratio': 1.6349809885931559,\n",
              "   'no_speech_prob': 0.0029342363122850657},\n",
              "  {'id': 19,\n",
              "   'seek': 19240,\n",
              "   'start': 208.4,\n",
              "   'end': 216.4,\n",
              "   'text': ' Estas pequeñas piezas que hoy les llamamos micros servicios, nos dan la inventaja de que podemos elegir el stack que nos interesa para resolver el problema.',\n",
              "   'tokens': [51164,\n",
              "    4410,\n",
              "    296,\n",
              "    19132,\n",
              "    32448,\n",
              "    1730,\n",
              "    24561,\n",
              "    631,\n",
              "    13775,\n",
              "    1512,\n",
              "    16848,\n",
              "    2151,\n",
              "    15547,\n",
              "    42722,\n",
              "    11,\n",
              "    3269,\n",
              "    3277,\n",
              "    635,\n",
              "    7962,\n",
              "    12908,\n",
              "    368,\n",
              "    631,\n",
              "    12234,\n",
              "    14459,\n",
              "    347,\n",
              "    806,\n",
              "    8630,\n",
              "    631,\n",
              "    3269,\n",
              "    728,\n",
              "    13708,\n",
              "    1690,\n",
              "    34480,\n",
              "    806,\n",
              "    12395,\n",
              "    13,\n",
              "    51564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.14352378138789423,\n",
              "   'compression_ratio': 1.6349809885931559,\n",
              "   'no_speech_prob': 0.0029342363122850657},\n",
              "  {'id': 20,\n",
              "   'seek': 21640,\n",
              "   'start': 216.4,\n",
              "   'end': 221.4,\n",
              "   'text': ' O sea el martizo para clavar, el serrucho para cortan madera.',\n",
              "   'tokens': [50364,\n",
              "    422,\n",
              "    4158,\n",
              "    806,\n",
              "    12396,\n",
              "    19055,\n",
              "    1690,\n",
              "    596,\n",
              "    706,\n",
              "    289,\n",
              "    11,\n",
              "    806,\n",
              "    816,\n",
              "    81,\n",
              "    625,\n",
              "    78,\n",
              "    1690,\n",
              "    11278,\n",
              "    282,\n",
              "    5244,\n",
              "    1663,\n",
              "    13,\n",
              "    50614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2195517903282529,\n",
              "   'compression_ratio': 1.639344262295082,\n",
              "   'no_speech_prob': 0.04739801213145256},\n",
              "  {'id': 21,\n",
              "   'seek': 21640,\n",
              "   'start': 221.4,\n",
              "   'end': 228.4,\n",
              "   'text': ' Este imagen que se ve acá, que no se ve mucho detalle, pero son muchos puntitos y muchas líneas azul.',\n",
              "   'tokens': [50614,\n",
              "    16105,\n",
              "    40652,\n",
              "    631,\n",
              "    369,\n",
              "    1241,\n",
              "    23496,\n",
              "    11,\n",
              "    631,\n",
              "    572,\n",
              "    369,\n",
              "    1241,\n",
              "    9824,\n",
              "    1141,\n",
              "    11780,\n",
              "    11,\n",
              "    4768,\n",
              "    1872,\n",
              "    17061,\n",
              "    18212,\n",
              "    11343,\n",
              "    288,\n",
              "    16072,\n",
              "    16118,\n",
              "    716,\n",
              "    296,\n",
              "    39580,\n",
              "    13,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2195517903282529,\n",
              "   'compression_ratio': 1.639344262295082,\n",
              "   'no_speech_prob': 0.04739801213145256},\n",
              "  {'id': 22,\n",
              "   'seek': 21640,\n",
              "   'start': 228.4,\n",
              "   'end': 237.4,\n",
              "   'text': ' Esos puntitos representan micros servicios. Son cada uno de esos puntitos de micros servicios y cada línea azul es una comunicación.',\n",
              "   'tokens': [50964,\n",
              "    2313,\n",
              "    329,\n",
              "    18212,\n",
              "    11343,\n",
              "    2906,\n",
              "    282,\n",
              "    15547,\n",
              "    42722,\n",
              "    13,\n",
              "    5185,\n",
              "    8411,\n",
              "    8526,\n",
              "    368,\n",
              "    22411,\n",
              "    18212,\n",
              "    11343,\n",
              "    368,\n",
              "    15547,\n",
              "    42722,\n",
              "    288,\n",
              "    8411,\n",
              "    37452,\n",
              "    39580,\n",
              "    785,\n",
              "    2002,\n",
              "    31710,\n",
              "    3482,\n",
              "    13,\n",
              "    51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2195517903282529,\n",
              "   'compression_ratio': 1.639344262295082,\n",
              "   'no_speech_prob': 0.04739801213145256},\n",
              "  {'id': 23,\n",
              "   'seek': 23740,\n",
              "   'start': 237.4,\n",
              "   'end': 245.4,\n",
              "   'text': ' Entonces si bien resolvimos problemas de escalidad, resolimos problemas que hay. Ahora tenemos equipo dedicados para los problemas que necesitamos resolver,',\n",
              "   'tokens': [50364,\n",
              "    15097,\n",
              "    1511,\n",
              "    3610,\n",
              "    7923,\n",
              "    85,\n",
              "    8372,\n",
              "    20720,\n",
              "    368,\n",
              "    17871,\n",
              "    4580,\n",
              "    11,\n",
              "    7923,\n",
              "    8372,\n",
              "    20720,\n",
              "    631,\n",
              "    4842,\n",
              "    13,\n",
              "    18840,\n",
              "    9914,\n",
              "    30048,\n",
              "    37071,\n",
              "    4181,\n",
              "    1690,\n",
              "    1750,\n",
              "    20720,\n",
              "    631,\n",
              "    38661,\n",
              "    2151,\n",
              "    34480,\n",
              "    11,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27911153520856585,\n",
              "   'compression_ratio': 1.6653846153846155,\n",
              "   'no_speech_prob': 0.02095353603363037},\n",
              "  {'id': 24,\n",
              "   'seek': 23740,\n",
              "   'start': 245.4,\n",
              "   'end': 251.4,\n",
              "   'text': ' podemos hacer mucho más diplóvimas rápido, se empiezan a aparecer otros problemas, que es el problema de la comunicación.',\n",
              "   'tokens': [50764,\n",
              "    12234,\n",
              "    6720,\n",
              "    9824,\n",
              "    3573,\n",
              "    11432,\n",
              "    812,\n",
              "    85,\n",
              "    17957,\n",
              "    24893,\n",
              "    11,\n",
              "    369,\n",
              "    4012,\n",
              "    18812,\n",
              "    282,\n",
              "    257,\n",
              "    43336,\n",
              "    16422,\n",
              "    20720,\n",
              "    11,\n",
              "    631,\n",
              "    785,\n",
              "    806,\n",
              "    12395,\n",
              "    368,\n",
              "    635,\n",
              "    31710,\n",
              "    3482,\n",
              "    13,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27911153520856585,\n",
              "   'compression_ratio': 1.6653846153846155,\n",
              "   'no_speech_prob': 0.02095353603363037},\n",
              "  {'id': 25,\n",
              "   'seek': 23740,\n",
              "   'start': 251.4,\n",
              "   'end': 258.4,\n",
              "   'text': ' ¿Qué significa? Ante una comunicación era una llamada una función, una llamada un método, era un 2 o 3 ciclo de CPU y ya teníamos una respuesta.',\n",
              "   'tokens': [51064,\n",
              "    3841,\n",
              "    15137,\n",
              "    19957,\n",
              "    30,\n",
              "    5130,\n",
              "    68,\n",
              "    2002,\n",
              "    31710,\n",
              "    3482,\n",
              "    4249,\n",
              "    2002,\n",
              "    16848,\n",
              "    1538,\n",
              "    2002,\n",
              "    43735,\n",
              "    11,\n",
              "    2002,\n",
              "    16848,\n",
              "    1538,\n",
              "    517,\n",
              "    20275,\n",
              "    17423,\n",
              "    11,\n",
              "    4249,\n",
              "    517,\n",
              "    568,\n",
              "    277,\n",
              "    805,\n",
              "    27464,\n",
              "    752,\n",
              "    368,\n",
              "    13199,\n",
              "    288,\n",
              "    2478,\n",
              "    2064,\n",
              "    16275,\n",
              "    2002,\n",
              "    40585,\n",
              "    13,\n",
              "    51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27911153520856585,\n",
              "   'compression_ratio': 1.6653846153846155,\n",
              "   'no_speech_prob': 0.02095353603363037},\n",
              "  {'id': 26,\n",
              "   'seek': 25840,\n",
              "   'start': 258.4,\n",
              "   'end': 267.4,\n",
              "   'text': ' Ahora tenemos un cable de red, una placa de red, tenemos de NS, tenemos un sistema mucho más complejo para poder sacar un mensaje de un micros servicio al otro.',\n",
              "   'tokens': [50364,\n",
              "    18840,\n",
              "    9914,\n",
              "    517,\n",
              "    8220,\n",
              "    368,\n",
              "    2182,\n",
              "    11,\n",
              "    2002,\n",
              "    499,\n",
              "    6628,\n",
              "    368,\n",
              "    2182,\n",
              "    11,\n",
              "    9914,\n",
              "    368,\n",
              "    15943,\n",
              "    11,\n",
              "    9914,\n",
              "    517,\n",
              "    13245,\n",
              "    9824,\n",
              "    3573,\n",
              "    44424,\n",
              "    5134,\n",
              "    1690,\n",
              "    8152,\n",
              "    43823,\n",
              "    517,\n",
              "    10923,\n",
              "    11153,\n",
              "    368,\n",
              "    517,\n",
              "    15547,\n",
              "    43078,\n",
              "    419,\n",
              "    11921,\n",
              "    13,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.26082931246076313,\n",
              "   'compression_ratio': 1.6081081081081081,\n",
              "   'no_speech_prob': 0.38755208253860474},\n",
              "  {'id': 27,\n",
              "   'seek': 25840,\n",
              "   'start': 267.4,\n",
              "   'end': 278.4,\n",
              "   'text': ' Nosotros cuando empezamos a trabajar con Python en mercado de libre fuerte, que empezamos a hacer Machine Learning, nos dimos cuenta que en las performan de todas las APIs o los micros servicios,',\n",
              "   'tokens': [50814,\n",
              "    18749,\n",
              "    11792,\n",
              "    7767,\n",
              "    18730,\n",
              "    2151,\n",
              "    257,\n",
              "    30793,\n",
              "    416,\n",
              "    15329,\n",
              "    465,\n",
              "    24775,\n",
              "    368,\n",
              "    29976,\n",
              "    37129,\n",
              "    11,\n",
              "    631,\n",
              "    18730,\n",
              "    2151,\n",
              "    257,\n",
              "    6720,\n",
              "    22155,\n",
              "    15205,\n",
              "    11,\n",
              "    3269,\n",
              "    5013,\n",
              "    329,\n",
              "    17868,\n",
              "    631,\n",
              "    465,\n",
              "    2439,\n",
              "    2042,\n",
              "    282,\n",
              "    368,\n",
              "    10906,\n",
              "    2439,\n",
              "    21445,\n",
              "    277,\n",
              "    1750,\n",
              "    15547,\n",
              "    42722,\n",
              "    11,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.26082931246076313,\n",
              "   'compression_ratio': 1.6081081081081081,\n",
              "   'no_speech_prob': 0.38755208253860474},\n",
              "  {'id': 28,\n",
              "   'seek': 27840,\n",
              "   'start': 278.4,\n",
              "   'end': 286.4,\n",
              "   'text': ' que hacíamos en Python, no se comparaban con lo que ya estaba hecho un go, por ejemplo. Y pero no tenía mucho sentido porque estábamos haciendo cosas sencillas del principio.',\n",
              "   'tokens': [50364,\n",
              "    631,\n",
              "    46093,\n",
              "    16275,\n",
              "    465,\n",
              "    15329,\n",
              "    11,\n",
              "    572,\n",
              "    369,\n",
              "    6311,\n",
              "    18165,\n",
              "    416,\n",
              "    450,\n",
              "    631,\n",
              "    2478,\n",
              "    17544,\n",
              "    13064,\n",
              "    517,\n",
              "    352,\n",
              "    11,\n",
              "    1515,\n",
              "    13358,\n",
              "    13,\n",
              "    398,\n",
              "    4768,\n",
              "    572,\n",
              "    23718,\n",
              "    9824,\n",
              "    19850,\n",
              "    4021,\n",
              "    3192,\n",
              "    65,\n",
              "    2151,\n",
              "    20509,\n",
              "    12218,\n",
              "    46749,\n",
              "    296,\n",
              "    1103,\n",
              "    34308,\n",
              "    13,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27714826705607964,\n",
              "   'compression_ratio': 1.6708860759493671,\n",
              "   'no_speech_prob': 0.12568050622940063},\n",
              "  {'id': 29,\n",
              "   'seek': 27840,\n",
              "   'start': 286.4,\n",
              "   'end': 291.4,\n",
              "   'text': ' Entonces empezamos a investigar un poquito y hay un poco de esta charla de los insens que sacamos.',\n",
              "   'tokens': [50764,\n",
              "    15097,\n",
              "    18730,\n",
              "    2151,\n",
              "    257,\n",
              "    4557,\n",
              "    289,\n",
              "    517,\n",
              "    28229,\n",
              "    288,\n",
              "    4842,\n",
              "    517,\n",
              "    10639,\n",
              "    368,\n",
              "    5283,\n",
              "    1290,\n",
              "    875,\n",
              "    368,\n",
              "    1750,\n",
              "    1028,\n",
              "    694,\n",
              "    631,\n",
              "    4899,\n",
              "    2151,\n",
              "    13,\n",
              "    51014],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27714826705607964,\n",
              "   'compression_ratio': 1.6708860759493671,\n",
              "   'no_speech_prob': 0.12568050622940063},\n",
              "  {'id': 30,\n",
              "   'seek': 27840,\n",
              "   'start': 291.4,\n",
              "   'end': 299.4,\n",
              "   'text': ' Entonces les queremos contar un poquito que hicimos y en general que se hace para conectar micros servicios con Python.',\n",
              "   'tokens': [51014,\n",
              "    15097,\n",
              "    1512,\n",
              "    26813,\n",
              "    27045,\n",
              "    517,\n",
              "    28229,\n",
              "    631,\n",
              "    23697,\n",
              "    8372,\n",
              "    288,\n",
              "    465,\n",
              "    2674,\n",
              "    631,\n",
              "    369,\n",
              "    10032,\n",
              "    1690,\n",
              "    30458,\n",
              "    289,\n",
              "    15547,\n",
              "    42722,\n",
              "    416,\n",
              "    15329,\n",
              "    13,\n",
              "    51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27714826705607964,\n",
              "   'compression_ratio': 1.6708860759493671,\n",
              "   'no_speech_prob': 0.12568050622940063},\n",
              "  {'id': 31,\n",
              "   'seek': 29940,\n",
              "   'start': 300.4,\n",
              "   'end': 314.4,\n",
              "   'text': ' En realidad conectar micros servicios a este nivel es hacer una llamada HTTP, es hacer un request como el que hace el navegador, cuando no entra una página, hace un request, ha sido un servidor, eso va a vuelve y en la degarlo renériz algo, en nuestro caso, mandamos un mensaje y recibimos una respuesta y trabajamos.',\n",
              "   'tokens': [50414,\n",
              "    2193,\n",
              "    25635,\n",
              "    30458,\n",
              "    289,\n",
              "    15547,\n",
              "    42722,\n",
              "    257,\n",
              "    4065,\n",
              "    24423,\n",
              "    785,\n",
              "    6720,\n",
              "    2002,\n",
              "    16848,\n",
              "    1538,\n",
              "    33283,\n",
              "    11,\n",
              "    785,\n",
              "    6720,\n",
              "    517,\n",
              "    5308,\n",
              "    2617,\n",
              "    806,\n",
              "    631,\n",
              "    10032,\n",
              "    806,\n",
              "    39376,\n",
              "    70,\n",
              "    5409,\n",
              "    11,\n",
              "    7767,\n",
              "    572,\n",
              "    22284,\n",
              "    2002,\n",
              "    36960,\n",
              "    11,\n",
              "    10032,\n",
              "    517,\n",
              "    5308,\n",
              "    11,\n",
              "    324,\n",
              "    14444,\n",
              "    517,\n",
              "    1658,\n",
              "    29718,\n",
              "    11,\n",
              "    7287,\n",
              "    2773,\n",
              "    257,\n",
              "    20126,\n",
              "    303,\n",
              "    288,\n",
              "    465,\n",
              "    635,\n",
              "    368,\n",
              "    2976,\n",
              "    752,\n",
              "    8124,\n",
              "    526,\n",
              "    24959,\n",
              "    8655,\n",
              "    11,\n",
              "    465,\n",
              "    14726,\n",
              "    9666,\n",
              "    11,\n",
              "    7411,\n",
              "    2151,\n",
              "    517,\n",
              "    10923,\n",
              "    11153,\n",
              "    288,\n",
              "    46387,\n",
              "    8372,\n",
              "    2002,\n",
              "    40585,\n",
              "    288,\n",
              "    9618,\n",
              "    2151,\n",
              "    13,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3437791617519884,\n",
              "   'compression_ratio': 1.5560975609756098,\n",
              "   'no_speech_prob': 0.04599738121032715},\n",
              "  {'id': 32,\n",
              "   'seek': 31440,\n",
              "   'start': 315.4,\n",
              "   'end': 327.4,\n",
              "   'text': ' El caso de una arquitectura de micros servicios, cuando nosotros montamos nuestra solución con este diseño, por lo que real corremos en infraestructura de red que está optimizada para esto.',\n",
              "   'tokens': [50414,\n",
              "    2699,\n",
              "    9666,\n",
              "    368,\n",
              "    2002,\n",
              "    40258,\n",
              "    5739,\n",
              "    2991,\n",
              "    368,\n",
              "    15547,\n",
              "    42722,\n",
              "    11,\n",
              "    7767,\n",
              "    13863,\n",
              "    8143,\n",
              "    2151,\n",
              "    16825,\n",
              "    24807,\n",
              "    5687,\n",
              "    416,\n",
              "    4065,\n",
              "    3814,\n",
              "    7716,\n",
              "    11,\n",
              "    1515,\n",
              "    450,\n",
              "    631,\n",
              "    957,\n",
              "    1181,\n",
              "    28343,\n",
              "    465,\n",
              "    23654,\n",
              "    43056,\n",
              "    2991,\n",
              "    368,\n",
              "    2182,\n",
              "    631,\n",
              "    3192,\n",
              "    5028,\n",
              "    39600,\n",
              "    1690,\n",
              "    7433,\n",
              "    13,\n",
              "    51014],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.19010218635934298,\n",
              "   'compression_ratio': 1.7683823529411764,\n",
              "   'no_speech_prob': 0.3804977834224701},\n",
              "  {'id': 33,\n",
              "   'seek': 31440,\n",
              "   'start': 327.4,\n",
              "   'end': 340.4,\n",
              "   'text': ' No es lo mismo yo acá entrando a Google que tengo que atravesar un montón de continentes hasta que llegue el rico, es el servidor y vuelva, cuando yo el mi empresa voy a armar en infraestructura de micros servicios, por lo general voy a intentar que la capa de tráfico, la capa de red,',\n",
              "   'tokens': [51014,\n",
              "    883,\n",
              "    785,\n",
              "    450,\n",
              "    12461,\n",
              "    5290,\n",
              "    23496,\n",
              "    948,\n",
              "    19845,\n",
              "    257,\n",
              "    3329,\n",
              "    631,\n",
              "    13989,\n",
              "    631,\n",
              "    44192,\n",
              "    977,\n",
              "    289,\n",
              "    517,\n",
              "    45259,\n",
              "    368,\n",
              "    1421,\n",
              "    9240,\n",
              "    10764,\n",
              "    631,\n",
              "    11234,\n",
              "    622,\n",
              "    806,\n",
              "    41529,\n",
              "    11,\n",
              "    785,\n",
              "    806,\n",
              "    1658,\n",
              "    29718,\n",
              "    288,\n",
              "    20126,\n",
              "    2757,\n",
              "    11,\n",
              "    7767,\n",
              "    5290,\n",
              "    806,\n",
              "    2752,\n",
              "    22682,\n",
              "    7552,\n",
              "    257,\n",
              "    3726,\n",
              "    289,\n",
              "    465,\n",
              "    23654,\n",
              "    43056,\n",
              "    2991,\n",
              "    368,\n",
              "    15547,\n",
              "    42722,\n",
              "    11,\n",
              "    1515,\n",
              "    450,\n",
              "    2674,\n",
              "    7552,\n",
              "    257,\n",
              "    46596,\n",
              "    631,\n",
              "    635,\n",
              "    1410,\n",
              "    64,\n",
              "    368,\n",
              "    504,\n",
              "    23858,\n",
              "    78,\n",
              "    11,\n",
              "    635,\n",
              "    1410,\n",
              "    64,\n",
              "    368,\n",
              "    2182,\n",
              "    11,\n",
              "    51664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.19010218635934298,\n",
              "   'compression_ratio': 1.7683823529411764,\n",
              "   'no_speech_prob': 0.3804977834224701},\n",
              "  {'id': 34,\n",
              "   'seek': 34040,\n",
              "   'start': 340.4,\n",
              "   'end': 350.4,\n",
              "   'text': ' se ha óptima chica, velos, entonces voy a montar por ejemplo todo en AWS para que el tráfico esté contenido adentro de tráfico de fibra y de backbone, eso es super eficientes.',\n",
              "   'tokens': [50364,\n",
              "    369,\n",
              "    324,\n",
              "    11857,\n",
              "    662,\n",
              "    4775,\n",
              "    417,\n",
              "    2262,\n",
              "    11,\n",
              "    1241,\n",
              "    9389,\n",
              "    11,\n",
              "    13003,\n",
              "    7552,\n",
              "    257,\n",
              "    8143,\n",
              "    289,\n",
              "    1515,\n",
              "    13358,\n",
              "    5149,\n",
              "    465,\n",
              "    17650,\n",
              "    1690,\n",
              "    631,\n",
              "    806,\n",
              "    504,\n",
              "    23858,\n",
              "    78,\n",
              "    34584,\n",
              "    21795,\n",
              "    2925,\n",
              "    614,\n",
              "    317,\n",
              "    340,\n",
              "    368,\n",
              "    504,\n",
              "    23858,\n",
              "    78,\n",
              "    368,\n",
              "    13116,\n",
              "    424,\n",
              "    288,\n",
              "    368,\n",
              "    34889,\n",
              "    11,\n",
              "    7287,\n",
              "    785,\n",
              "    1687,\n",
              "    49510,\n",
              "    20135,\n",
              "    13,\n",
              "    50864],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.29850196838378906,\n",
              "   'compression_ratio': 1.5298245614035089,\n",
              "   'no_speech_prob': 0.06366432458162308},\n",
              "  {'id': 35,\n",
              "   'seek': 34040,\n",
              "   'start': 350.4,\n",
              "   'end': 367.4,\n",
              "   'text': ' Entonces lo que realmente pasa a nivel código pasa hacer relevante, ¿eh? Entonces típicamente que hacemos el mundo Python para hacer un request HTTP, quieren conocer a librería requests, levanten la mano por favor, casi todos bien, perfecto, el 78,29%.',\n",
              "   'tokens': [50864,\n",
              "    15097,\n",
              "    450,\n",
              "    631,\n",
              "    14446,\n",
              "    20260,\n",
              "    257,\n",
              "    24423,\n",
              "    44195,\n",
              "    20260,\n",
              "    6720,\n",
              "    25916,\n",
              "    2879,\n",
              "    11,\n",
              "    3841,\n",
              "    13301,\n",
              "    30,\n",
              "    15097,\n",
              "    256,\n",
              "    28236,\n",
              "    23653,\n",
              "    631,\n",
              "    33839,\n",
              "    806,\n",
              "    7968,\n",
              "    15329,\n",
              "    1690,\n",
              "    6720,\n",
              "    517,\n",
              "    5308,\n",
              "    33283,\n",
              "    11,\n",
              "    36706,\n",
              "    35241,\n",
              "    257,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    12475,\n",
              "    11,\n",
              "    30612,\n",
              "    268,\n",
              "    635,\n",
              "    18384,\n",
              "    1515,\n",
              "    2294,\n",
              "    11,\n",
              "    22567,\n",
              "    6321,\n",
              "    3610,\n",
              "    11,\n",
              "    2176,\n",
              "    78,\n",
              "    11,\n",
              "    806,\n",
              "    26369,\n",
              "    11,\n",
              "    11871,\n",
              "    6856,\n",
              "    51714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.29850196838378906,\n",
              "   'compression_ratio': 1.5298245614035089,\n",
              "   'no_speech_prob': 0.06366432458162308},\n",
              "  {'id': 36,\n",
              "   'seek': 36740,\n",
              "   'start': 368.4,\n",
              "   'end': 380.4,\n",
              "   'text': ' Casi todo, sí, request es lo que se usa en Python y tiene sentido porque la librería request nos abstracte los BMoles, el protocol HTTP, ¿qué significa un request HTTP?',\n",
              "   'tokens': [50414,\n",
              "    383,\n",
              "    8483,\n",
              "    5149,\n",
              "    11,\n",
              "    8600,\n",
              "    11,\n",
              "    5308,\n",
              "    785,\n",
              "    450,\n",
              "    631,\n",
              "    369,\n",
              "    29909,\n",
              "    465,\n",
              "    15329,\n",
              "    288,\n",
              "    7066,\n",
              "    19850,\n",
              "    4021,\n",
              "    635,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    5308,\n",
              "    3269,\n",
              "    12649,\n",
              "    68,\n",
              "    1750,\n",
              "    363,\n",
              "    44,\n",
              "    7456,\n",
              "    11,\n",
              "    806,\n",
              "    10336,\n",
              "    33283,\n",
              "    11,\n",
              "    3841,\n",
              "    16412,\n",
              "    19957,\n",
              "    517,\n",
              "    5308,\n",
              "    33283,\n",
              "    30,\n",
              "    51014],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2883637396843879,\n",
              "   'compression_ratio': 1.4955357142857142,\n",
              "   'no_speech_prob': 0.11579056829214096},\n",
              "  {'id': 37,\n",
              "   'seek': 36740,\n",
              "   'start': 380.4,\n",
              "   'end': 390.4,\n",
              "   'text': ' Hay cierto estrin formateado con un formalismo que tiene que viajar hacia un servidor que lo vas a recibir y que me va a devolver con cierta formalidad o mensaje.',\n",
              "   'tokens': [51014,\n",
              "    8721,\n",
              "    28558,\n",
              "    785,\n",
              "    6903,\n",
              "    259,\n",
              "    1254,\n",
              "    473,\n",
              "    1573,\n",
              "    416,\n",
              "    517,\n",
              "    9860,\n",
              "    6882,\n",
              "    631,\n",
              "    7066,\n",
              "    631,\n",
              "    5766,\n",
              "    10150,\n",
              "    21365,\n",
              "    517,\n",
              "    1658,\n",
              "    29718,\n",
              "    631,\n",
              "    450,\n",
              "    11481,\n",
              "    257,\n",
              "    49703,\n",
              "    288,\n",
              "    631,\n",
              "    385,\n",
              "    2773,\n",
              "    257,\n",
              "    1905,\n",
              "    401,\n",
              "    331,\n",
              "    416,\n",
              "    39769,\n",
              "    1328,\n",
              "    9860,\n",
              "    4580,\n",
              "    277,\n",
              "    10923,\n",
              "    11153,\n",
              "    13,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2883637396843879,\n",
              "   'compression_ratio': 1.4955357142857142,\n",
              "   'no_speech_prob': 0.11579056829214096},\n",
              "  {'id': 38,\n",
              "   'seek': 39040,\n",
              "   'start': 390.4,\n",
              "   'end': 403.4,\n",
              "   'text': ' Eso es un protocolo que se monta sobre un montón de cosas, sobre en particular la red. Entonces por ejemplo que yo quiero en mi aplicación que calcula el tiempo de envío y un paquete, estípicamente voy a depender de otros servicios,',\n",
              "   'tokens': [50364,\n",
              "    27795,\n",
              "    785,\n",
              "    517,\n",
              "    10336,\n",
              "    78,\n",
              "    631,\n",
              "    369,\n",
              "    8143,\n",
              "    64,\n",
              "    5473,\n",
              "    517,\n",
              "    45259,\n",
              "    368,\n",
              "    12218,\n",
              "    11,\n",
              "    5473,\n",
              "    465,\n",
              "    1729,\n",
              "    635,\n",
              "    2182,\n",
              "    13,\n",
              "    15097,\n",
              "    1515,\n",
              "    13358,\n",
              "    631,\n",
              "    5290,\n",
              "    16811,\n",
              "    465,\n",
              "    2752,\n",
              "    18221,\n",
              "    3482,\n",
              "    631,\n",
              "    4322,\n",
              "    64,\n",
              "    806,\n",
              "    11772,\n",
              "    368,\n",
              "    2267,\n",
              "    20492,\n",
              "    288,\n",
              "    517,\n",
              "    2502,\n",
              "    358,\n",
              "    3498,\n",
              "    11,\n",
              "    871,\n",
              "    28236,\n",
              "    23653,\n",
              "    7552,\n",
              "    257,\n",
              "    1367,\n",
              "    3216,\n",
              "    368,\n",
              "    16422,\n",
              "    42722,\n",
              "    11,\n",
              "    51014],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2044623847146636,\n",
              "   'compression_ratio': 1.6942148760330578,\n",
              "   'no_speech_prob': 0.13107554614543915},\n",
              "  {'id': 39,\n",
              "   'seek': 39040,\n",
              "   'start': 403.4,\n",
              "   'end': 412.4,\n",
              "   'text': ' voy a depender de servicios externos, porque yo voy a querer calcular para determinado usuario y determinado producto, bueno, ¿cuánto tal ese producto en llegar a su casa?',\n",
              "   'tokens': [51014,\n",
              "    7552,\n",
              "    257,\n",
              "    1367,\n",
              "    3216,\n",
              "    368,\n",
              "    42722,\n",
              "    30360,\n",
              "    329,\n",
              "    11,\n",
              "    4021,\n",
              "    5290,\n",
              "    7552,\n",
              "    257,\n",
              "    39318,\n",
              "    2104,\n",
              "    17792,\n",
              "    1690,\n",
              "    15957,\n",
              "    1573,\n",
              "    32247,\n",
              "    4912,\n",
              "    288,\n",
              "    15957,\n",
              "    1573,\n",
              "    47583,\n",
              "    11,\n",
              "    11974,\n",
              "    11,\n",
              "    3841,\n",
              "    12032,\n",
              "    27525,\n",
              "    78,\n",
              "    4023,\n",
              "    10167,\n",
              "    47583,\n",
              "    465,\n",
              "    24892,\n",
              "    257,\n",
              "    459,\n",
              "    9022,\n",
              "    30,\n",
              "    51464],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2044623847146636,\n",
              "   'compression_ratio': 1.6942148760330578,\n",
              "   'no_speech_prob': 0.13107554614543915},\n",
              "  {'id': 40,\n",
              "   'seek': 41240,\n",
              "   'start': 412.4,\n",
              "   'end': 427.4,\n",
              "   'text': ' Entonces yo voy a tener que pedirle a la API de direcciones de usuarios que me diga las direcciones de usuario y voy a querer pedir a otro endpoint que es la información de los vendedores, que me de información y después a la información de las direcciones de los vendedores.',\n",
              "   'tokens': [50364,\n",
              "    15097,\n",
              "    5290,\n",
              "    7552,\n",
              "    257,\n",
              "    11640,\n",
              "    631,\n",
              "    33533,\n",
              "    306,\n",
              "    257,\n",
              "    635,\n",
              "    9362,\n",
              "    368,\n",
              "    1264,\n",
              "    35560,\n",
              "    368,\n",
              "    32247,\n",
              "    9720,\n",
              "    631,\n",
              "    385,\n",
              "    2528,\n",
              "    64,\n",
              "    2439,\n",
              "    1264,\n",
              "    35560,\n",
              "    368,\n",
              "    32247,\n",
              "    4912,\n",
              "    288,\n",
              "    7552,\n",
              "    257,\n",
              "    39318,\n",
              "    33533,\n",
              "    257,\n",
              "    11921,\n",
              "    917,\n",
              "    6053,\n",
              "    631,\n",
              "    785,\n",
              "    635,\n",
              "    21660,\n",
              "    368,\n",
              "    1750,\n",
              "    371,\n",
              "    3502,\n",
              "    2706,\n",
              "    11,\n",
              "    631,\n",
              "    385,\n",
              "    368,\n",
              "    21660,\n",
              "    288,\n",
              "    15283,\n",
              "    257,\n",
              "    635,\n",
              "    21660,\n",
              "    368,\n",
              "    2439,\n",
              "    1264,\n",
              "    35560,\n",
              "    368,\n",
              "    1750,\n",
              "    371,\n",
              "    3502,\n",
              "    2706,\n",
              "    13,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20478007223753802,\n",
              "   'compression_ratio': 1.9007936507936507,\n",
              "   'no_speech_prob': 0.1539791375398636},\n",
              "  {'id': 41,\n",
              "   'seek': 41240,\n",
              "   'start': 427.4,\n",
              "   'end': 441.4,\n",
              "   'text': ' Entonces en una esquema de microservicios típicamente vamos a tener una serie de llamadas, una serie de requests a otros servicios, posiblemente aún mismo servicio, yo le quiero pegar muchas veces.',\n",
              "   'tokens': [51114,\n",
              "    15097,\n",
              "    465,\n",
              "    2002,\n",
              "    34611,\n",
              "    5619,\n",
              "    368,\n",
              "    15547,\n",
              "    1978,\n",
              "    26817,\n",
              "    256,\n",
              "    28236,\n",
              "    23653,\n",
              "    5295,\n",
              "    257,\n",
              "    11640,\n",
              "    2002,\n",
              "    23030,\n",
              "    368,\n",
              "    16848,\n",
              "    6872,\n",
              "    11,\n",
              "    2002,\n",
              "    23030,\n",
              "    368,\n",
              "    12475,\n",
              "    257,\n",
              "    16422,\n",
              "    42722,\n",
              "    11,\n",
              "    26644,\n",
              "    4082,\n",
              "    31676,\n",
              "    12461,\n",
              "    43078,\n",
              "    11,\n",
              "    5290,\n",
              "    476,\n",
              "    16811,\n",
              "    22418,\n",
              "    16072,\n",
              "    17054,\n",
              "    13,\n",
              "    51814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20478007223753802,\n",
              "   'compression_ratio': 1.9007936507936507,\n",
              "   'no_speech_prob': 0.1539791375398636},\n",
              "  {'id': 42,\n",
              "   'seek': 44140,\n",
              "   'start': 442.4,\n",
              "   'end': 455.4,\n",
              "   'text': ' Este código cada vez que llegó request ustedes de entrar al mercado libre al marketplace, entre la verulítem y en algún momento le dice por ejemplo cuánto mataró a llegar aproximadamente el sistema a su casa.',\n",
              "   'tokens': [50414,\n",
              "    16105,\n",
              "    44195,\n",
              "    8411,\n",
              "    5715,\n",
              "    631,\n",
              "    46182,\n",
              "    5308,\n",
              "    17110,\n",
              "    368,\n",
              "    20913,\n",
              "    419,\n",
              "    24775,\n",
              "    29976,\n",
              "    419,\n",
              "    19455,\n",
              "    11,\n",
              "    3962,\n",
              "    635,\n",
              "    1306,\n",
              "    425,\n",
              "    6712,\n",
              "    443,\n",
              "    288,\n",
              "    465,\n",
              "    26300,\n",
              "    9333,\n",
              "    476,\n",
              "    10313,\n",
              "    1515,\n",
              "    13358,\n",
              "    44256,\n",
              "    78,\n",
              "    39208,\n",
              "    812,\n",
              "    257,\n",
              "    24892,\n",
              "    48892,\n",
              "    806,\n",
              "    13245,\n",
              "    257,\n",
              "    459,\n",
              "    9022,\n",
              "    13,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3892456236339751,\n",
              "   'compression_ratio': 1.6561085972850678,\n",
              "   'no_speech_prob': 0.010984868742525578},\n",
              "  {'id': 43,\n",
              "   'seek': 44140,\n",
              "   'start': 455.4,\n",
              "   'end': 467.4,\n",
              "   'text': ' Eso significa que con cada rico es que llega al mercado libre, este código se ejecuta y al mercado libre tenemos cientos de miles de ricos por minuto.',\n",
              "   'tokens': [51064,\n",
              "    27795,\n",
              "    19957,\n",
              "    631,\n",
              "    416,\n",
              "    8411,\n",
              "    41529,\n",
              "    785,\n",
              "    631,\n",
              "    40423,\n",
              "    419,\n",
              "    24775,\n",
              "    29976,\n",
              "    11,\n",
              "    4065,\n",
              "    44195,\n",
              "    369,\n",
              "    39564,\n",
              "    6672,\n",
              "    64,\n",
              "    288,\n",
              "    419,\n",
              "    24775,\n",
              "    29976,\n",
              "    9914,\n",
              "    269,\n",
              "    20370,\n",
              "    368,\n",
              "    6193,\n",
              "    368,\n",
              "    367,\n",
              "    9940,\n",
              "    1515,\n",
              "    923,\n",
              "    8262,\n",
              "    13,\n",
              "    51664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3892456236339751,\n",
              "   'compression_ratio': 1.6561085972850678,\n",
              "   'no_speech_prob': 0.010984868742525578},\n",
              "  {'id': 44,\n",
              "   'seek': 46740,\n",
              "   'start': 467.4,\n",
              "   'end': 481.4,\n",
              "   'text': ' Y significa que este endpoint se va a llamar cientos de miles de veces por minuto. Entonces estas llamadas mi microservicio le va a estar pegando los otros microservicios de una manera exponencial con respecto al tráfico que recibo.',\n",
              "   'tokens': [50364,\n",
              "    398,\n",
              "    19957,\n",
              "    631,\n",
              "    4065,\n",
              "    917,\n",
              "    6053,\n",
              "    369,\n",
              "    2773,\n",
              "    257,\n",
              "    16848,\n",
              "    289,\n",
              "    269,\n",
              "    20370,\n",
              "    368,\n",
              "    6193,\n",
              "    368,\n",
              "    17054,\n",
              "    1515,\n",
              "    923,\n",
              "    8262,\n",
              "    13,\n",
              "    15097,\n",
              "    13897,\n",
              "    16848,\n",
              "    6872,\n",
              "    2752,\n",
              "    15547,\n",
              "    1978,\n",
              "    18322,\n",
              "    476,\n",
              "    2773,\n",
              "    257,\n",
              "    8755,\n",
              "    17199,\n",
              "    1806,\n",
              "    1750,\n",
              "    16422,\n",
              "    15547,\n",
              "    1978,\n",
              "    26817,\n",
              "    368,\n",
              "    2002,\n",
              "    13913,\n",
              "    12680,\n",
              "    26567,\n",
              "    416,\n",
              "    35694,\n",
              "    419,\n",
              "    504,\n",
              "    23858,\n",
              "    78,\n",
              "    631,\n",
              "    4214,\n",
              "    1763,\n",
              "    13,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.155615289332503,\n",
              "   'compression_ratio': 1.5129870129870129,\n",
              "   'no_speech_prob': 0.01342442911118269},\n",
              "  {'id': 45,\n",
              "   'seek': 48140,\n",
              "   'start': 481.4,\n",
              "   'end': 490.4,\n",
              "   'text': ' Entonces ¿qué pasa cada vez que yo le pego otro microservicio? ¿Bien esto que en mi computadora se desmejor?',\n",
              "   'tokens': [50364,\n",
              "    15097,\n",
              "    3841,\n",
              "    16412,\n",
              "    20260,\n",
              "    8411,\n",
              "    5715,\n",
              "    631,\n",
              "    5290,\n",
              "    476,\n",
              "    520,\n",
              "    1571,\n",
              "    11921,\n",
              "    15547,\n",
              "    1978,\n",
              "    18322,\n",
              "    30,\n",
              "    3841,\n",
              "    33,\n",
              "    1053,\n",
              "    7433,\n",
              "    631,\n",
              "    465,\n",
              "    2752,\n",
              "    2807,\n",
              "    23020,\n",
              "    369,\n",
              "    730,\n",
              "    1398,\n",
              "    2337,\n",
              "    30,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.24913783073425294,\n",
              "   'compression_ratio': 1.3928571428571428,\n",
              "   'no_speech_prob': 0.2971368730068207},\n",
              "  {'id': 46,\n",
              "   'seek': 48140,\n",
              "   'start': 490.4,\n",
              "   'end': 500.4,\n",
              "   'text': ' Esta tiene que ver más o menos con la explicación del protocolo tcp, la capa de red. ¿Qué pasa cuando yo le envío desde mi cliente a un mensaje al servidor?',\n",
              "   'tokens': [50814,\n",
              "    20547,\n",
              "    7066,\n",
              "    631,\n",
              "    1306,\n",
              "    3573,\n",
              "    277,\n",
              "    8902,\n",
              "    416,\n",
              "    635,\n",
              "    28021,\n",
              "    3482,\n",
              "    1103,\n",
              "    10336,\n",
              "    78,\n",
              "    256,\n",
              "    66,\n",
              "    79,\n",
              "    11,\n",
              "    635,\n",
              "    1410,\n",
              "    64,\n",
              "    368,\n",
              "    2182,\n",
              "    13,\n",
              "    3841,\n",
              "    15137,\n",
              "    20260,\n",
              "    7767,\n",
              "    5290,\n",
              "    476,\n",
              "    2267,\n",
              "    20492,\n",
              "    10188,\n",
              "    2752,\n",
              "    6423,\n",
              "    68,\n",
              "    257,\n",
              "    517,\n",
              "    10923,\n",
              "    11153,\n",
              "    419,\n",
              "    1658,\n",
              "    29718,\n",
              "    30,\n",
              "    51314],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.24913783073425294,\n",
              "   'compression_ratio': 1.3928571428571428,\n",
              "   'no_speech_prob': 0.2971368730068207},\n",
              "  {'id': 47,\n",
              "   'seek': 50040,\n",
              "   'start': 500.4,\n",
              "   'end': 515.4,\n",
              "   'text': ' Se establece una comunicación a nivel red donde primero hay que ir al DNS para ver cuál es la IP del servidor que tiene que llegar porque yo le digo una URL, una string. Entonces da de ese IP tengo que empezar a mandar ciertos mensajes de conexión a ese otro servidor.',\n",
              "   'tokens': [50364,\n",
              "    1100,\n",
              "    37444,\n",
              "    384,\n",
              "    2002,\n",
              "    31710,\n",
              "    3482,\n",
              "    257,\n",
              "    24423,\n",
              "    2182,\n",
              "    10488,\n",
              "    21289,\n",
              "    4842,\n",
              "    631,\n",
              "    3418,\n",
              "    419,\n",
              "    35153,\n",
              "    1690,\n",
              "    1306,\n",
              "    44318,\n",
              "    785,\n",
              "    635,\n",
              "    8671,\n",
              "    1103,\n",
              "    1658,\n",
              "    29718,\n",
              "    631,\n",
              "    7066,\n",
              "    631,\n",
              "    24892,\n",
              "    4021,\n",
              "    5290,\n",
              "    476,\n",
              "    22990,\n",
              "    2002,\n",
              "    12905,\n",
              "    11,\n",
              "    2002,\n",
              "    6798,\n",
              "    13,\n",
              "    15097,\n",
              "    1120,\n",
              "    368,\n",
              "    10167,\n",
              "    8671,\n",
              "    13989,\n",
              "    631,\n",
              "    31168,\n",
              "    257,\n",
              "    48689,\n",
              "    49252,\n",
              "    329,\n",
              "    10923,\n",
              "    29362,\n",
              "    368,\n",
              "    49509,\n",
              "    2560,\n",
              "    257,\n",
              "    10167,\n",
              "    11921,\n",
              "    1658,\n",
              "    29718,\n",
              "    13,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2189527361580495,\n",
              "   'compression_ratio': 1.5847457627118644,\n",
              "   'no_speech_prob': 0.4603361487388611},\n",
              "  {'id': 48,\n",
              "   'seek': 50040,\n",
              "   'start': 515.4,\n",
              "   'end': 520.4,\n",
              "   'text': ' Entonces esos son un montón de mensajes entre mi entre la máquina original y la máquina de destino.',\n",
              "   'tokens': [51114,\n",
              "    15097,\n",
              "    22411,\n",
              "    1872,\n",
              "    517,\n",
              "    45259,\n",
              "    368,\n",
              "    10923,\n",
              "    29362,\n",
              "    3962,\n",
              "    2752,\n",
              "    3962,\n",
              "    635,\n",
              "    49360,\n",
              "    3380,\n",
              "    288,\n",
              "    635,\n",
              "    49360,\n",
              "    368,\n",
              "    2677,\n",
              "    2982,\n",
              "    13,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2189527361580495,\n",
              "   'compression_ratio': 1.5847457627118644,\n",
              "   'no_speech_prob': 0.4603361487388611},\n",
              "  {'id': 49,\n",
              "   'seek': 52040,\n",
              "   'start': 520.4,\n",
              "   'end': 534.4,\n",
              "   'text': ' Le va a tu mensaje para que se conecte y una vez que se conecta tiene que haber si estoy en un esquema de ese cl o de seguridad, hay todo un intercambio de protocolos, asociado a que voy a asegurarme de que está protegida, la conexión, esto se unir y vueltas de mensajes.',\n",
              "   'tokens': [50364,\n",
              "    1456,\n",
              "    2773,\n",
              "    257,\n",
              "    2604,\n",
              "    10923,\n",
              "    11153,\n",
              "    1690,\n",
              "    631,\n",
              "    369,\n",
              "    30458,\n",
              "    68,\n",
              "    288,\n",
              "    2002,\n",
              "    5715,\n",
              "    631,\n",
              "    369,\n",
              "    30458,\n",
              "    64,\n",
              "    7066,\n",
              "    631,\n",
              "    15811,\n",
              "    1511,\n",
              "    15796,\n",
              "    465,\n",
              "    517,\n",
              "    34611,\n",
              "    5619,\n",
              "    368,\n",
              "    10167,\n",
              "    269,\n",
              "    75,\n",
              "    277,\n",
              "    368,\n",
              "    35415,\n",
              "    11,\n",
              "    4842,\n",
              "    5149,\n",
              "    517,\n",
              "    728,\n",
              "    66,\n",
              "    2173,\n",
              "    1004,\n",
              "    368,\n",
              "    10336,\n",
              "    329,\n",
              "    11,\n",
              "    382,\n",
              "    78,\n",
              "    537,\n",
              "    1573,\n",
              "    257,\n",
              "    631,\n",
              "    7552,\n",
              "    257,\n",
              "    38174,\n",
              "    28586,\n",
              "    1398,\n",
              "    368,\n",
              "    631,\n",
              "    3192,\n",
              "    49157,\n",
              "    2887,\n",
              "    11,\n",
              "    635,\n",
              "    49509,\n",
              "    2560,\n",
              "    11,\n",
              "    7433,\n",
              "    369,\n",
              "    517,\n",
              "    347,\n",
              "    288,\n",
              "    9732,\n",
              "    2018,\n",
              "    296,\n",
              "    368,\n",
              "    10923,\n",
              "    29362,\n",
              "    13,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3207605430878789,\n",
              "   'compression_ratio': 1.5511363636363635,\n",
              "   'no_speech_prob': 0.3305797278881073},\n",
              "  {'id': 50,\n",
              "   'seek': 53440,\n",
              "   'start': 534.4,\n",
              "   'end': 552.4,\n",
              "   'text': ' Para que finalmente yo le pueda mandar el payload de mi mensaje, para que fíjense que nosotros en Python le dijimos mandar un get y traer este resultado, internamente que nos resolvió request y hizo toda esta comunicación, mandó el mensaje y cerró la conexión.',\n",
              "   'tokens': [50364,\n",
              "    11107,\n",
              "    631,\n",
              "    35577,\n",
              "    5290,\n",
              "    476,\n",
              "    31907,\n",
              "    48689,\n",
              "    806,\n",
              "    30918,\n",
              "    368,\n",
              "    2752,\n",
              "    10923,\n",
              "    11153,\n",
              "    11,\n",
              "    1690,\n",
              "    631,\n",
              "    283,\n",
              "    870,\n",
              "    73,\n",
              "    1288,\n",
              "    631,\n",
              "    13863,\n",
              "    465,\n",
              "    15329,\n",
              "    476,\n",
              "    47709,\n",
              "    8372,\n",
              "    48689,\n",
              "    517,\n",
              "    483,\n",
              "    288,\n",
              "    944,\n",
              "    260,\n",
              "    4065,\n",
              "    28047,\n",
              "    11,\n",
              "    2154,\n",
              "    3439,\n",
              "    631,\n",
              "    3269,\n",
              "    7923,\n",
              "    4917,\n",
              "    812,\n",
              "    5308,\n",
              "    288,\n",
              "    28803,\n",
              "    11687,\n",
              "    5283,\n",
              "    31710,\n",
              "    3482,\n",
              "    11,\n",
              "    7411,\n",
              "    812,\n",
              "    806,\n",
              "    10923,\n",
              "    11153,\n",
              "    288,\n",
              "    10146,\n",
              "    11721,\n",
              "    635,\n",
              "    49509,\n",
              "    2560,\n",
              "    13,\n",
              "    51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.23625053576569058,\n",
              "   'compression_ratio': 1.52,\n",
              "   'no_speech_prob': 0.5187823176383972},\n",
              "  {'id': 51,\n",
              "   'seek': 55240,\n",
              "   'start': 553.4,\n",
              "   'end': 561.4,\n",
              "   'text': ' Y eso lo hizo cada vez resolución de DNS, ese se conectó, ese cl, le mandó el payload y la cerró.',\n",
              "   'tokens': [50414,\n",
              "    398,\n",
              "    7287,\n",
              "    450,\n",
              "    28803,\n",
              "    8411,\n",
              "    5715,\n",
              "    7923,\n",
              "    30813,\n",
              "    368,\n",
              "    35153,\n",
              "    11,\n",
              "    10167,\n",
              "    369,\n",
              "    30458,\n",
              "    812,\n",
              "    11,\n",
              "    10167,\n",
              "    269,\n",
              "    75,\n",
              "    11,\n",
              "    476,\n",
              "    7411,\n",
              "    812,\n",
              "    806,\n",
              "    30918,\n",
              "    288,\n",
              "    635,\n",
              "    10146,\n",
              "    11721,\n",
              "    13,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.30930328369140625,\n",
              "   'compression_ratio': 1.6178861788617886,\n",
              "   'no_speech_prob': 0.14995577931404114},\n",
              "  {'id': 52,\n",
              "   'seek': 55240,\n",
              "   'start': 561.4,\n",
              "   'end': 566.4,\n",
              "   'text': ' Con cada vez y los cientos de miles de veces que yo me conecto con el otro servidor, request aseto.',\n",
              "   'tokens': [50814,\n",
              "    2656,\n",
              "    8411,\n",
              "    5715,\n",
              "    288,\n",
              "    1750,\n",
              "    269,\n",
              "    20370,\n",
              "    368,\n",
              "    6193,\n",
              "    368,\n",
              "    17054,\n",
              "    631,\n",
              "    5290,\n",
              "    385,\n",
              "    30458,\n",
              "    78,\n",
              "    416,\n",
              "    806,\n",
              "    11921,\n",
              "    1658,\n",
              "    29718,\n",
              "    11,\n",
              "    5308,\n",
              "    382,\n",
              "    19515,\n",
              "    13,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.30930328369140625,\n",
              "   'compression_ratio': 1.6178861788617886,\n",
              "   'no_speech_prob': 0.14995577931404114},\n",
              "  {'id': 53,\n",
              "   'seek': 55240,\n",
              "   'start': 566.4,\n",
              "   'end': 570.4,\n",
              "   'text': ' Porque bueno, porque el que se hace es fácil, con muy poco, hace mucho.',\n",
              "   'tokens': [51064,\n",
              "    11287,\n",
              "    11974,\n",
              "    11,\n",
              "    4021,\n",
              "    806,\n",
              "    631,\n",
              "    369,\n",
              "    10032,\n",
              "    785,\n",
              "    17474,\n",
              "    11,\n",
              "    416,\n",
              "    5323,\n",
              "    10639,\n",
              "    11,\n",
              "    10032,\n",
              "    9824,\n",
              "    13,\n",
              "    51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.30930328369140625,\n",
              "   'compression_ratio': 1.6178861788617886,\n",
              "   'no_speech_prob': 0.14995577931404114},\n",
              "  {'id': 54,\n",
              "   'seek': 55240,\n",
              "   'start': 570.4,\n",
              "   'end': 575.4,\n",
              "   'text': ' Ahora yo estoy en una esquema de micro-serizo, yo voy a conectar muchas veces con el mismo servidor, era un esquema seguro.',\n",
              "   'tokens': [51264,\n",
              "    18840,\n",
              "    5290,\n",
              "    15796,\n",
              "    465,\n",
              "    2002,\n",
              "    34611,\n",
              "    5619,\n",
              "    368,\n",
              "    4532,\n",
              "    12,\n",
              "    12484,\n",
              "    19055,\n",
              "    11,\n",
              "    5290,\n",
              "    7552,\n",
              "    257,\n",
              "    30458,\n",
              "    289,\n",
              "    16072,\n",
              "    17054,\n",
              "    416,\n",
              "    806,\n",
              "    12461,\n",
              "    1658,\n",
              "    29718,\n",
              "    11,\n",
              "    4249,\n",
              "    517,\n",
              "    34611,\n",
              "    5619,\n",
              "    31424,\n",
              "    13,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.30930328369140625,\n",
              "   'compression_ratio': 1.6178861788617886,\n",
              "   'no_speech_prob': 0.14995577931404114},\n",
              "  {'id': 55,\n",
              "   'seek': 57540,\n",
              "   'start': 576.4,\n",
              "   'end': 583.4,\n",
              "   'text': ' Yo no quisiera estar abriendo y cerrando esta conexión cada vez, yo no quisiera estar intercambiando, certificado, ese cl.',\n",
              "   'tokens': [50414,\n",
              "    7616,\n",
              "    572,\n",
              "    37945,\n",
              "    10609,\n",
              "    8755,\n",
              "    410,\n",
              "    470,\n",
              "    3999,\n",
              "    288,\n",
              "    10146,\n",
              "    19845,\n",
              "    5283,\n",
              "    49509,\n",
              "    2560,\n",
              "    8411,\n",
              "    5715,\n",
              "    11,\n",
              "    5290,\n",
              "    572,\n",
              "    37945,\n",
              "    10609,\n",
              "    8755,\n",
              "    728,\n",
              "    66,\n",
              "    2173,\n",
              "    72,\n",
              "    1806,\n",
              "    11,\n",
              "    12378,\n",
              "    1573,\n",
              "    11,\n",
              "    10167,\n",
              "    269,\n",
              "    75,\n",
              "    13,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2433231816147313,\n",
              "   'compression_ratio': 1.462962962962963,\n",
              "   'no_speech_prob': 0.07473964244127274},\n",
              "  {'id': 56,\n",
              "   'seek': 57540,\n",
              "   'start': 583.4,\n",
              "   'end': 590.4,\n",
              "   'text': ' Entonces en realidad yo me gustaría quedarme con una partecita muy chiquita todo lo que está haciendo, request.',\n",
              "   'tokens': [50764,\n",
              "    15097,\n",
              "    465,\n",
              "    25635,\n",
              "    5290,\n",
              "    385,\n",
              "    45896,\n",
              "    13617,\n",
              "    35890,\n",
              "    416,\n",
              "    2002,\n",
              "    6975,\n",
              "    66,\n",
              "    2786,\n",
              "    5323,\n",
              "    417,\n",
              "    3221,\n",
              "    2786,\n",
              "    5149,\n",
              "    450,\n",
              "    631,\n",
              "    3192,\n",
              "    20509,\n",
              "    11,\n",
              "    5308,\n",
              "    13,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2433231816147313,\n",
              "   'compression_ratio': 1.462962962962963,\n",
              "   'no_speech_prob': 0.07473964244127274},\n",
              "  {'id': 57,\n",
              "   'seek': 59040,\n",
              "   'start': 591.4,\n",
              "   'end': 599.4,\n",
              "   'text': ' Entonces la librería request con muy poco me permite ganar esa optimización.',\n",
              "   'tokens': [50414,\n",
              "    15097,\n",
              "    635,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    5308,\n",
              "    416,\n",
              "    5323,\n",
              "    10639,\n",
              "    385,\n",
              "    31105,\n",
              "    7574,\n",
              "    289,\n",
              "    11342,\n",
              "    5028,\n",
              "    27603,\n",
              "    13,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2375893539257264,\n",
              "   'compression_ratio': 1.63135593220339,\n",
              "   'no_speech_prob': 0.3103140592575073},\n",
              "  {'id': 58,\n",
              "   'seek': 59040,\n",
              "   'start': 599.4,\n",
              "   'end': 609.4,\n",
              "   'text': ' Uno tiene que leer la documentación de request, tiene que pasar del getting start, de quick start de request y empezar a ver los features como en todas las librerías que estamos usando en general.',\n",
              "   'tokens': [50814,\n",
              "    37468,\n",
              "    7066,\n",
              "    631,\n",
              "    34172,\n",
              "    635,\n",
              "    4166,\n",
              "    3482,\n",
              "    368,\n",
              "    5308,\n",
              "    11,\n",
              "    7066,\n",
              "    631,\n",
              "    25344,\n",
              "    1103,\n",
              "    1242,\n",
              "    722,\n",
              "    11,\n",
              "    368,\n",
              "    1702,\n",
              "    722,\n",
              "    368,\n",
              "    5308,\n",
              "    288,\n",
              "    31168,\n",
              "    257,\n",
              "    1306,\n",
              "    1750,\n",
              "    4122,\n",
              "    2617,\n",
              "    465,\n",
              "    10906,\n",
              "    2439,\n",
              "    4939,\n",
              "    260,\n",
              "    10025,\n",
              "    631,\n",
              "    10382,\n",
              "    29798,\n",
              "    465,\n",
              "    2674,\n",
              "    13,\n",
              "    51314],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2375893539257264,\n",
              "   'compression_ratio': 1.63135593220339,\n",
              "   'no_speech_prob': 0.3103140592575073},\n",
              "  {'id': 59,\n",
              "   'seek': 59040,\n",
              "   'start': 609.4,\n",
              "   'end': 614.4,\n",
              "   'text': ' Tenemos un quick start pero después tenemos que ver cuáles son los parámetros un poquito más avanzados.',\n",
              "   'tokens': [51314,\n",
              "    44903,\n",
              "    517,\n",
              "    1702,\n",
              "    722,\n",
              "    4768,\n",
              "    15283,\n",
              "    9914,\n",
              "    631,\n",
              "    1306,\n",
              "    2702,\n",
              "    842,\n",
              "    904,\n",
              "    1872,\n",
              "    1750,\n",
              "    971,\n",
              "    842,\n",
              "    29570,\n",
              "    517,\n",
              "    28229,\n",
              "    3573,\n",
              "    42444,\n",
              "    4181,\n",
              "    13,\n",
              "    51564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2375893539257264,\n",
              "   'compression_ratio': 1.63135593220339,\n",
              "   'no_speech_prob': 0.3103140592575073},\n",
              "  {'id': 60,\n",
              "   'seek': 61440,\n",
              "   'start': 615.4,\n",
              "   'end': 621.4,\n",
              "   'text': ' Fíjense que con muy pocos cambios, yo request le puedo decir no quiero usar la de top level, request le digo che de alguna sesión.',\n",
              "   'tokens': [50414,\n",
              "    479,\n",
              "    870,\n",
              "    73,\n",
              "    1288,\n",
              "    631,\n",
              "    416,\n",
              "    5323,\n",
              "    714,\n",
              "    6877,\n",
              "    18751,\n",
              "    2717,\n",
              "    11,\n",
              "    5290,\n",
              "    5308,\n",
              "    476,\n",
              "    21612,\n",
              "    10235,\n",
              "    572,\n",
              "    16811,\n",
              "    14745,\n",
              "    635,\n",
              "    368,\n",
              "    1192,\n",
              "    1496,\n",
              "    11,\n",
              "    5308,\n",
              "    476,\n",
              "    22990,\n",
              "    947,\n",
              "    368,\n",
              "    20651,\n",
              "    5385,\n",
              "    2560,\n",
              "    13,\n",
              "    50714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3086246762956892,\n",
              "   'compression_ratio': 1.657243816254417,\n",
              "   'no_speech_prob': 0.02973751723766327},\n",
              "  {'id': 61,\n",
              "   'seek': 61440,\n",
              "   'start': 621.4,\n",
              "   'end': 622.4,\n",
              "   'text': ' Che.',\n",
              "   'tokens': [50714, 3351, 13, 50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3086246762956892,\n",
              "   'compression_ratio': 1.657243816254417,\n",
              "   'no_speech_prob': 0.02973751723766327},\n",
              "  {'id': 62,\n",
              "   'seek': 61440,\n",
              "   'start': 622.4,\n",
              "   'end': 623.4,\n",
              "   'text': ' Bueno, no sé.',\n",
              "   'tokens': [50764, 16046, 11, 572, 7910, 13, 50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3086246762956892,\n",
              "   'compression_ratio': 1.657243816254417,\n",
              "   'no_speech_prob': 0.02973751723766327},\n",
              "  {'id': 63,\n",
              "   'seek': 61440,\n",
              "   'start': 623.4,\n",
              "   'end': 624.4,\n",
              "   'text': ' Hola.',\n",
              "   'tokens': [50814, 22637, 13, 50864],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3086246762956892,\n",
              "   'compression_ratio': 1.657243816254417,\n",
              "   'no_speech_prob': 0.02973751723766327},\n",
              "  {'id': 64,\n",
              "   'seek': 61440,\n",
              "   'start': 624.4,\n",
              "   'end': 625.4,\n",
              "   'text': ' Riqueste.',\n",
              "   'tokens': [50864, 497, 3221, 8887, 13, 50914],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3086246762956892,\n",
              "   'compression_ratio': 1.657243816254417,\n",
              "   'no_speech_prob': 0.02973751723766327},\n",
              "  {'id': 65,\n",
              "   'seek': 61440,\n",
              "   'start': 625.4,\n",
              "   'end': 626.4,\n",
              "   'text': ' La buena sesión.',\n",
              "   'tokens': [50914, 2369, 25710, 5385, 2560, 13, 50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3086246762956892,\n",
              "   'compression_ratio': 1.657243816254417,\n",
              "   'no_speech_prob': 0.02973751723766327},\n",
              "  {'id': 66,\n",
              "   'seek': 61440,\n",
              "   'start': 626.4,\n",
              "   'end': 628.4,\n",
              "   'text': ' Y después yo puedo usar esa sesión.',\n",
              "   'tokens': [50964,\n",
              "    398,\n",
              "    15283,\n",
              "    5290,\n",
              "    21612,\n",
              "    14745,\n",
              "    11342,\n",
              "    5385,\n",
              "    2560,\n",
              "    13,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3086246762956892,\n",
              "   'compression_ratio': 1.657243816254417,\n",
              "   'no_speech_prob': 0.02973751723766327},\n",
              "  {'id': 67,\n",
              "   'seek': 61440,\n",
              "   'start': 628.4,\n",
              "   'end': 631.4,\n",
              "   'text': ' Esa sesión significa justamente ganar todas esas optimizaciones.',\n",
              "   'tokens': [51064,\n",
              "    2313,\n",
              "    64,\n",
              "    5385,\n",
              "    2560,\n",
              "    19957,\n",
              "    41056,\n",
              "    7574,\n",
              "    289,\n",
              "    10906,\n",
              "    23388,\n",
              "    5028,\n",
              "    590,\n",
              "    9188,\n",
              "    13,\n",
              "    51214],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3086246762956892,\n",
              "   'compression_ratio': 1.657243816254417,\n",
              "   'no_speech_prob': 0.02973751723766327},\n",
              "  {'id': 68,\n",
              "   'seek': 61440,\n",
              "   'start': 631.4,\n",
              "   'end': 637.4,\n",
              "   'text': ' Riquest establece una sesión de comunicación con un servidor y ya mantiene abierta la conexión.',\n",
              "   'tokens': [51214,\n",
              "    497,\n",
              "    3221,\n",
              "    377,\n",
              "    37444,\n",
              "    384,\n",
              "    2002,\n",
              "    5385,\n",
              "    2560,\n",
              "    368,\n",
              "    31710,\n",
              "    3482,\n",
              "    416,\n",
              "    517,\n",
              "    1658,\n",
              "    29718,\n",
              "    288,\n",
              "    2478,\n",
              "    10845,\n",
              "    10174,\n",
              "    410,\n",
              "    811,\n",
              "    1328,\n",
              "    635,\n",
              "    49509,\n",
              "    2560,\n",
              "    13,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3086246762956892,\n",
              "   'compression_ratio': 1.657243816254417,\n",
              "   'no_speech_prob': 0.02973751723766327},\n",
              "  {'id': 69,\n",
              "   'seek': 61440,\n",
              "   'start': 637.4,\n",
              "   'end': 641.4,\n",
              "   'text': ' Entonces yo después cada vez que mando un mensaje solamente envía el payload.',\n",
              "   'tokens': [51514,\n",
              "    15097,\n",
              "    5290,\n",
              "    15283,\n",
              "    8411,\n",
              "    5715,\n",
              "    631,\n",
              "    7411,\n",
              "    78,\n",
              "    517,\n",
              "    10923,\n",
              "    11153,\n",
              "    27814,\n",
              "    2267,\n",
              "    2686,\n",
              "    806,\n",
              "    30918,\n",
              "    13,\n",
              "    51714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3086246762956892,\n",
              "   'compression_ratio': 1.657243816254417,\n",
              "   'no_speech_prob': 0.02973751723766327},\n",
              "  {'id': 70,\n",
              "   'seek': 64140,\n",
              "   'start': 642.4,\n",
              "   'end': 645.4,\n",
              "   'text': ' Para ahí agrego algo, esto está escalando.',\n",
              "   'tokens': [50414,\n",
              "    11107,\n",
              "    12571,\n",
              "    623,\n",
              "    3375,\n",
              "    78,\n",
              "    8655,\n",
              "    11,\n",
              "    7433,\n",
              "    3192,\n",
              "    17871,\n",
              "    1806,\n",
              "    13,\n",
              "    50564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2755996834518563,\n",
              "   'compression_ratio': 1.608695652173913,\n",
              "   'no_speech_prob': 0.06271471828222275},\n",
              "  {'id': 71,\n",
              "   'seek': 64140,\n",
              "   'start': 645.4,\n",
              "   'end': 652.4,\n",
              "   'text': ' Que realmente cuando uno hace micro servicio el payload es una ID, es un string, es muy chiquito, no estás pasando un imagen de dos digas.',\n",
              "   'tokens': [50564,\n",
              "    4493,\n",
              "    14446,\n",
              "    7767,\n",
              "    8526,\n",
              "    10032,\n",
              "    4532,\n",
              "    43078,\n",
              "    806,\n",
              "    30918,\n",
              "    785,\n",
              "    2002,\n",
              "    7348,\n",
              "    11,\n",
              "    785,\n",
              "    517,\n",
              "    6798,\n",
              "    11,\n",
              "    785,\n",
              "    5323,\n",
              "    417,\n",
              "    3221,\n",
              "    3528,\n",
              "    11,\n",
              "    572,\n",
              "    24389,\n",
              "    45412,\n",
              "    517,\n",
              "    40652,\n",
              "    368,\n",
              "    4491,\n",
              "    2528,\n",
              "    296,\n",
              "    13,\n",
              "    50914],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2755996834518563,\n",
              "   'compression_ratio': 1.608695652173913,\n",
              "   'no_speech_prob': 0.06271471828222275},\n",
              "  {'id': 72,\n",
              "   'seek': 64140,\n",
              "   'start': 652.4,\n",
              "   'end': 661.4,\n",
              "   'text': ' Entonces es realmente es muchísimo lo que uno gana si puede hacer use of optimo de los tiempos esto que estamos haciendo.',\n",
              "   'tokens': [50914,\n",
              "    15097,\n",
              "    785,\n",
              "    14446,\n",
              "    785,\n",
              "    44722,\n",
              "    450,\n",
              "    631,\n",
              "    8526,\n",
              "    290,\n",
              "    2095,\n",
              "    1511,\n",
              "    8919,\n",
              "    6720,\n",
              "    764,\n",
              "    295,\n",
              "    5028,\n",
              "    78,\n",
              "    368,\n",
              "    1750,\n",
              "    7582,\n",
              "    2455,\n",
              "    329,\n",
              "    7433,\n",
              "    631,\n",
              "    10382,\n",
              "    20509,\n",
              "    13,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2755996834518563,\n",
              "   'compression_ratio': 1.608695652173913,\n",
              "   'no_speech_prob': 0.06271471828222275},\n",
              "  {'id': 73,\n",
              "   'seek': 64140,\n",
              "   'start': 663.4,\n",
              "   'end': 670.4,\n",
              "   'text': ' Y si yo lo único que voy a hacer en aplicaciones, una vez por ahora peguirle algo a Google y volver, no esté queriendo activizar esto.',\n",
              "   'tokens': [51464,\n",
              "    398,\n",
              "    1511,\n",
              "    5290,\n",
              "    450,\n",
              "    26113,\n",
              "    631,\n",
              "    7552,\n",
              "    257,\n",
              "    6720,\n",
              "    465,\n",
              "    18221,\n",
              "    9188,\n",
              "    11,\n",
              "    2002,\n",
              "    5715,\n",
              "    1515,\n",
              "    9923,\n",
              "    520,\n",
              "    2794,\n",
              "    347,\n",
              "    306,\n",
              "    8655,\n",
              "    257,\n",
              "    3329,\n",
              "    288,\n",
              "    33998,\n",
              "    11,\n",
              "    572,\n",
              "    34584,\n",
              "    7083,\n",
              "    7304,\n",
              "    2430,\n",
              "    9736,\n",
              "    7433,\n",
              "    13,\n",
              "    51814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2755996834518563,\n",
              "   'compression_ratio': 1.608695652173913,\n",
              "   'no_speech_prob': 0.06271471828222275},\n",
              "  {'id': 74,\n",
              "   'seek': 67040,\n",
              "   'start': 670.4,\n",
              "   'end': 679.4,\n",
              "   'text': ' Y luego pensemos en la escala en la que mi arquitectura entera los miles de ricos que atiendo por segundo se transforman en cientos de miles de ricos adentro de mis istevas.',\n",
              "   'tokens': [50364,\n",
              "    398,\n",
              "    17222,\n",
              "    11209,\n",
              "    3415,\n",
              "    465,\n",
              "    635,\n",
              "    4721,\n",
              "    5159,\n",
              "    465,\n",
              "    635,\n",
              "    631,\n",
              "    2752,\n",
              "    40258,\n",
              "    5739,\n",
              "    2991,\n",
              "    948,\n",
              "    1663,\n",
              "    1750,\n",
              "    6193,\n",
              "    368,\n",
              "    367,\n",
              "    9940,\n",
              "    631,\n",
              "    412,\n",
              "    1174,\n",
              "    78,\n",
              "    1515,\n",
              "    17954,\n",
              "    369,\n",
              "    4088,\n",
              "    282,\n",
              "    465,\n",
              "    269,\n",
              "    20370,\n",
              "    368,\n",
              "    6193,\n",
              "    368,\n",
              "    367,\n",
              "    9940,\n",
              "    614,\n",
              "    317,\n",
              "    340,\n",
              "    368,\n",
              "    3346,\n",
              "    1418,\n",
              "    68,\n",
              "    7967,\n",
              "    13,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2801634335348792,\n",
              "   'compression_ratio': 1.778181818181818,\n",
              "   'no_speech_prob': 0.02095211111009121},\n",
              "  {'id': 75,\n",
              "   'seek': 67040,\n",
              "   'start': 679.4,\n",
              "   'end': 686.4,\n",
              "   'text': ' Cada mil y segundo que yo le gane va a ser un mil y segundo menos de cómputo, mil y segundo menos de tráfico y eso se transforma por lo que creen costos.',\n",
              "   'tokens': [50814,\n",
              "    38603,\n",
              "    1962,\n",
              "    288,\n",
              "    17954,\n",
              "    631,\n",
              "    5290,\n",
              "    476,\n",
              "    290,\n",
              "    1929,\n",
              "    2773,\n",
              "    257,\n",
              "    816,\n",
              "    517,\n",
              "    1962,\n",
              "    288,\n",
              "    17954,\n",
              "    8902,\n",
              "    368,\n",
              "    6333,\n",
              "    2455,\n",
              "    8262,\n",
              "    11,\n",
              "    1962,\n",
              "    288,\n",
              "    17954,\n",
              "    8902,\n",
              "    368,\n",
              "    504,\n",
              "    23858,\n",
              "    78,\n",
              "    288,\n",
              "    7287,\n",
              "    369,\n",
              "    4088,\n",
              "    64,\n",
              "    1515,\n",
              "    450,\n",
              "    631,\n",
              "    1197,\n",
              "    268,\n",
              "    2063,\n",
              "    329,\n",
              "    13,\n",
              "    51164],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2801634335348792,\n",
              "   'compression_ratio': 1.778181818181818,\n",
              "   'no_speech_prob': 0.02095211111009121},\n",
              "  {'id': 76,\n",
              "   'seek': 67040,\n",
              "   'start': 686.4,\n",
              "   'end': 688.4,\n",
              "   'text': ' Bien, el mejor es en costos.',\n",
              "   'tokens': [51164, 16956, 11, 806, 11479, 785, 465, 2063, 329, 13, 51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2801634335348792,\n",
              "   'compression_ratio': 1.778181818181818,\n",
              "   'no_speech_prob': 0.02095211111009121},\n",
              "  {'id': 77,\n",
              "   'seek': 67040,\n",
              "   'start': 688.4,\n",
              "   'end': 697.4,\n",
              "   'text': ' Entonces los otros vivimos que se estaba usando de forma naive, Riquest, trabajamos con múltiples equipos entre la organización.',\n",
              "   'tokens': [51264,\n",
              "    15097,\n",
              "    1750,\n",
              "    16422,\n",
              "    11005,\n",
              "    8372,\n",
              "    631,\n",
              "    369,\n",
              "    17544,\n",
              "    29798,\n",
              "    368,\n",
              "    8366,\n",
              "    29052,\n",
              "    11,\n",
              "    497,\n",
              "    3221,\n",
              "    377,\n",
              "    11,\n",
              "    9618,\n",
              "    2151,\n",
              "    416,\n",
              "    275,\n",
              "    43447,\n",
              "    72,\n",
              "    2622,\n",
              "    5037,\n",
              "    329,\n",
              "    3962,\n",
              "    635,\n",
              "    4645,\n",
              "    3482,\n",
              "    13,\n",
              "    51714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2801634335348792,\n",
              "   'compression_ratio': 1.778181818181818,\n",
              "   'no_speech_prob': 0.02095211111009121},\n",
              "  {'id': 78,\n",
              "   'seek': 69740,\n",
              "   'start': 697.4,\n",
              "   'end': 707.4,\n",
              "   'text': ' Veamos que estaban usando Riquest así no más como Quick Start y hicimos algunos benchmarks usando session y en particular el happy que hacemos con Rudy empezamos a usar sessions.',\n",
              "   'tokens': [50364,\n",
              "    9706,\n",
              "    2151,\n",
              "    631,\n",
              "    36713,\n",
              "    29798,\n",
              "    497,\n",
              "    3221,\n",
              "    377,\n",
              "    8582,\n",
              "    572,\n",
              "    3573,\n",
              "    2617,\n",
              "    12101,\n",
              "    6481,\n",
              "    288,\n",
              "    23697,\n",
              "    8372,\n",
              "    21078,\n",
              "    43751,\n",
              "    29798,\n",
              "    5481,\n",
              "    288,\n",
              "    465,\n",
              "    1729,\n",
              "    806,\n",
              "    2055,\n",
              "    631,\n",
              "    33839,\n",
              "    416,\n",
              "    38690,\n",
              "    18730,\n",
              "    2151,\n",
              "    257,\n",
              "    14745,\n",
              "    11081,\n",
              "    13,\n",
              "    50864],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3376580801877109,\n",
              "   'compression_ratio': 1.510204081632653,\n",
              "   'no_speech_prob': 0.08744177222251892},\n",
              "  {'id': 79,\n",
              "   'seek': 69740,\n",
              "   'start': 707.4,\n",
              "   'end': 712.4,\n",
              "   'text': ' Claro. Y vimos mejoras impresionantes con realmente como poco cambio.',\n",
              "   'tokens': [50864,\n",
              "    33380,\n",
              "    13,\n",
              "    398,\n",
              "    49266,\n",
              "    11479,\n",
              "    296,\n",
              "    35672,\n",
              "    313,\n",
              "    9327,\n",
              "    416,\n",
              "    14446,\n",
              "    2617,\n",
              "    10639,\n",
              "    28731,\n",
              "    13,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3376580801877109,\n",
              "   'compression_ratio': 1.510204081632653,\n",
              "   'no_speech_prob': 0.08744177222251892},\n",
              "  {'id': 80,\n",
              "   'seek': 69740,\n",
              "   'start': 712.4,\n",
              "   'end': 720.4,\n",
              "   'text': ' Por ejemplo, la cantidad de ricos que puedo hacer eso por segundo con el primer vea su eco, digo, son alrededor de 500.',\n",
              "   'tokens': [51114,\n",
              "    5269,\n",
              "    13358,\n",
              "    11,\n",
              "    635,\n",
              "    33757,\n",
              "    368,\n",
              "    367,\n",
              "    9940,\n",
              "    631,\n",
              "    21612,\n",
              "    6720,\n",
              "    7287,\n",
              "    1515,\n",
              "    17954,\n",
              "    416,\n",
              "    806,\n",
              "    12595,\n",
              "    1241,\n",
              "    64,\n",
              "    459,\n",
              "    30226,\n",
              "    11,\n",
              "    22990,\n",
              "    11,\n",
              "    1872,\n",
              "    43663,\n",
              "    368,\n",
              "    5923,\n",
              "    13,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3376580801877109,\n",
              "   'compression_ratio': 1.510204081632653,\n",
              "   'no_speech_prob': 0.08744177222251892},\n",
              "  {'id': 81,\n",
              "   'seek': 72040,\n",
              "   'start': 721.4,\n",
              "   'end': 730.4,\n",
              "   'text': ' Usando sessions se duplicó, se duplicó la cantidad de ricos que puedo hacer eso en un segundo haciendo tres líneas de código de cambio.',\n",
              "   'tokens': [50414,\n",
              "    4958,\n",
              "    1806,\n",
              "    11081,\n",
              "    369,\n",
              "    17154,\n",
              "    812,\n",
              "    11,\n",
              "    369,\n",
              "    17154,\n",
              "    812,\n",
              "    635,\n",
              "    33757,\n",
              "    368,\n",
              "    367,\n",
              "    9940,\n",
              "    631,\n",
              "    21612,\n",
              "    6720,\n",
              "    7287,\n",
              "    465,\n",
              "    517,\n",
              "    17954,\n",
              "    20509,\n",
              "    15890,\n",
              "    16118,\n",
              "    716,\n",
              "    296,\n",
              "    368,\n",
              "    44195,\n",
              "    368,\n",
              "    28731,\n",
              "    13,\n",
              "    50864],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.35028264662798714,\n",
              "   'compression_ratio': 1.671497584541063,\n",
              "   'no_speech_prob': 0.056567057967185974},\n",
              "  {'id': 82,\n",
              "   'seek': 72040,\n",
              "   'start': 730.4,\n",
              "   'end': 740.4,\n",
              "   'text': ' Bien, acá bueno el vea no me quiero hacer refoco en el benchmark si pero bueno hicimos esto es una prueba local, obviamente la cantidad de ricos que puedan hacer por segundo va a vender 1 millón de cosas.',\n",
              "   'tokens': [50864,\n",
              "    16956,\n",
              "    11,\n",
              "    23496,\n",
              "    11974,\n",
              "    806,\n",
              "    1241,\n",
              "    64,\n",
              "    572,\n",
              "    385,\n",
              "    16811,\n",
              "    6720,\n",
              "    1895,\n",
              "    11198,\n",
              "    465,\n",
              "    806,\n",
              "    18927,\n",
              "    1511,\n",
              "    4768,\n",
              "    11974,\n",
              "    23697,\n",
              "    8372,\n",
              "    7433,\n",
              "    785,\n",
              "    2002,\n",
              "    48241,\n",
              "    2654,\n",
              "    11,\n",
              "    36325,\n",
              "    635,\n",
              "    33757,\n",
              "    368,\n",
              "    367,\n",
              "    9940,\n",
              "    631,\n",
              "    41241,\n",
              "    6720,\n",
              "    1515,\n",
              "    17954,\n",
              "    2773,\n",
              "    257,\n",
              "    44281,\n",
              "    502,\n",
              "    1728,\n",
              "    1801,\n",
              "    368,\n",
              "    12218,\n",
              "    13,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.35028264662798714,\n",
              "   'compression_ratio': 1.671497584541063,\n",
              "   'no_speech_prob': 0.056567057967185974},\n",
              "  {'id': 83,\n",
              "   'seek': 74040,\n",
              "   'start': 740.4,\n",
              "   'end': 747.4,\n",
              "   'text': ' Cuando probas R, tratas de australerte de la RID y usas tu propia interfaz de tu máquina como para tener algo consistente.',\n",
              "   'tokens': [50364,\n",
              "    21907,\n",
              "    1239,\n",
              "    296,\n",
              "    497,\n",
              "    11,\n",
              "    21507,\n",
              "    296,\n",
              "    368,\n",
              "    34916,\n",
              "    2155,\n",
              "    10634,\n",
              "    368,\n",
              "    635,\n",
              "    497,\n",
              "    2777,\n",
              "    288,\n",
              "    505,\n",
              "    296,\n",
              "    2604,\n",
              "    40464,\n",
              "    14510,\n",
              "    921,\n",
              "    368,\n",
              "    2604,\n",
              "    49360,\n",
              "    2617,\n",
              "    1690,\n",
              "    11640,\n",
              "    8655,\n",
              "    4603,\n",
              "    1576,\n",
              "    13,\n",
              "    50714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3790009442497702,\n",
              "   'compression_ratio': 1.5457627118644068,\n",
              "   'no_speech_prob': 0.1821548044681549},\n",
              "  {'id': 84,\n",
              "   'seek': 74040,\n",
              "   'start': 747.4,\n",
              "   'end': 754.4,\n",
              "   'text': ' Entonces realmente por hacer tres líneas de código de cambio ganamos una performance en cuanto a la cantidad rico que podemos hacer por segundo del doble.',\n",
              "   'tokens': [50714,\n",
              "    15097,\n",
              "    14446,\n",
              "    1515,\n",
              "    6720,\n",
              "    15890,\n",
              "    16118,\n",
              "    716,\n",
              "    296,\n",
              "    368,\n",
              "    44195,\n",
              "    368,\n",
              "    28731,\n",
              "    7574,\n",
              "    2151,\n",
              "    2002,\n",
              "    3389,\n",
              "    465,\n",
              "    36685,\n",
              "    257,\n",
              "    635,\n",
              "    33757,\n",
              "    367,\n",
              "    2789,\n",
              "    631,\n",
              "    12234,\n",
              "    6720,\n",
              "    1515,\n",
              "    17954,\n",
              "    1103,\n",
              "    360,\n",
              "    638,\n",
              "    13,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3790009442497702,\n",
              "   'compression_ratio': 1.5457627118644068,\n",
              "   'no_speech_prob': 0.1821548044681549},\n",
              "  {'id': 85,\n",
              "   'seek': 74040,\n",
              "   'start': 754.4,\n",
              "   'end': 765.4,\n",
              "   'text': ' También es más impresionante en una esquema chiste de TPS donde toda la negociación de certificados de SCL, metetanto a Vergette, que yo podía hacer 146 ricos por segundo,',\n",
              "   'tokens': [51064,\n",
              "    25682,\n",
              "    785,\n",
              "    3573,\n",
              "    35672,\n",
              "    313,\n",
              "    2879,\n",
              "    465,\n",
              "    2002,\n",
              "    34611,\n",
              "    5619,\n",
              "    417,\n",
              "    8375,\n",
              "    368,\n",
              "    314,\n",
              "    6273,\n",
              "    10488,\n",
              "    11687,\n",
              "    635,\n",
              "    26722,\n",
              "    537,\n",
              "    3482,\n",
              "    368,\n",
              "    12378,\n",
              "    4181,\n",
              "    368,\n",
              "    9028,\n",
              "    43,\n",
              "    11,\n",
              "    1131,\n",
              "    302,\n",
              "    5857,\n",
              "    257,\n",
              "    4281,\n",
              "    847,\n",
              "    975,\n",
              "    11,\n",
              "    631,\n",
              "    5290,\n",
              "    45588,\n",
              "    6720,\n",
              "    3499,\n",
              "    21,\n",
              "    367,\n",
              "    9940,\n",
              "    1515,\n",
              "    17954,\n",
              "    11,\n",
              "    51614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3790009442497702,\n",
              "   'compression_ratio': 1.5457627118644068,\n",
              "   'no_speech_prob': 0.1821548044681549},\n",
              "  {'id': 86,\n",
              "   'seek': 76540,\n",
              "   'start': 765.4,\n",
              "   'end': 772.4,\n",
              "   'text': ' habría desarrollándolo con acción y pasando sesiones, pasó a mil, o sea el cambio y la gana se realmente impresionante.',\n",
              "   'tokens': [50364,\n",
              "    32794,\n",
              "    2686,\n",
              "    32501,\n",
              "    18606,\n",
              "    7902,\n",
              "    416,\n",
              "    696,\n",
              "    5687,\n",
              "    288,\n",
              "    45412,\n",
              "    5385,\n",
              "    5411,\n",
              "    11,\n",
              "    41382,\n",
              "    257,\n",
              "    1962,\n",
              "    11,\n",
              "    277,\n",
              "    4158,\n",
              "    806,\n",
              "    28731,\n",
              "    288,\n",
              "    635,\n",
              "    290,\n",
              "    2095,\n",
              "    369,\n",
              "    14446,\n",
              "    35672,\n",
              "    313,\n",
              "    2879,\n",
              "    13,\n",
              "    50714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.424698969523112,\n",
              "   'compression_ratio': 1.443298969072165,\n",
              "   'no_speech_prob': 0.03459952026605606},\n",
              "  {'id': 87,\n",
              "   'seek': 76540,\n",
              "   'start': 772.4,\n",
              "   'end': 788.4,\n",
              "   'text': ' Entonces bueno y también todo el que priori no habíamos pensado pero que terminó sucediendo es que el uso de CPU, el mi aplicación, casi pasó la mitad.',\n",
              "   'tokens': [50714,\n",
              "    15097,\n",
              "    11974,\n",
              "    288,\n",
              "    6407,\n",
              "    5149,\n",
              "    806,\n",
              "    631,\n",
              "    4059,\n",
              "    72,\n",
              "    572,\n",
              "    3025,\n",
              "    16275,\n",
              "    6099,\n",
              "    1573,\n",
              "    4768,\n",
              "    631,\n",
              "    10761,\n",
              "    812,\n",
              "    41928,\n",
              "    7304,\n",
              "    785,\n",
              "    631,\n",
              "    806,\n",
              "    22728,\n",
              "    368,\n",
              "    13199,\n",
              "    11,\n",
              "    806,\n",
              "    2752,\n",
              "    18221,\n",
              "    3482,\n",
              "    11,\n",
              "    22567,\n",
              "    1736,\n",
              "    812,\n",
              "    635,\n",
              "    46895,\n",
              "    13,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.424698969523112,\n",
              "   'compression_ratio': 1.443298969072165,\n",
              "   'no_speech_prob': 0.03459952026605606},\n",
              "  {'id': 88,\n",
              "   'seek': 78840,\n",
              "   'start': 789.4,\n",
              "   'end': 798.4,\n",
              "   'text': ' Porque todas estas cosas que estaban haciendo ricos por abajo no las tiene que hacer más y si estamos pagando por CPU, por ejemplo comprando instancias en la 9,',\n",
              "   'tokens': [50414,\n",
              "    11287,\n",
              "    10906,\n",
              "    13897,\n",
              "    12218,\n",
              "    631,\n",
              "    36713,\n",
              "    20509,\n",
              "    367,\n",
              "    9940,\n",
              "    1515,\n",
              "    30613,\n",
              "    572,\n",
              "    2439,\n",
              "    7066,\n",
              "    631,\n",
              "    6720,\n",
              "    3573,\n",
              "    288,\n",
              "    1511,\n",
              "    10382,\n",
              "    11812,\n",
              "    1806,\n",
              "    1515,\n",
              "    13199,\n",
              "    11,\n",
              "    1515,\n",
              "    13358,\n",
              "    715,\n",
              "    19845,\n",
              "    1058,\n",
              "    282,\n",
              "    12046,\n",
              "    465,\n",
              "    635,\n",
              "    1722,\n",
              "    11,\n",
              "    50864],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3287111992059752,\n",
              "   'compression_ratio': 1.5377358490566038,\n",
              "   'no_speech_prob': 0.34799936413764954},\n",
              "  {'id': 89,\n",
              "   'seek': 78840,\n",
              "   'start': 798.4,\n",
              "   'end': 809.4,\n",
              "   'text': ' tal vez si tengo múltiples instancias, bueno usarla menos significa costo, mejoras en costos, o si tienen datos entre en su pieza, no sé menos calor, algo pero...',\n",
              "   'tokens': [50864,\n",
              "    4023,\n",
              "    5715,\n",
              "    1511,\n",
              "    13989,\n",
              "    275,\n",
              "    43447,\n",
              "    72,\n",
              "    2622,\n",
              "    1058,\n",
              "    282,\n",
              "    12046,\n",
              "    11,\n",
              "    11974,\n",
              "    14745,\n",
              "    875,\n",
              "    8902,\n",
              "    19957,\n",
              "    2063,\n",
              "    78,\n",
              "    11,\n",
              "    11479,\n",
              "    296,\n",
              "    465,\n",
              "    2063,\n",
              "    329,\n",
              "    11,\n",
              "    277,\n",
              "    1511,\n",
              "    12536,\n",
              "    27721,\n",
              "    3962,\n",
              "    465,\n",
              "    459,\n",
              "    1730,\n",
              "    2394,\n",
              "    11,\n",
              "    572,\n",
              "    7910,\n",
              "    8902,\n",
              "    31575,\n",
              "    11,\n",
              "    8655,\n",
              "    4768,\n",
              "    485,\n",
              "    51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3287111992059752,\n",
              "   'compression_ratio': 1.5377358490566038,\n",
              "   'no_speech_prob': 0.34799936413764954},\n",
              "  {'id': 90,\n",
              "   'seek': 80940,\n",
              "   'start': 810.4,\n",
              "   'end': 826.4,\n",
              "   'text': ' La ventaja para todos, entonces bueno a ver por qué estamos usando ricos, porque estábamos usando ricos, tiene una interfaz espectacular, realmente muy amigable, muy simple hacer un llamado de Jueves, después tiene un montón de ventajas asociadas a las aplicaciones web tradicionales, no necesariamente a micro-servings,',\n",
              "   'tokens': [50414,\n",
              "    2369,\n",
              "    6931,\n",
              "    12908,\n",
              "    1690,\n",
              "    6321,\n",
              "    11,\n",
              "    13003,\n",
              "    11974,\n",
              "    257,\n",
              "    1306,\n",
              "    1515,\n",
              "    8057,\n",
              "    10382,\n",
              "    29798,\n",
              "    367,\n",
              "    9940,\n",
              "    11,\n",
              "    4021,\n",
              "    3192,\n",
              "    65,\n",
              "    2151,\n",
              "    29798,\n",
              "    367,\n",
              "    9940,\n",
              "    11,\n",
              "    7066,\n",
              "    2002,\n",
              "    14510,\n",
              "    921,\n",
              "    38244,\n",
              "    14700,\n",
              "    11,\n",
              "    14446,\n",
              "    5323,\n",
              "    669,\n",
              "    328,\n",
              "    712,\n",
              "    11,\n",
              "    5323,\n",
              "    2199,\n",
              "    6720,\n",
              "    517,\n",
              "    47055,\n",
              "    368,\n",
              "    508,\n",
              "    622,\n",
              "    977,\n",
              "    11,\n",
              "    15283,\n",
              "    7066,\n",
              "    517,\n",
              "    45259,\n",
              "    368,\n",
              "    6931,\n",
              "    1805,\n",
              "    296,\n",
              "    382,\n",
              "    78,\n",
              "    537,\n",
              "    6872,\n",
              "    257,\n",
              "    2439,\n",
              "    18221,\n",
              "    9188,\n",
              "    3670,\n",
              "    47956,\n",
              "    279,\n",
              "    11,\n",
              "    572,\n",
              "    11909,\n",
              "    45149,\n",
              "    257,\n",
              "    4532,\n",
              "    12,\n",
              "    12484,\n",
              "    798,\n",
              "    82,\n",
              "    11,\n",
              "    51214],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4305534827999952,\n",
              "   'compression_ratio': 1.5502392344497609,\n",
              "   'no_speech_prob': 0.4756048321723938},\n",
              "  {'id': 91,\n",
              "   'seek': 82640,\n",
              "   'start': 827.4,\n",
              "   'end': 843.4,\n",
              "   'text': ' entonces manejos de cookies, verificaciones de cosas de seguridad, decodificación de contenido, streaming, chunking de vio de datos, tiene un montón de ventajas que están buenísimas, de las cuales a nosotros prácticamente no nos interesa ninguna.',\n",
              "   'tokens': [50414,\n",
              "    13003,\n",
              "    12743,\n",
              "    19136,\n",
              "    368,\n",
              "    13670,\n",
              "    11,\n",
              "    1306,\n",
              "    1089,\n",
              "    9188,\n",
              "    368,\n",
              "    12218,\n",
              "    368,\n",
              "    35415,\n",
              "    11,\n",
              "    979,\n",
              "    378,\n",
              "    40802,\n",
              "    368,\n",
              "    47117,\n",
              "    11,\n",
              "    11791,\n",
              "    11,\n",
              "    16635,\n",
              "    278,\n",
              "    368,\n",
              "    371,\n",
              "    1004,\n",
              "    368,\n",
              "    27721,\n",
              "    11,\n",
              "    7066,\n",
              "    517,\n",
              "    45259,\n",
              "    368,\n",
              "    6931,\n",
              "    1805,\n",
              "    296,\n",
              "    631,\n",
              "    10368,\n",
              "    30037,\n",
              "    5113,\n",
              "    17957,\n",
              "    11,\n",
              "    368,\n",
              "    2439,\n",
              "    46932,\n",
              "    257,\n",
              "    13863,\n",
              "    27300,\n",
              "    50250,\n",
              "    572,\n",
              "    3269,\n",
              "    728,\n",
              "    13708,\n",
              "    36073,\n",
              "    13,\n",
              "    51214],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2833041826883952,\n",
              "   'compression_ratio': 1.5120481927710843,\n",
              "   'no_speech_prob': 0.08623896539211273},\n",
              "  {'id': 92,\n",
              "   'seek': 84340,\n",
              "   'start': 844.4,\n",
              "   'end': 851.4,\n",
              "   'text': ' Está bien, te va a ir a empezar muy rápido, pero en el fondo usa un relícter.',\n",
              "   'tokens': [50414,\n",
              "    27304,\n",
              "    3610,\n",
              "    11,\n",
              "    535,\n",
              "    2773,\n",
              "    257,\n",
              "    3418,\n",
              "    257,\n",
              "    31168,\n",
              "    5323,\n",
              "    24893,\n",
              "    11,\n",
              "    4768,\n",
              "    465,\n",
              "    806,\n",
              "    38101,\n",
              "    29909,\n",
              "    517,\n",
              "    1039,\n",
              "    870,\n",
              "    349,\n",
              "    260,\n",
              "    13,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.40344980027940536,\n",
              "   'compression_ratio': 0.975609756097561,\n",
              "   'no_speech_prob': 0.16860716044902802},\n",
              "  {'id': 93,\n",
              "   'seek': 85140,\n",
              "   'start': 852.4,\n",
              "   'end': 874.4,\n",
              "   'text': ' Hay alguna aclaración, esto no se trata de comparar cosas, no queremos hacer comparaciones, las comparaciones son odiosas, en realidad estamos tratando de ver distintas herramientas, yo oí lo veo como rico es una herramienta para resolver algunos tipos problemas y Jueves relíctres, que es lo que voy a hablar un poquito ahora, es una herramienta para resolver otro tipo de problema,',\n",
              "   'tokens': [50414,\n",
              "    8721,\n",
              "    20651,\n",
              "    696,\n",
              "    2200,\n",
              "    3482,\n",
              "    11,\n",
              "    7433,\n",
              "    572,\n",
              "    369,\n",
              "    31920,\n",
              "    368,\n",
              "    6311,\n",
              "    289,\n",
              "    12218,\n",
              "    11,\n",
              "    572,\n",
              "    26813,\n",
              "    6720,\n",
              "    6311,\n",
              "    9188,\n",
              "    11,\n",
              "    2439,\n",
              "    6311,\n",
              "    9188,\n",
              "    1872,\n",
              "    3611,\n",
              "    2717,\n",
              "    296,\n",
              "    11,\n",
              "    465,\n",
              "    25635,\n",
              "    10382,\n",
              "    21507,\n",
              "    1806,\n",
              "    368,\n",
              "    1306,\n",
              "    31489,\n",
              "    296,\n",
              "    38271,\n",
              "    296,\n",
              "    11,\n",
              "    5290,\n",
              "    277,\n",
              "    870,\n",
              "    450,\n",
              "    41319,\n",
              "    2617,\n",
              "    367,\n",
              "    2789,\n",
              "    785,\n",
              "    2002,\n",
              "    38271,\n",
              "    64,\n",
              "    1690,\n",
              "    34480,\n",
              "    21078,\n",
              "    37105,\n",
              "    20720,\n",
              "    288,\n",
              "    508,\n",
              "    622,\n",
              "    977,\n",
              "    1039,\n",
              "    870,\n",
              "    349,\n",
              "    495,\n",
              "    11,\n",
              "    631,\n",
              "    785,\n",
              "    450,\n",
              "    631,\n",
              "    7552,\n",
              "    257,\n",
              "    21014,\n",
              "    517,\n",
              "    28229,\n",
              "    9923,\n",
              "    11,\n",
              "    785,\n",
              "    2002,\n",
              "    38271,\n",
              "    64,\n",
              "    1690,\n",
              "    34480,\n",
              "    11921,\n",
              "    9746,\n",
              "    368,\n",
              "    12395,\n",
              "    11,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.240389895695512,\n",
              "   'compression_ratio': 1.7788018433179724,\n",
              "   'no_speech_prob': 0.20150095224380493},\n",
              "  {'id': 94,\n",
              "   'seek': 87440,\n",
              "   'start': 875.4,\n",
              "   'end': 884.4,\n",
              "   'text': ' que estamos comparando que una es mejor que otra, son cosas diferentes, en el caso de web relíctres, lo primero que fuimos a analizar es ¿qué tan diferente es la interfaz?',\n",
              "   'tokens': [50414,\n",
              "    631,\n",
              "    10382,\n",
              "    6311,\n",
              "    1806,\n",
              "    631,\n",
              "    2002,\n",
              "    785,\n",
              "    11479,\n",
              "    631,\n",
              "    13623,\n",
              "    11,\n",
              "    1872,\n",
              "    12218,\n",
              "    17686,\n",
              "    11,\n",
              "    465,\n",
              "    806,\n",
              "    9666,\n",
              "    368,\n",
              "    3670,\n",
              "    1039,\n",
              "    870,\n",
              "    349,\n",
              "    495,\n",
              "    11,\n",
              "    450,\n",
              "    21289,\n",
              "    631,\n",
              "    8536,\n",
              "    8372,\n",
              "    257,\n",
              "    2624,\n",
              "    9736,\n",
              "    785,\n",
              "    3841,\n",
              "    16412,\n",
              "    7603,\n",
              "    20973,\n",
              "    785,\n",
              "    635,\n",
              "    14510,\n",
              "    921,\n",
              "    30,\n",
              "    50864],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2633663507608267,\n",
              "   'compression_ratio': 1.5984555984555984,\n",
              "   'no_speech_prob': 0.06004759669303894},\n",
              "  {'id': 95,\n",
              "   'seek': 87440,\n",
              "   'start': 884.4,\n",
              "   'end': 896.4,\n",
              "   'text': ' Porque esto lo tenemos a replicar en 300 equipos, tenemos aligo un mensaje a 300 equipos de heche, deberíamos empezar a utilizar este herramienta porque ahí lo vamos a ver más adelante, y nos encontramos que si bien no están amigables,',\n",
              "   'tokens': [50864,\n",
              "    11287,\n",
              "    7433,\n",
              "    450,\n",
              "    9914,\n",
              "    257,\n",
              "    3248,\n",
              "    7953,\n",
              "    465,\n",
              "    6641,\n",
              "    5037,\n",
              "    329,\n",
              "    11,\n",
              "    9914,\n",
              "    419,\n",
              "    7483,\n",
              "    517,\n",
              "    10923,\n",
              "    11153,\n",
              "    257,\n",
              "    6641,\n",
              "    5037,\n",
              "    329,\n",
              "    368,\n",
              "    415,\n",
              "    1876,\n",
              "    11,\n",
              "    29671,\n",
              "    16275,\n",
              "    31168,\n",
              "    257,\n",
              "    24060,\n",
              "    4065,\n",
              "    38271,\n",
              "    64,\n",
              "    4021,\n",
              "    12571,\n",
              "    450,\n",
              "    5295,\n",
              "    257,\n",
              "    1306,\n",
              "    3573,\n",
              "    40214,\n",
              "    11,\n",
              "    288,\n",
              "    3269,\n",
              "    45049,\n",
              "    631,\n",
              "    1511,\n",
              "    3610,\n",
              "    572,\n",
              "    10368,\n",
              "    669,\n",
              "    328,\n",
              "    2965,\n",
              "    11,\n",
              "    51464],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2633663507608267,\n",
              "   'compression_ratio': 1.5984555984555984,\n",
              "   'no_speech_prob': 0.06004759669303894},\n",
              "  {'id': 96,\n",
              "   'seek': 89640,\n",
              "   'start': 896.4,\n",
              "   'end': 897.4,\n",
              "   'text': ' acá no puede utilizar como así con rico es de no hacer una sesión, acá realmente hay que hacer un pull, lo sision de rico es en el fondo, hacer un pull de web relíctres, hay que ser más explícito en los parámetros, no es tan que los adivino más quicamente, igual son dos parámetros, no más, uno dice a cuántos dominios diferente va mantener una conexión, por ejemplo si me conecto a 5 microservicios, el número de pull es 5, y el max size que está ahí como 10, el',\n",
              "   'tokens': [50414,\n",
              "    23496,\n",
              "    572,\n",
              "    8919,\n",
              "    24060,\n",
              "    2617,\n",
              "    8582,\n",
              "    416,\n",
              "    367,\n",
              "    2789,\n",
              "    785,\n",
              "    368,\n",
              "    572,\n",
              "    6720,\n",
              "    2002,\n",
              "    5385,\n",
              "    2560,\n",
              "    11,\n",
              "    23496,\n",
              "    14446,\n",
              "    4842,\n",
              "    631,\n",
              "    6720,\n",
              "    517,\n",
              "    2235,\n",
              "    11,\n",
              "    450,\n",
              "    262,\n",
              "    1991,\n",
              "    368,\n",
              "    367,\n",
              "    2789,\n",
              "    785,\n",
              "    465,\n",
              "    806,\n",
              "    38101,\n",
              "    11,\n",
              "    6720,\n",
              "    517,\n",
              "    2235,\n",
              "    368,\n",
              "    3670,\n",
              "    1039,\n",
              "    870,\n",
              "    349,\n",
              "    495,\n",
              "    11,\n",
              "    4842,\n",
              "    631,\n",
              "    816,\n",
              "    3573,\n",
              "    1490,\n",
              "    870,\n",
              "    32030,\n",
              "    465,\n",
              "    1750,\n",
              "    971,\n",
              "    842,\n",
              "    29570,\n",
              "    11,\n",
              "    572,\n",
              "    785,\n",
              "    7603,\n",
              "    631,\n",
              "    1750,\n",
              "    614,\n",
              "    592,\n",
              "    2982,\n",
              "    3573,\n",
              "    421,\n",
              "    23653,\n",
              "    11,\n",
              "    10953,\n",
              "    1872,\n",
              "    4491,\n",
              "    971,\n",
              "    842,\n",
              "    29570,\n",
              "    11,\n",
              "    572,\n",
              "    3573,\n",
              "    11,\n",
              "    8526,\n",
              "    10313,\n",
              "    257,\n",
              "    44256,\n",
              "    329,\n",
              "    8859,\n",
              "    2717,\n",
              "    20973,\n",
              "    2773,\n",
              "    42759,\n",
              "    2002,\n",
              "    49509,\n",
              "    2560,\n",
              "    11,\n",
              "    1515,\n",
              "    13358,\n",
              "    1511,\n",
              "    385,\n",
              "    30458,\n",
              "    78,\n",
              "    257,\n",
              "    1025,\n",
              "    15547,\n",
              "    1978,\n",
              "    26817,\n",
              "    11,\n",
              "    806,\n",
              "    14959,\n",
              "    368,\n",
              "    2235,\n",
              "    785,\n",
              "    1025,\n",
              "    11,\n",
              "    288,\n",
              "    806,\n",
              "    11469,\n",
              "    2744,\n",
              "    631,\n",
              "    3192,\n",
              "    12571,\n",
              "    2617,\n",
              "    1266,\n",
              "    11,\n",
              "    806],\n",
              "   'temperature': 0.2,\n",
              "   'avg_logprob': -0.3289730041984498,\n",
              "   'compression_ratio': 1.704626334519573,\n",
              "   'no_speech_prob': 0.09131621569395065},\n",
              "  {'id': 97,\n",
              "   'seek': 92640,\n",
              "   'start': 926.4,\n",
              "   'end': 956.4,\n",
              "   'text': ' es la cantidad de ídios que vamos a tener abierto por cada pull, entonces si estamos trabajando con un unicórbudo lsg y estamos haciendo 3d y vamos a poner 10 cilos, sabemos que ahí tenemos poner un número 10 o más, esto no es un número duro, no es que si de repente hay más hilos corriendo insestables en más conexiones no nos va a permitir lo que va a pasar, que cuando se cumple un timeout va ir eliminando conexiones y siempre va a dejar 10 establecidas, y las otras se van a tener establecer cuando se inician, después en el uso, y es un poco',\n",
              "   'tokens': [50364,\n",
              "    785,\n",
              "    635,\n",
              "    33757,\n",
              "    368,\n",
              "    18645,\n",
              "    67,\n",
              "    2717,\n",
              "    631,\n",
              "    5295,\n",
              "    257,\n",
              "    11640,\n",
              "    410,\n",
              "    20747,\n",
              "    1515,\n",
              "    8411,\n",
              "    2235,\n",
              "    11,\n",
              "    13003,\n",
              "    1511,\n",
              "    10382,\n",
              "    40473,\n",
              "    416,\n",
              "    517,\n",
              "    517,\n",
              "    299,\n",
              "    15614,\n",
              "    65,\n",
              "    6207,\n",
              "    287,\n",
              "    82,\n",
              "    70,\n",
              "    288,\n",
              "    10382,\n",
              "    20509,\n",
              "    805,\n",
              "    67,\n",
              "    288,\n",
              "    5295,\n",
              "    257,\n",
              "    19149,\n",
              "    1266,\n",
              "    269,\n",
              "    6136,\n",
              "    11,\n",
              "    27200,\n",
              "    631,\n",
              "    12571,\n",
              "    9914,\n",
              "    19149,\n",
              "    517,\n",
              "    14959,\n",
              "    1266,\n",
              "    277,\n",
              "    3573,\n",
              "    11,\n",
              "    7433,\n",
              "    572,\n",
              "    785,\n",
              "    517,\n",
              "    14959,\n",
              "    1581,\n",
              "    340,\n",
              "    11,\n",
              "    572,\n",
              "    785,\n",
              "    631,\n",
              "    1511,\n",
              "    368,\n",
              "    42884,\n",
              "    4842,\n",
              "    3573,\n",
              "    276,\n",
              "    6136,\n",
              "    47908,\n",
              "    3999,\n",
              "    1028,\n",
              "    377,\n",
              "    2965,\n",
              "    465,\n",
              "    3573,\n",
              "    49509,\n",
              "    5411,\n",
              "    572,\n",
              "    3269,\n",
              "    2773,\n",
              "    257,\n",
              "    46865,\n",
              "    450,\n",
              "    631,\n",
              "    2773,\n",
              "    257,\n",
              "    25344,\n",
              "    11,\n",
              "    631,\n",
              "    7767,\n",
              "    369,\n",
              "    12713,\n",
              "    781,\n",
              "    517,\n",
              "    565,\n",
              "    346,\n",
              "    2773,\n",
              "    3418,\n",
              "    7892,\n",
              "    1806,\n",
              "    49509,\n",
              "    5411,\n",
              "    288,\n",
              "    12758,\n",
              "    2773,\n",
              "    257,\n",
              "    24391,\n",
              "    1266,\n",
              "    37444,\n",
              "    66,\n",
              "    11382,\n",
              "    11,\n",
              "    288,\n",
              "    2439,\n",
              "    20244,\n",
              "    369,\n",
              "    3161,\n",
              "    257,\n",
              "    11640,\n",
              "    37444,\n",
              "    1776,\n",
              "    7767,\n",
              "    369,\n",
              "    294,\n",
              "    9027,\n",
              "    11,\n",
              "    15283,\n",
              "    465,\n",
              "    806,\n",
              "    22728,\n",
              "    11,\n",
              "    288,\n",
              "    785,\n",
              "    517,\n",
              "    10639],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.30370894955917144,\n",
              "   'compression_ratio': 1.7993527508090614,\n",
              "   'no_speech_prob': 0.001206462038680911},\n",
              "  {'id': 98,\n",
              "   'seek': 95640,\n",
              "   'start': 956.4,\n",
              "   'end': 979.4,\n",
              "   'text': ' raro en realidad el get no es un método y es un parámetro, los fields, hay cosas que realmente el interfaz rico, están buenísimas y no la tenemos en un lugar real entre 3, pero haciendo un análisis rápido tampoco es inentendible, no es que hoy va a haber mejor esto todo lo que estamos acá y más o menos podemos entender que eso quiere hacer un get a esta URL y que le quiere pasar estas parámetros',\n",
              "   'tokens': [50364,\n",
              "    367,\n",
              "    9708,\n",
              "    465,\n",
              "    25635,\n",
              "    806,\n",
              "    483,\n",
              "    572,\n",
              "    785,\n",
              "    517,\n",
              "    20275,\n",
              "    17423,\n",
              "    288,\n",
              "    785,\n",
              "    517,\n",
              "    971,\n",
              "    842,\n",
              "    45400,\n",
              "    11,\n",
              "    1750,\n",
              "    7909,\n",
              "    11,\n",
              "    4842,\n",
              "    12218,\n",
              "    631,\n",
              "    14446,\n",
              "    806,\n",
              "    14510,\n",
              "    921,\n",
              "    41529,\n",
              "    11,\n",
              "    10368,\n",
              "    30037,\n",
              "    5113,\n",
              "    17957,\n",
              "    288,\n",
              "    572,\n",
              "    635,\n",
              "    9914,\n",
              "    465,\n",
              "    517,\n",
              "    11467,\n",
              "    957,\n",
              "    3962,\n",
              "    805,\n",
              "    11,\n",
              "    4768,\n",
              "    20509,\n",
              "    517,\n",
              "    44113,\n",
              "    28436,\n",
              "    24893,\n",
              "    36838,\n",
              "    785,\n",
              "    294,\n",
              "    317,\n",
              "    521,\n",
              "    964,\n",
              "    11,\n",
              "    572,\n",
              "    785,\n",
              "    631,\n",
              "    13775,\n",
              "    2773,\n",
              "    257,\n",
              "    15811,\n",
              "    11479,\n",
              "    7433,\n",
              "    5149,\n",
              "    450,\n",
              "    631,\n",
              "    10382,\n",
              "    23496,\n",
              "    288,\n",
              "    3573,\n",
              "    277,\n",
              "    8902,\n",
              "    12234,\n",
              "    20054,\n",
              "    631,\n",
              "    7287,\n",
              "    23877,\n",
              "    6720,\n",
              "    517,\n",
              "    483,\n",
              "    257,\n",
              "    5283,\n",
              "    12905,\n",
              "    288,\n",
              "    631,\n",
              "    476,\n",
              "    23877,\n",
              "    25344,\n",
              "    13897,\n",
              "    971,\n",
              "    842,\n",
              "    29570,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.36822975158691407,\n",
              "   'compression_ratio': 1.6150793650793651,\n",
              "   'no_speech_prob': 0.005299742799252272},\n",
              "  {'id': 99,\n",
              "   'seek': 97940,\n",
              "   'start': 980.4,\n",
              "   'end': 1003.4,\n",
              "   'text': ' y simulas mivas pruebas que veníamos haciendo exactamente el mismo escenario y encontramos que con solo esos cambios que no son menores, si uno ya tiene un proveo de acto que está establecido, que es grande y tiene muchos test, escritos con ricos y ricos mos son cambios importantes pero ya teníamos un 30% de aarancia y no es poco un 30%',\n",
              "   'tokens': [50414,\n",
              "    288,\n",
              "    1034,\n",
              "    16968,\n",
              "    275,\n",
              "    24759,\n",
              "    32820,\n",
              "    16342,\n",
              "    631,\n",
              "    6138,\n",
              "    16275,\n",
              "    20509,\n",
              "    48686,\n",
              "    806,\n",
              "    12461,\n",
              "    4721,\n",
              "    49120,\n",
              "    288,\n",
              "    45049,\n",
              "    631,\n",
              "    416,\n",
              "    6944,\n",
              "    22411,\n",
              "    18751,\n",
              "    2717,\n",
              "    631,\n",
              "    572,\n",
              "    1872,\n",
              "    1706,\n",
              "    2706,\n",
              "    11,\n",
              "    1511,\n",
              "    8526,\n",
              "    2478,\n",
              "    7066,\n",
              "    517,\n",
              "    7081,\n",
              "    78,\n",
              "    368,\n",
              "    605,\n",
              "    78,\n",
              "    631,\n",
              "    3192,\n",
              "    37444,\n",
              "    17994,\n",
              "    11,\n",
              "    631,\n",
              "    785,\n",
              "    8883,\n",
              "    288,\n",
              "    7066,\n",
              "    17061,\n",
              "    1500,\n",
              "    11,\n",
              "    785,\n",
              "    66,\n",
              "    42887,\n",
              "    416,\n",
              "    367,\n",
              "    9940,\n",
              "    288,\n",
              "    367,\n",
              "    9940,\n",
              "    275,\n",
              "    329,\n",
              "    1872,\n",
              "    18751,\n",
              "    2717,\n",
              "    27963,\n",
              "    4768,\n",
              "    2478,\n",
              "    2064,\n",
              "    16275,\n",
              "    517,\n",
              "    2217,\n",
              "    4,\n",
              "    368,\n",
              "    257,\n",
              "    289,\n",
              "    22862,\n",
              "    288,\n",
              "    572,\n",
              "    785,\n",
              "    10639,\n",
              "    517,\n",
              "    2217,\n",
              "    4,\n",
              "    51564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.458977296617296,\n",
              "   'compression_ratio': 1.631578947368421,\n",
              "   'no_speech_prob': 0.6711498498916626},\n",
              "  {'id': 100,\n",
              "   'seek': 100340,\n",
              "   'start': 1003.4,\n",
              "   'end': 1010.4,\n",
              "   'text': ' 30% es un montón cuando tienen millones de ricos que se están ejecutando, entonces pasamos de 1000 que le teníamos antes a 1300',\n",
              "   'tokens': [50364,\n",
              "    2217,\n",
              "    4,\n",
              "    785,\n",
              "    517,\n",
              "    45259,\n",
              "    7767,\n",
              "    12536,\n",
              "    22416,\n",
              "    368,\n",
              "    367,\n",
              "    9940,\n",
              "    631,\n",
              "    369,\n",
              "    10368,\n",
              "    39564,\n",
              "    6672,\n",
              "    1806,\n",
              "    11,\n",
              "    13003,\n",
              "    1736,\n",
              "    2151,\n",
              "    368,\n",
              "    9714,\n",
              "    631,\n",
              "    476,\n",
              "    2064,\n",
              "    16275,\n",
              "    11014,\n",
              "    257,\n",
              "    48156,\n",
              "    50714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3644742965698242,\n",
              "   'compression_ratio': 1.456043956043956,\n",
              "   'no_speech_prob': 0.12407776713371277},\n",
              "  {'id': 101,\n",
              "   'seek': 100340,\n",
              "   'start': 1016.4,\n",
              "   'end': 1024.4,\n",
              "   'text': ' en ese momento ya estamos en canchila, habíamos pasado de un mes, no sé si algo que usan acá o una mala palabra que van a Cualombia',\n",
              "   'tokens': [51014,\n",
              "    465,\n",
              "    10167,\n",
              "    9333,\n",
              "    2478,\n",
              "    10382,\n",
              "    465,\n",
              "    393,\n",
              "    339,\n",
              "    7371,\n",
              "    11,\n",
              "    3025,\n",
              "    16275,\n",
              "    24794,\n",
              "    368,\n",
              "    517,\n",
              "    3813,\n",
              "    11,\n",
              "    572,\n",
              "    7910,\n",
              "    1511,\n",
              "    8655,\n",
              "    631,\n",
              "    505,\n",
              "    282,\n",
              "    23496,\n",
              "    277,\n",
              "    2002,\n",
              "    37508,\n",
              "    31702,\n",
              "    631,\n",
              "    3161,\n",
              "    257,\n",
              "    383,\n",
              "    901,\n",
              "    3548,\n",
              "    654,\n",
              "    51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3644742965698242,\n",
              "   'compression_ratio': 1.456043956043956,\n",
              "   'no_speech_prob': 0.12407776713371277},\n",
              "  {'id': 102,\n",
              "   'seek': 102440,\n",
              "   'start': 1024.4,\n",
              "   'end': 1027.4,\n",
              "   'text': ' si no va a la palabra, no es la palabra',\n",
              "   'tokens': [50364,\n",
              "    1511,\n",
              "    572,\n",
              "    2773,\n",
              "    257,\n",
              "    635,\n",
              "    31702,\n",
              "    11,\n",
              "    572,\n",
              "    785,\n",
              "    635,\n",
              "    31702,\n",
              "    50514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.48052621856937566,\n",
              "   'compression_ratio': 1.7178571428571427,\n",
              "   'no_speech_prob': 0.3980577290058136},\n",
              "  {'id': 103,\n",
              "   'seek': 102440,\n",
              "   'start': 1027.4,\n",
              "   'end': 1053.4,\n",
              "   'text': ' o sea habíamos trabajado un mes aproximadamente haciendo estas pruebas y estos cambios probándolo en API y ya estamos al doble y un poquito más del doble y es que muy bueno, investimos un poquito más, vamos más ya, somos una compañía grande, tenemos muchas apes que escrita en Python, tenemos tiempos para hacer estas cosas, entonces bueno juguemos, empecemos, investigar y obviamente ir de Python a C, que es paicul, está hecho en C',\n",
              "   'tokens': [50514,\n",
              "    277,\n",
              "    4158,\n",
              "    3025,\n",
              "    16275,\n",
              "    9618,\n",
              "    1573,\n",
              "    517,\n",
              "    3813,\n",
              "    48892,\n",
              "    20509,\n",
              "    13897,\n",
              "    32820,\n",
              "    16342,\n",
              "    288,\n",
              "    12585,\n",
              "    18751,\n",
              "    2717,\n",
              "    1239,\n",
              "    18606,\n",
              "    7902,\n",
              "    465,\n",
              "    9362,\n",
              "    288,\n",
              "    2478,\n",
              "    10382,\n",
              "    419,\n",
              "    360,\n",
              "    638,\n",
              "    288,\n",
              "    517,\n",
              "    28229,\n",
              "    3573,\n",
              "    1103,\n",
              "    360,\n",
              "    638,\n",
              "    288,\n",
              "    785,\n",
              "    631,\n",
              "    5323,\n",
              "    11974,\n",
              "    11,\n",
              "    1963,\n",
              "    8372,\n",
              "    517,\n",
              "    28229,\n",
              "    3573,\n",
              "    11,\n",
              "    5295,\n",
              "    3573,\n",
              "    2478,\n",
              "    11,\n",
              "    25244,\n",
              "    2002,\n",
              "    29953,\n",
              "    2686,\n",
              "    8883,\n",
              "    11,\n",
              "    9914,\n",
              "    16072,\n",
              "    1882,\n",
              "    279,\n",
              "    631,\n",
              "    49865,\n",
              "    2786,\n",
              "    465,\n",
              "    15329,\n",
              "    11,\n",
              "    9914,\n",
              "    7582,\n",
              "    2455,\n",
              "    329,\n",
              "    1690,\n",
              "    6720,\n",
              "    13897,\n",
              "    12218,\n",
              "    11,\n",
              "    13003,\n",
              "    11974,\n",
              "    9568,\n",
              "    84,\n",
              "    4485,\n",
              "    11,\n",
              "    846,\n",
              "    494,\n",
              "    38173,\n",
              "    11,\n",
              "    4557,\n",
              "    289,\n",
              "    288,\n",
              "    36325,\n",
              "    3418,\n",
              "    368,\n",
              "    15329,\n",
              "    257,\n",
              "    383,\n",
              "    11,\n",
              "    631,\n",
              "    785,\n",
              "    2502,\n",
              "    299,\n",
              "    425,\n",
              "    11,\n",
              "    3192,\n",
              "    13064,\n",
              "    465,\n",
              "    383,\n",
              "    51814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.48052621856937566,\n",
              "   'compression_ratio': 1.7178571428571427,\n",
              "   'no_speech_prob': 0.3980577290058136},\n",
              "  {'id': 104,\n",
              "   'seek': 105340,\n",
              "   'start': 1053.4,\n",
              "   'end': 1065.4,\n",
              "   'text': ' sabíamos que vamos a tener alguna ventaja en tiempo, ahora teníamos enalizar cuel son las desventajas de usar paicul, porque no todo de gratis en la vida, entonces empezamos a investigar Cual',\n",
              "   'tokens': [50364,\n",
              "    5560,\n",
              "    16275,\n",
              "    631,\n",
              "    5295,\n",
              "    257,\n",
              "    11640,\n",
              "    20651,\n",
              "    6931,\n",
              "    12908,\n",
              "    465,\n",
              "    11772,\n",
              "    11,\n",
              "    9923,\n",
              "    2064,\n",
              "    16275,\n",
              "    465,\n",
              "    304,\n",
              "    9736,\n",
              "    2702,\n",
              "    338,\n",
              "    1872,\n",
              "    2439,\n",
              "    730,\n",
              "    2475,\n",
              "    1805,\n",
              "    296,\n",
              "    368,\n",
              "    14745,\n",
              "    2502,\n",
              "    299,\n",
              "    425,\n",
              "    11,\n",
              "    4021,\n",
              "    572,\n",
              "    5149,\n",
              "    368,\n",
              "    10158,\n",
              "    271,\n",
              "    465,\n",
              "    635,\n",
              "    7644,\n",
              "    11,\n",
              "    13003,\n",
              "    18730,\n",
              "    2151,\n",
              "    257,\n",
              "    4557,\n",
              "    289,\n",
              "    383,\n",
              "    901,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3049764161062713,\n",
              "   'compression_ratio': 1.6,\n",
              "   'no_speech_prob': 0.008981495164334774},\n",
              "  {'id': 105,\n",
              "   'seek': 105340,\n",
              "   'start': 1065.4,\n",
              "   'end': 1081.4,\n",
              "   'text': ' lo primero que vimos en la documentación es que es para usuarios avanzados, para hacer docena de conexiones con currrentes, feature sustificados y la documentación está escrito en HTML1.0',\n",
              "   'tokens': [50964,\n",
              "    450,\n",
              "    21289,\n",
              "    631,\n",
              "    49266,\n",
              "    465,\n",
              "    635,\n",
              "    4166,\n",
              "    3482,\n",
              "    785,\n",
              "    631,\n",
              "    785,\n",
              "    1690,\n",
              "    32247,\n",
              "    9720,\n",
              "    42444,\n",
              "    4181,\n",
              "    11,\n",
              "    1690,\n",
              "    6720,\n",
              "    3211,\n",
              "    4118,\n",
              "    368,\n",
              "    49509,\n",
              "    5411,\n",
              "    416,\n",
              "    1262,\n",
              "    81,\n",
              "    1753,\n",
              "    279,\n",
              "    11,\n",
              "    4111,\n",
              "    5402,\n",
              "    1089,\n",
              "    4181,\n",
              "    288,\n",
              "    635,\n",
              "    4166,\n",
              "    3482,\n",
              "    3192,\n",
              "    49451,\n",
              "    465,\n",
              "    17995,\n",
              "    16,\n",
              "    13,\n",
              "    15,\n",
              "    51764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3049764161062713,\n",
              "   'compression_ratio': 1.6,\n",
              "   'no_speech_prob': 0.008981495164334774},\n",
              "  {'id': 106,\n",
              "   'seek': 108140,\n",
              "   'start': 1081.4,\n",
              "   'end': 1099.4,\n",
              "   'text': ' Yo que venía de ritme de doc, si tuviste estas cosas bonitas y con buscadores en pese a leer esa documentación y dije no, porque me estoy metiendo acá, pero bueno, nada, tenía el tiempo, somos informático, nos gusta hacer estas cosas, investimos un poquito más, empecé a jugar y dije bueno voy a hacer mi primer get in paicul.',\n",
              "   'tokens': [50364,\n",
              "    7616,\n",
              "    631,\n",
              "    6138,\n",
              "    2686,\n",
              "    368,\n",
              "    11289,\n",
              "    1398,\n",
              "    368,\n",
              "    3211,\n",
              "    11,\n",
              "    1511,\n",
              "    38177,\n",
              "    8375,\n",
              "    13897,\n",
              "    12218,\n",
              "    4428,\n",
              "    14182,\n",
              "    288,\n",
              "    416,\n",
              "    1255,\n",
              "    66,\n",
              "    11856,\n",
              "    465,\n",
              "    280,\n",
              "    1130,\n",
              "    257,\n",
              "    34172,\n",
              "    11342,\n",
              "    4166,\n",
              "    3482,\n",
              "    288,\n",
              "    39414,\n",
              "    572,\n",
              "    11,\n",
              "    4021,\n",
              "    385,\n",
              "    15796,\n",
              "    1131,\n",
              "    7304,\n",
              "    23496,\n",
              "    11,\n",
              "    4768,\n",
              "    11974,\n",
              "    11,\n",
              "    8096,\n",
              "    11,\n",
              "    23718,\n",
              "    806,\n",
              "    11772,\n",
              "    11,\n",
              "    25244,\n",
              "    1356,\n",
              "    28234,\n",
              "    11,\n",
              "    3269,\n",
              "    20576,\n",
              "    6720,\n",
              "    13897,\n",
              "    12218,\n",
              "    11,\n",
              "    1963,\n",
              "    8372,\n",
              "    517,\n",
              "    28229,\n",
              "    3573,\n",
              "    11,\n",
              "    846,\n",
              "    494,\n",
              "    13523,\n",
              "    257,\n",
              "    37692,\n",
              "    288,\n",
              "    39414,\n",
              "    11974,\n",
              "    7552,\n",
              "    257,\n",
              "    6720,\n",
              "    2752,\n",
              "    12595,\n",
              "    483,\n",
              "    294,\n",
              "    2502,\n",
              "    299,\n",
              "    425,\n",
              "    13,\n",
              "    51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.35097257206948956,\n",
              "   'compression_ratio': 1.5488372093023255,\n",
              "   'no_speech_prob': 0.01970866695046425},\n",
              "  {'id': 107,\n",
              "   'seek': 109940,\n",
              "   'start': 1100.4,\n",
              "   'end': 1109.4,\n",
              "   'text': ' Esto es copy page de la documentación de paicul, que es que la web page está buenísimo, el que avisa no tradiciona, ¿eh?',\n",
              "   'tokens': [50414,\n",
              "    20880,\n",
              "    785,\n",
              "    5055,\n",
              "    3028,\n",
              "    368,\n",
              "    635,\n",
              "    4166,\n",
              "    3482,\n",
              "    368,\n",
              "    2502,\n",
              "    299,\n",
              "    425,\n",
              "    11,\n",
              "    631,\n",
              "    785,\n",
              "    631,\n",
              "    635,\n",
              "    3670,\n",
              "    3028,\n",
              "    3192,\n",
              "    30037,\n",
              "    49889,\n",
              "    11,\n",
              "    806,\n",
              "    631,\n",
              "    1305,\n",
              "    3837,\n",
              "    572,\n",
              "    2479,\n",
              "    18899,\n",
              "    64,\n",
              "    11,\n",
              "    3841,\n",
              "    13301,\n",
              "    30,\n",
              "    50864],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5851056689307803,\n",
              "   'compression_ratio': 1.391812865497076,\n",
              "   'no_speech_prob': 0.2969836890697479},\n",
              "  {'id': 108,\n",
              "   'seek': 109940,\n",
              "   'start': 1109.4,\n",
              "   'end': 1114.4,\n",
              "   'text': ' Y está muy bien, ¿por qué, ¿quién usted usa paicul?',\n",
              "   'tokens': [50864,\n",
              "    398,\n",
              "    3192,\n",
              "    5323,\n",
              "    3610,\n",
              "    11,\n",
              "    3841,\n",
              "    2816,\n",
              "    8057,\n",
              "    11,\n",
              "    3841,\n",
              "    358,\n",
              "    5770,\n",
              "    10467,\n",
              "    29909,\n",
              "    2502,\n",
              "    299,\n",
              "    425,\n",
              "    30,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5851056689307803,\n",
              "   'compression_ratio': 1.391812865497076,\n",
              "   'no_speech_prob': 0.2969836890697479},\n",
              "  {'id': 109,\n",
              "   'seek': 109940,\n",
              "   'start': 1116.4,\n",
              "   'end': 1122.4,\n",
              "   'text': ' Una, un valiente, o relíptr, o relíptr, ¿qué no usa?',\n",
              "   'tokens': [51214,\n",
              "    15491,\n",
              "    11,\n",
              "    517,\n",
              "    1323,\n",
              "    8413,\n",
              "    11,\n",
              "    277,\n",
              "    1039,\n",
              "    870,\n",
              "    662,\n",
              "    81,\n",
              "    11,\n",
              "    277,\n",
              "    1039,\n",
              "    870,\n",
              "    662,\n",
              "    81,\n",
              "    11,\n",
              "    3841,\n",
              "    16412,\n",
              "    572,\n",
              "    29909,\n",
              "    30,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5851056689307803,\n",
              "   'compression_ratio': 1.391812865497076,\n",
              "   'no_speech_prob': 0.2969836890697479},\n",
              "  {'id': 110,\n",
              "   'seek': 112240,\n",
              "   'start': 1123.4,\n",
              "   'end': 1125.4,\n",
              "   'text': ' Ahí está, pa, ahí va, ¿cómo?',\n",
              "   'tokens': [50414,\n",
              "    49924,\n",
              "    3192,\n",
              "    11,\n",
              "    2502,\n",
              "    11,\n",
              "    12571,\n",
              "    2773,\n",
              "    11,\n",
              "    3841,\n",
              "    46614,\n",
              "    30,\n",
              "    50514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.510879140504649,\n",
              "   'compression_ratio': 1.3058823529411765,\n",
              "   'no_speech_prob': 0.0351121686398983},\n",
              "  {'id': 111,\n",
              "   'seek': 112240,\n",
              "   'start': 1125.4,\n",
              "   'end': 1128.4,\n",
              "   'text': ' Hay que trabajar con los microsaricios, hablemos en un rato.',\n",
              "   'tokens': [50514,\n",
              "    8721,\n",
              "    631,\n",
              "    30793,\n",
              "    416,\n",
              "    1750,\n",
              "    3123,\n",
              "    2635,\n",
              "    289,\n",
              "    26817,\n",
              "    11,\n",
              "    324,\n",
              "    1113,\n",
              "    329,\n",
              "    465,\n",
              "    517,\n",
              "    367,\n",
              "    2513,\n",
              "    13,\n",
              "    50664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.510879140504649,\n",
              "   'compression_ratio': 1.3058823529411765,\n",
              "   'no_speech_prob': 0.0351121686398983},\n",
              "  {'id': 112,\n",
              "   'seek': 112240,\n",
              "   'start': 1128.4,\n",
              "   'end': 1137.4,\n",
              "   'text': ' Pero sí, pero acá paicul está diciendo, sin necesitas docenas de llamadas con currrentes y erones, con feature sustificados,',\n",
              "   'tokens': [50664,\n",
              "    9377,\n",
              "    8600,\n",
              "    11,\n",
              "    4768,\n",
              "    23496,\n",
              "    2502,\n",
              "    299,\n",
              "    425,\n",
              "    3192,\n",
              "    42797,\n",
              "    11,\n",
              "    3343,\n",
              "    11909,\n",
              "    14182,\n",
              "    3211,\n",
              "    11581,\n",
              "    368,\n",
              "    16848,\n",
              "    6872,\n",
              "    416,\n",
              "    1262,\n",
              "    81,\n",
              "    1753,\n",
              "    279,\n",
              "    288,\n",
              "    1189,\n",
              "    2213,\n",
              "    11,\n",
              "    416,\n",
              "    4111,\n",
              "    5402,\n",
              "    1089,\n",
              "    4181,\n",
              "    11,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.510879140504649,\n",
              "   'compression_ratio': 1.3058823529411765,\n",
              "   'no_speech_prob': 0.0351121686398983},\n",
              "  {'id': 113,\n",
              "   'seek': 113740,\n",
              "   'start': 1137.4,\n",
              "   'end': 1145.4,\n",
              "   'text': ' entonces ya está avisando que, también si lo que único que queréis hacerle un post a la lista de, no sé qué pública, no hace falta,',\n",
              "   'tokens': [50364,\n",
              "    13003,\n",
              "    2478,\n",
              "    3192,\n",
              "    34588,\n",
              "    1806,\n",
              "    631,\n",
              "    11,\n",
              "    6407,\n",
              "    1511,\n",
              "    450,\n",
              "    631,\n",
              "    26113,\n",
              "    631,\n",
              "    7083,\n",
              "    15064,\n",
              "    6720,\n",
              "    306,\n",
              "    517,\n",
              "    2183,\n",
              "    257,\n",
              "    635,\n",
              "    27764,\n",
              "    368,\n",
              "    11,\n",
              "    572,\n",
              "    7910,\n",
              "    8057,\n",
              "    38905,\n",
              "    11,\n",
              "    572,\n",
              "    10032,\n",
              "    22111,\n",
              "    11,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3928170860360522,\n",
              "   'compression_ratio': 1.6081632653061224,\n",
              "   'no_speech_prob': 0.2304597944021225},\n",
              "  {'id': 114,\n",
              "   'seek': 113740,\n",
              "   'start': 1145.4,\n",
              "   'end': 1155.4,\n",
              "   'text': ' pero capaz de una vez que más microsaricios, donde queréis hacer docenas de concurrentes ricos, si tenés advanced developers que se la banquen,',\n",
              "   'tokens': [50764,\n",
              "    4768,\n",
              "    35453,\n",
              "    368,\n",
              "    2002,\n",
              "    5715,\n",
              "    631,\n",
              "    3573,\n",
              "    3123,\n",
              "    2635,\n",
              "    289,\n",
              "    26817,\n",
              "    11,\n",
              "    10488,\n",
              "    7083,\n",
              "    15064,\n",
              "    6720,\n",
              "    3211,\n",
              "    11581,\n",
              "    368,\n",
              "    37702,\n",
              "    279,\n",
              "    367,\n",
              "    9940,\n",
              "    11,\n",
              "    1511,\n",
              "    2064,\n",
              "    2191,\n",
              "    7339,\n",
              "    8849,\n",
              "    631,\n",
              "    369,\n",
              "    635,\n",
              "    5643,\n",
              "    358,\n",
              "    268,\n",
              "    11,\n",
              "    51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3928170860360522,\n",
              "   'compression_ratio': 1.6081632653061224,\n",
              "   'no_speech_prob': 0.2304597944021225},\n",
              "  {'id': 115,\n",
              "   'seek': 113740,\n",
              "   'start': 1155.4,\n",
              "   'end': 1157.4,\n",
              "   'text': ' puede llegar a tener sentido.',\n",
              "   'tokens': [51264, 8919, 24892, 257, 11640, 19850, 13, 51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3928170860360522,\n",
              "   'compression_ratio': 1.6081632653061224,\n",
              "   'no_speech_prob': 0.2304597944021225},\n",
              "  {'id': 116,\n",
              "   'seek': 113740,\n",
              "   'start': 1157.4,\n",
              "   'end': 1161.4,\n",
              "   'text': ' Igual vamos a llegar a esa parte, avance de viguelo, pero sí, vamos a faltar.',\n",
              "   'tokens': [51364,\n",
              "    19271,\n",
              "    901,\n",
              "    5295,\n",
              "    257,\n",
              "    24892,\n",
              "    257,\n",
              "    11342,\n",
              "    6975,\n",
              "    11,\n",
              "    1305,\n",
              "    719,\n",
              "    368,\n",
              "    15366,\n",
              "    3483,\n",
              "    78,\n",
              "    11,\n",
              "    4768,\n",
              "    8600,\n",
              "    11,\n",
              "    5295,\n",
              "    257,\n",
              "    37108,\n",
              "    289,\n",
              "    13,\n",
              "    51564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3928170860360522,\n",
              "   'compression_ratio': 1.6081632653061224,\n",
              "   'no_speech_prob': 0.2304597944021225},\n",
              "  {'id': 117,\n",
              "   'seek': 116140,\n",
              "   'start': 1162.4,\n",
              "   'end': 1170.4,\n",
              "   'text': ' Lo primero que vimos cuando hicimos las pruebas es que ya duplicamos lo que habíamos duplicado.',\n",
              "   'tokens': [50414,\n",
              "    6130,\n",
              "    21289,\n",
              "    631,\n",
              "    49266,\n",
              "    7767,\n",
              "    23697,\n",
              "    8372,\n",
              "    2439,\n",
              "    32820,\n",
              "    16342,\n",
              "    785,\n",
              "    631,\n",
              "    2478,\n",
              "    17154,\n",
              "    2151,\n",
              "    450,\n",
              "    631,\n",
              "    3025,\n",
              "    16275,\n",
              "    17154,\n",
              "    1573,\n",
              "    13,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.35147735476493835,\n",
              "   'compression_ratio': 1.6457564575645756,\n",
              "   'no_speech_prob': 0.05568700656294823},\n",
              "  {'id': 118,\n",
              "   'seek': 116140,\n",
              "   'start': 1170.4,\n",
              "   'end': 1174.4,\n",
              "   'text': ' La verdad está, súper contento, eso tenía muchísimas ganas de implementar esto, decirlo a todo el mundo, por favor,',\n",
              "   'tokens': [50814,\n",
              "    2369,\n",
              "    13692,\n",
              "    3192,\n",
              "    11,\n",
              "    43282,\n",
              "    2701,\n",
              "    78,\n",
              "    11,\n",
              "    7287,\n",
              "    23718,\n",
              "    29353,\n",
              "    17957,\n",
              "    7574,\n",
              "    296,\n",
              "    368,\n",
              "    4445,\n",
              "    289,\n",
              "    7433,\n",
              "    11,\n",
              "    10235,\n",
              "    752,\n",
              "    257,\n",
              "    5149,\n",
              "    806,\n",
              "    7968,\n",
              "    11,\n",
              "    1515,\n",
              "    2294,\n",
              "    11,\n",
              "    51014],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.35147735476493835,\n",
              "   'compression_ratio': 1.6457564575645756,\n",
              "   'no_speech_prob': 0.05568700656294823},\n",
              "  {'id': 119,\n",
              "   'seek': 116140,\n",
              "   'start': 1174.4,\n",
              "   'end': 1182.4,\n",
              "   'text': ' uso paicul, es la que va, me junté con listos, con Javi, un poco analizar el Javi, es un batuchivo de trabajo con nosotros,',\n",
              "   'tokens': [51014,\n",
              "    22728,\n",
              "    2502,\n",
              "    299,\n",
              "    425,\n",
              "    11,\n",
              "    785,\n",
              "    635,\n",
              "    631,\n",
              "    2773,\n",
              "    11,\n",
              "    385,\n",
              "    22739,\n",
              "    526,\n",
              "    416,\n",
              "    1329,\n",
              "    329,\n",
              "    11,\n",
              "    416,\n",
              "    508,\n",
              "    18442,\n",
              "    11,\n",
              "    517,\n",
              "    10639,\n",
              "    2624,\n",
              "    9736,\n",
              "    806,\n",
              "    508,\n",
              "    18442,\n",
              "    11,\n",
              "    785,\n",
              "    517,\n",
              "    7362,\n",
              "    625,\n",
              "    6340,\n",
              "    368,\n",
              "    18099,\n",
              "    416,\n",
              "    13863,\n",
              "    11,\n",
              "    51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.35147735476493835,\n",
              "   'compression_ratio': 1.6457564575645756,\n",
              "   'no_speech_prob': 0.05568700656294823},\n",
              "  {'id': 120,\n",
              "   'seek': 116140,\n",
              "   'start': 1182.4,\n",
              "   'end': 1189.4,\n",
              "   'text': ' analizar esto y empezamos a ver un poco cómo se hace el gays y cómo se usa y no los convencilla mucho.',\n",
              "   'tokens': [51414,\n",
              "    2624,\n",
              "    9736,\n",
              "    7433,\n",
              "    288,\n",
              "    18730,\n",
              "    2151,\n",
              "    257,\n",
              "    1306,\n",
              "    517,\n",
              "    10639,\n",
              "    12826,\n",
              "    369,\n",
              "    10032,\n",
              "    806,\n",
              "    290,\n",
              "    3772,\n",
              "    288,\n",
              "    12826,\n",
              "    369,\n",
              "    29909,\n",
              "    288,\n",
              "    572,\n",
              "    1750,\n",
              "    7158,\n",
              "    66,\n",
              "    5291,\n",
              "    9824,\n",
              "    13,\n",
              "    51764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.35147735476493835,\n",
              "   'compression_ratio': 1.6457564575645756,\n",
              "   'no_speech_prob': 0.05568700656294823},\n",
              "  {'id': 121,\n",
              "   'seek': 118940,\n",
              "   'start': 1190.4,\n",
              "   'end': 1195.4,\n",
              "   'text': ' Esto es importantísimo, el uso de CPU se fue al 0.73%, ¿no?',\n",
              "   'tokens': [50414,\n",
              "    20880,\n",
              "    785,\n",
              "    1021,\n",
              "    49889,\n",
              "    11,\n",
              "    806,\n",
              "    22728,\n",
              "    368,\n",
              "    13199,\n",
              "    369,\n",
              "    9248,\n",
              "    419,\n",
              "    1958,\n",
              "    13,\n",
              "    33396,\n",
              "    4,\n",
              "    11,\n",
              "    3841,\n",
              "    1771,\n",
              "    30,\n",
              "    50664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.30635225772857666,\n",
              "   'compression_ratio': 1.336405529953917,\n",
              "   'no_speech_prob': 0.01383008062839508},\n",
              "  {'id': 122,\n",
              "   'seek': 118940,\n",
              "   'start': 1195.4,\n",
              "   'end': 1203.4,\n",
              "   'text': ' Entonces, la gente que está usando mucho Python hoy en Mercado de Libre hace Machine Learning cada porcentaje de CPU que le liberamos,',\n",
              "   'tokens': [50664,\n",
              "    15097,\n",
              "    11,\n",
              "    635,\n",
              "    3788,\n",
              "    631,\n",
              "    3192,\n",
              "    29798,\n",
              "    9824,\n",
              "    15329,\n",
              "    13775,\n",
              "    465,\n",
              "    18897,\n",
              "    1573,\n",
              "    368,\n",
              "    15834,\n",
              "    265,\n",
              "    10032,\n",
              "    22155,\n",
              "    15205,\n",
              "    8411,\n",
              "    1515,\n",
              "    2207,\n",
              "    11153,\n",
              "    368,\n",
              "    13199,\n",
              "    631,\n",
              "    476,\n",
              "    6774,\n",
              "    2151,\n",
              "    11,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.30635225772857666,\n",
              "   'compression_ratio': 1.336405529953917,\n",
              "   'no_speech_prob': 0.01383008062839508},\n",
              "  {'id': 123,\n",
              "   'seek': 118940,\n",
              "   'start': 1203.4,\n",
              "   'end': 1205.4,\n",
              "   'text': ' es jugo para eso.',\n",
              "   'tokens': [51064, 785, 9568, 78, 1690, 7287, 13, 51164],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.30635225772857666,\n",
              "   'compression_ratio': 1.336405529953917,\n",
              "   'no_speech_prob': 0.01383008062839508},\n",
              "  {'id': 124,\n",
              "   'seek': 118940,\n",
              "   'start': 1205.4,\n",
              "   'end': 1209.4,\n",
              "   'text': ' Entonces, tenemos que salir con esto rápido producción, ¿cómo hacemos?',\n",
              "   'tokens': [51164,\n",
              "    15097,\n",
              "    11,\n",
              "    9914,\n",
              "    631,\n",
              "    31514,\n",
              "    416,\n",
              "    7433,\n",
              "    24893,\n",
              "    48586,\n",
              "    11,\n",
              "    3841,\n",
              "    46614,\n",
              "    33839,\n",
              "    30,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.30635225772857666,\n",
              "   'compression_ratio': 1.336405529953917,\n",
              "   'no_speech_prob': 0.01383008062839508},\n",
              "  {'id': 125,\n",
              "   'seek': 120940,\n",
              "   'start': 1210.4,\n",
              "   'end': 1214.4,\n",
              "   'text': ' Eso es un get en paicul.',\n",
              "   'tokens': [50414, 27795, 785, 517, 483, 465, 2502, 299, 425, 13, 50614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.479285648890904,\n",
              "   'compression_ratio': 1.6217391304347826,\n",
              "   'no_speech_prob': 0.12391006946563721},\n",
              "  {'id': 126,\n",
              "   'seek': 120940,\n",
              "   'start': 1214.4,\n",
              "   'end': 1221.4,\n",
              "   'text': ' Se recuerdan, bueno, todo usa un rico de rico es punto get y ya estás haciendo un get.',\n",
              "   'tokens': [50614,\n",
              "    1100,\n",
              "    39092,\n",
              "    10312,\n",
              "    11,\n",
              "    11974,\n",
              "    11,\n",
              "    5149,\n",
              "    29909,\n",
              "    517,\n",
              "    367,\n",
              "    2789,\n",
              "    368,\n",
              "    367,\n",
              "    2789,\n",
              "    785,\n",
              "    14326,\n",
              "    483,\n",
              "    288,\n",
              "    2478,\n",
              "    24389,\n",
              "    20509,\n",
              "    517,\n",
              "    483,\n",
              "    13,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.479285648890904,\n",
              "   'compression_ratio': 1.6217391304347826,\n",
              "   'no_speech_prob': 0.12391006946563721},\n",
              "  {'id': 127,\n",
              "   'seek': 120940,\n",
              "   'start': 1221.4,\n",
              "   'end': 1230.4,\n",
              "   'text': ' Y acá hay tan color al tovard 1, no sé si un color o un bíavardo significa lo mismo que significa de Argentina.',\n",
              "   'tokens': [50964,\n",
              "    398,\n",
              "    23496,\n",
              "    4842,\n",
              "    7603,\n",
              "    2017,\n",
              "    419,\n",
              "    281,\n",
              "    11303,\n",
              "    502,\n",
              "    11,\n",
              "    572,\n",
              "    7910,\n",
              "    1511,\n",
              "    517,\n",
              "    2017,\n",
              "    277,\n",
              "    517,\n",
              "    272,\n",
              "    870,\n",
              "    706,\n",
              "    289,\n",
              "    2595,\n",
              "    19957,\n",
              "    450,\n",
              "    12461,\n",
              "    631,\n",
              "    19957,\n",
              "    368,\n",
              "    18336,\n",
              "    13,\n",
              "    51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.479285648890904,\n",
              "   'compression_ratio': 1.6217391304347826,\n",
              "   'no_speech_prob': 0.12391006946563721},\n",
              "  {'id': 128,\n",
              "   'seek': 120940,\n",
              "   'start': 1230.4,\n",
              "   'end': 1232.4,\n",
              "   'text': ' Un gran problema, uno.',\n",
              "   'tokens': [51414, 1156, 9370, 12395, 11, 8526, 13, 51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.479285648890904,\n",
              "   'compression_ratio': 1.6217391304347826,\n",
              "   'no_speech_prob': 0.12391006946563721},\n",
              "  {'id': 129,\n",
              "   'seek': 120940,\n",
              "   'start': 1232.4,\n",
              "   'end': 1238.4,\n",
              "   'text': ' Un gran problema, uno, un gran problema, la forma que uno le tiene que pasar los parámetros, no es un diccionario común,',\n",
              "   'tokens': [51514,\n",
              "    1156,\n",
              "    9370,\n",
              "    12395,\n",
              "    11,\n",
              "    8526,\n",
              "    11,\n",
              "    517,\n",
              "    9370,\n",
              "    12395,\n",
              "    11,\n",
              "    635,\n",
              "    8366,\n",
              "    631,\n",
              "    8526,\n",
              "    476,\n",
              "    7066,\n",
              "    631,\n",
              "    25344,\n",
              "    1750,\n",
              "    971,\n",
              "    842,\n",
              "    29570,\n",
              "    11,\n",
              "    572,\n",
              "    785,\n",
              "    517,\n",
              "    14285,\n",
              "    10015,\n",
              "    4912,\n",
              "    45448,\n",
              "    11,\n",
              "    51814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.479285648890904,\n",
              "   'compression_ratio': 1.6217391304347826,\n",
              "   'no_speech_prob': 0.12391006946563721},\n",
              "  {'id': 130,\n",
              "   'seek': 123840,\n",
              "   'start': 1238.4,\n",
              "   'end': 1241.4,\n",
              "   'text': ' realmente es súper complejo, súper confuso.',\n",
              "   'tokens': [50364,\n",
              "    14446,\n",
              "    785,\n",
              "    43282,\n",
              "    44424,\n",
              "    5134,\n",
              "    11,\n",
              "    43282,\n",
              "    1497,\n",
              "    24431,\n",
              "    13,\n",
              "    50514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3353113027719351,\n",
              "   'compression_ratio': 1.583673469387755,\n",
              "   'no_speech_prob': 0.02327137254178524},\n",
              "  {'id': 131,\n",
              "   'seek': 123840,\n",
              "   'start': 1241.4,\n",
              "   'end': 1246.4,\n",
              "   'text': ' Yo hace cinco años estoy con Python y venía que veía esto y decía por qué, por favor, ¿por qué es así?',\n",
              "   'tokens': [50514,\n",
              "    7616,\n",
              "    10032,\n",
              "    21350,\n",
              "    11424,\n",
              "    15796,\n",
              "    416,\n",
              "    15329,\n",
              "    288,\n",
              "    6138,\n",
              "    2686,\n",
              "    631,\n",
              "    1241,\n",
              "    2686,\n",
              "    7433,\n",
              "    288,\n",
              "    37599,\n",
              "    1515,\n",
              "    8057,\n",
              "    11,\n",
              "    1515,\n",
              "    2294,\n",
              "    11,\n",
              "    3841,\n",
              "    2816,\n",
              "    8057,\n",
              "    785,\n",
              "    8582,\n",
              "    30,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3353113027719351,\n",
              "   'compression_ratio': 1.583673469387755,\n",
              "   'no_speech_prob': 0.02327137254178524},\n",
              "  {'id': 132,\n",
              "   'seek': 123840,\n",
              "   'start': 1246.4,\n",
              "   'end': 1254.4,\n",
              "   'text': ' Pero bueno, tiene sus ventaja, tiene la ventaja de duplicar la cantidad rico de URL.3 de uso de CPU,',\n",
              "   'tokens': [50764,\n",
              "    9377,\n",
              "    11974,\n",
              "    11,\n",
              "    7066,\n",
              "    3291,\n",
              "    6931,\n",
              "    12908,\n",
              "    11,\n",
              "    7066,\n",
              "    635,\n",
              "    6931,\n",
              "    12908,\n",
              "    368,\n",
              "    17154,\n",
              "    289,\n",
              "    635,\n",
              "    33757,\n",
              "    367,\n",
              "    2789,\n",
              "    368,\n",
              "    12905,\n",
              "    13,\n",
              "    18,\n",
              "    368,\n",
              "    22728,\n",
              "    368,\n",
              "    13199,\n",
              "    11,\n",
              "    51164],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3353113027719351,\n",
              "   'compression_ratio': 1.583673469387755,\n",
              "   'no_speech_prob': 0.02327137254178524},\n",
              "  {'id': 133,\n",
              "   'seek': 123840,\n",
              "   'start': 1254.4,\n",
              "   'end': 1256.4,\n",
              "   'text': ' tenemos que ver que así vamos.',\n",
              "   'tokens': [51164, 9914, 631, 1306, 631, 8582, 5295, 13, 51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3353113027719351,\n",
              "   'compression_ratio': 1.583673469387755,\n",
              "   'no_speech_prob': 0.02327137254178524},\n",
              "  {'id': 134,\n",
              "   'seek': 123840,\n",
              "   'start': 1256.4,\n",
              "   'end': 1262.4,\n",
              "   'text': ' Creo que el post no se lo puse, bueno, el post, un get en un bardo, el post es doblemente lo ardo.',\n",
              "   'tokens': [51264,\n",
              "    40640,\n",
              "    631,\n",
              "    806,\n",
              "    2183,\n",
              "    572,\n",
              "    369,\n",
              "    450,\n",
              "    280,\n",
              "    438,\n",
              "    11,\n",
              "    11974,\n",
              "    11,\n",
              "    806,\n",
              "    2183,\n",
              "    11,\n",
              "    517,\n",
              "    483,\n",
              "    465,\n",
              "    517,\n",
              "    272,\n",
              "    12850,\n",
              "    11,\n",
              "    806,\n",
              "    2183,\n",
              "    785,\n",
              "    360,\n",
              "    638,\n",
              "    4082,\n",
              "    450,\n",
              "    594,\n",
              "    2595,\n",
              "    13,\n",
              "    51564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3353113027719351,\n",
              "   'compression_ratio': 1.583673469387755,\n",
              "   'no_speech_prob': 0.02327137254178524},\n",
              "  {'id': 135,\n",
              "   'seek': 126240,\n",
              "   'start': 1262.4,\n",
              "   'end': 1269.4,\n",
              "   'text': ' Imagínense te estía a éso, es como te estío este de pedase código, como reparto este código en 300, 400 aplicaciones.',\n",
              "   'tokens': [50364,\n",
              "    34223,\n",
              "    10973,\n",
              "    1288,\n",
              "    535,\n",
              "    871,\n",
              "    2686,\n",
              "    257,\n",
              "    1136,\n",
              "    539,\n",
              "    11,\n",
              "    785,\n",
              "    2617,\n",
              "    535,\n",
              "    871,\n",
              "    20492,\n",
              "    4065,\n",
              "    368,\n",
              "    5670,\n",
              "    651,\n",
              "    44195,\n",
              "    11,\n",
              "    2617,\n",
              "    1085,\n",
              "    15864,\n",
              "    4065,\n",
              "    44195,\n",
              "    465,\n",
              "    6641,\n",
              "    11,\n",
              "    8423,\n",
              "    18221,\n",
              "    9188,\n",
              "    13,\n",
              "    50714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.40992291768391925,\n",
              "   'compression_ratio': 1.694078947368421,\n",
              "   'no_speech_prob': 0.19408643245697021},\n",
              "  {'id': 136,\n",
              "   'seek': 126240,\n",
              "   'start': 1269.4,\n",
              "   'end': 1271.4,\n",
              "   'text': ' Es muy difícil.',\n",
              "   'tokens': [50714, 2313, 5323, 17258, 13, 50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.40992291768391925,\n",
              "   'compression_ratio': 1.694078947368421,\n",
              "   'no_speech_prob': 0.19408643245697021},\n",
              "  {'id': 137,\n",
              "   'seek': 126240,\n",
              "   'start': 1271.4,\n",
              "   'end': 1275.4,\n",
              "   'text': ' Te he ganado de cuenta de que todos conocen ricos, nosotros también conocemos ricos.',\n",
              "   'tokens': [50814,\n",
              "    1989,\n",
              "    415,\n",
              "    7574,\n",
              "    1573,\n",
              "    368,\n",
              "    17868,\n",
              "    368,\n",
              "    631,\n",
              "    6321,\n",
              "    15871,\n",
              "    268,\n",
              "    367,\n",
              "    9940,\n",
              "    11,\n",
              "    13863,\n",
              "    6407,\n",
              "    15871,\n",
              "    4485,\n",
              "    367,\n",
              "    9940,\n",
              "    13,\n",
              "    51014],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.40992291768391925,\n",
              "   'compression_ratio': 1.694078947368421,\n",
              "   'no_speech_prob': 0.19408643245697021},\n",
              "  {'id': 138,\n",
              "   'seek': 126240,\n",
              "   'start': 1275.4,\n",
              "   'end': 1278.4,\n",
              "   'text': ' Entonces, ¿cómo tienes que hacer una solución?',\n",
              "   'tokens': [51014,\n",
              "    15097,\n",
              "    11,\n",
              "    3841,\n",
              "    46614,\n",
              "    20716,\n",
              "    631,\n",
              "    6720,\n",
              "    2002,\n",
              "    24807,\n",
              "    5687,\n",
              "    30,\n",
              "    51164],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.40992291768391925,\n",
              "   'compression_ratio': 1.694078947368421,\n",
              "   'no_speech_prob': 0.19408643245697021},\n",
              "  {'id': 139,\n",
              "   'seek': 126240,\n",
              "   'start': 1278.4,\n",
              "   'end': 1282.4,\n",
              "   'text': ' ¿Ustedes ricos? El momento 0, no te lo preguntaste, lo cual es un problema en un contexto productivo,',\n",
              "   'tokens': [51164,\n",
              "    3841,\n",
              "    52,\n",
              "    30115,\n",
              "    279,\n",
              "    367,\n",
              "    9940,\n",
              "    30,\n",
              "    2699,\n",
              "    9333,\n",
              "    1958,\n",
              "    11,\n",
              "    572,\n",
              "    535,\n",
              "    450,\n",
              "    19860,\n",
              "    9079,\n",
              "    11,\n",
              "    450,\n",
              "    10911,\n",
              "    785,\n",
              "    517,\n",
              "    12395,\n",
              "    465,\n",
              "    517,\n",
              "    47685,\n",
              "    1674,\n",
              "    6340,\n",
              "    11,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.40992291768391925,\n",
              "   'compression_ratio': 1.694078947368421,\n",
              "   'no_speech_prob': 0.19408643245697021},\n",
              "  {'id': 140,\n",
              "   'seek': 126240,\n",
              "   'start': 1282.4,\n",
              "   'end': 1285.4,\n",
              "   'text': ' si están haciendo un apoc, si están haciendo un prototipo, si están haciendo una prueba,',\n",
              "   'tokens': [51364,\n",
              "    1511,\n",
              "    10368,\n",
              "    20509,\n",
              "    517,\n",
              "    1882,\n",
              "    905,\n",
              "    11,\n",
              "    1511,\n",
              "    10368,\n",
              "    20509,\n",
              "    517,\n",
              "    1742,\n",
              "    310,\n",
              "    647,\n",
              "    78,\n",
              "    11,\n",
              "    1511,\n",
              "    10368,\n",
              "    20509,\n",
              "    2002,\n",
              "    48241,\n",
              "    11,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.40992291768391925,\n",
              "   'compression_ratio': 1.694078947368421,\n",
              "   'no_speech_prob': 0.19408643245697021},\n",
              "  {'id': 141,\n",
              "   'seek': 126240,\n",
              "   'start': 1285.4,\n",
              "   'end': 1287.4,\n",
              "   'text': ' hay preguntas que no necesitan trabajarnos.',\n",
              "   'tokens': [51514,\n",
              "    4842,\n",
              "    39722,\n",
              "    631,\n",
              "    572,\n",
              "    11909,\n",
              "    9670,\n",
              "    9618,\n",
              "    24979,\n",
              "    13,\n",
              "    51614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.40992291768391925,\n",
              "   'compression_ratio': 1.694078947368421,\n",
              "   'no_speech_prob': 0.19408643245697021},\n",
              "  {'id': 142,\n",
              "   'seek': 128740,\n",
              "   'start': 1288.4,\n",
              "   'end': 1292.4,\n",
              "   'text': ' Pero cuando vamos a un entorno productivo, sobre todo de escala, tenemos que ser mucho más detallados.',\n",
              "   'tokens': [50414,\n",
              "    9377,\n",
              "    7767,\n",
              "    5295,\n",
              "    257,\n",
              "    517,\n",
              "    948,\n",
              "    21998,\n",
              "    1674,\n",
              "    6340,\n",
              "    11,\n",
              "    5473,\n",
              "    5149,\n",
              "    368,\n",
              "    4721,\n",
              "    5159,\n",
              "    11,\n",
              "    9914,\n",
              "    631,\n",
              "    816,\n",
              "    9824,\n",
              "    3573,\n",
              "    1141,\n",
              "    336,\n",
              "    4181,\n",
              "    13,\n",
              "    50614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.28540998109629456,\n",
              "   'compression_ratio': 1.7587412587412588,\n",
              "   'no_speech_prob': 0.25354498624801636},\n",
              "  {'id': 143,\n",
              "   'seek': 128740,\n",
              "   'start': 1292.4,\n",
              "   'end': 1297.4,\n",
              "   'text': ' Entonces, haber el ejido rico es como librería de comunicación entre procesos, es de dotécquia.',\n",
              "   'tokens': [50614,\n",
              "    15097,\n",
              "    11,\n",
              "    15811,\n",
              "    806,\n",
              "    10012,\n",
              "    2925,\n",
              "    367,\n",
              "    2789,\n",
              "    785,\n",
              "    2617,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    368,\n",
              "    31710,\n",
              "    3482,\n",
              "    3962,\n",
              "    17565,\n",
              "    329,\n",
              "    11,\n",
              "    785,\n",
              "    368,\n",
              "    5893,\n",
              "    9062,\n",
              "    358,\n",
              "    654,\n",
              "    13,\n",
              "    50864],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.28540998109629456,\n",
              "   'compression_ratio': 1.7587412587412588,\n",
              "   'no_speech_prob': 0.25354498624801636},\n",
              "  {'id': 144,\n",
              "   'seek': 128740,\n",
              "   'start': 1297.4,\n",
              "   'end': 1303.4,\n",
              "   'text': ' Es cierto. Bien, es un riesgo que estamos tomando y que en algún momento nos puede costar',\n",
              "   'tokens': [50864,\n",
              "    2313,\n",
              "    28558,\n",
              "    13,\n",
              "    16956,\n",
              "    11,\n",
              "    785,\n",
              "    517,\n",
              "    23932,\n",
              "    1571,\n",
              "    631,\n",
              "    10382,\n",
              "    2916,\n",
              "    1806,\n",
              "    288,\n",
              "    631,\n",
              "    465,\n",
              "    26300,\n",
              "    9333,\n",
              "    3269,\n",
              "    8919,\n",
              "    2063,\n",
              "    289,\n",
              "    51164],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.28540998109629456,\n",
              "   'compression_ratio': 1.7587412587412588,\n",
              "   'no_speech_prob': 0.25354498624801636},\n",
              "  {'id': 145,\n",
              "   'seek': 128740,\n",
              "   'start': 1303.4,\n",
              "   'end': 1307.4,\n",
              "   'text': ' y que en algún momento ese costo, como cualquier deuda, con sus hitéres se va a hacer más caro.',\n",
              "   'tokens': [51164,\n",
              "    288,\n",
              "    631,\n",
              "    465,\n",
              "    26300,\n",
              "    9333,\n",
              "    10167,\n",
              "    2063,\n",
              "    78,\n",
              "    11,\n",
              "    2617,\n",
              "    21004,\n",
              "    368,\n",
              "    11152,\n",
              "    11,\n",
              "    416,\n",
              "    3291,\n",
              "    2045,\n",
              "    526,\n",
              "    495,\n",
              "    369,\n",
              "    2773,\n",
              "    257,\n",
              "    6720,\n",
              "    3573,\n",
              "    1032,\n",
              "    78,\n",
              "    13,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.28540998109629456,\n",
              "   'compression_ratio': 1.7587412587412588,\n",
              "   'no_speech_prob': 0.25354498624801636},\n",
              "  {'id': 146,\n",
              "   'seek': 128740,\n",
              "   'start': 1307.4,\n",
              "   'end': 1310.4,\n",
              "   'text': ' Bien, y nosotros no nos dimos cuenta.',\n",
              "   'tokens': [51364,\n",
              "    16956,\n",
              "    11,\n",
              "    288,\n",
              "    13863,\n",
              "    572,\n",
              "    3269,\n",
              "    5013,\n",
              "    329,\n",
              "    17868,\n",
              "    13,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.28540998109629456,\n",
              "   'compression_ratio': 1.7587412587412588,\n",
              "   'no_speech_prob': 0.25354498624801636},\n",
              "  {'id': 147,\n",
              "   'seek': 128740,\n",
              "   'start': 1310.4,\n",
              "   'end': 1315.4,\n",
              "   'text': ' Y nos dimos cuenta cuando nos dimos cuenta que hay que implementar esto.',\n",
              "   'tokens': [51514,\n",
              "    398,\n",
              "    3269,\n",
              "    5013,\n",
              "    329,\n",
              "    17868,\n",
              "    7767,\n",
              "    3269,\n",
              "    5013,\n",
              "    329,\n",
              "    17868,\n",
              "    631,\n",
              "    4842,\n",
              "    631,\n",
              "    4445,\n",
              "    289,\n",
              "    7433,\n",
              "    13,\n",
              "    51764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.28540998109629456,\n",
              "   'compression_ratio': 1.7587412587412588,\n",
              "   'no_speech_prob': 0.25354498624801636},\n",
              "  {'id': 148,\n",
              "   'seek': 131540,\n",
              "   'start': 1316.4,\n",
              "   'end': 1322.4,\n",
              "   'text': ' Con cada rico es que teníamos en cada una de los, hoy por hoy, cientos de microsavicios desplegados en Python que tenemos.',\n",
              "   'tokens': [50414,\n",
              "    2656,\n",
              "    8411,\n",
              "    367,\n",
              "    2789,\n",
              "    785,\n",
              "    631,\n",
              "    2064,\n",
              "    16275,\n",
              "    465,\n",
              "    8411,\n",
              "    2002,\n",
              "    368,\n",
              "    1750,\n",
              "    11,\n",
              "    13775,\n",
              "    1515,\n",
              "    13775,\n",
              "    11,\n",
              "    269,\n",
              "    20370,\n",
              "    368,\n",
              "    15547,\n",
              "    706,\n",
              "    26817,\n",
              "    730,\n",
              "    781,\n",
              "    70,\n",
              "    4181,\n",
              "    465,\n",
              "    15329,\n",
              "    631,\n",
              "    9914,\n",
              "    13,\n",
              "    50714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.37958436853745403,\n",
              "   'compression_ratio': 1.4973262032085561,\n",
              "   'no_speech_prob': 0.0034814004320651293},\n",
              "  {'id': 149,\n",
              "   'seek': 131540,\n",
              "   'start': 1322.4,\n",
              "   'end': 1327.4,\n",
              "   'text': ' Son muchos equipos de trabajo trabajando y si cada una de esos equipos se le digo, ¿es Alinea?',\n",
              "   'tokens': [50714,\n",
              "    5185,\n",
              "    17061,\n",
              "    5037,\n",
              "    329,\n",
              "    368,\n",
              "    18099,\n",
              "    40473,\n",
              "    288,\n",
              "    1511,\n",
              "    8411,\n",
              "    2002,\n",
              "    368,\n",
              "    22411,\n",
              "    5037,\n",
              "    329,\n",
              "    369,\n",
              "    476,\n",
              "    22990,\n",
              "    11,\n",
              "    3841,\n",
              "    279,\n",
              "    967,\n",
              "    533,\n",
              "    64,\n",
              "    30,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.37958436853745403,\n",
              "   'compression_ratio': 1.4973262032085561,\n",
              "   'no_speech_prob': 0.0034814004320651293},\n",
              "  {'id': 150,\n",
              "   'seek': 131540,\n",
              "   'start': 1327.4,\n",
              "   'end': 1332.4,\n",
              "   'text': ' No, no, reclasas las por estas 75 que tenemos acá. Y listo.',\n",
              "   'tokens': [50964,\n",
              "    883,\n",
              "    11,\n",
              "    572,\n",
              "    11,\n",
              "    850,\n",
              "    7743,\n",
              "    296,\n",
              "    2439,\n",
              "    1515,\n",
              "    13897,\n",
              "    9562,\n",
              "    631,\n",
              "    9914,\n",
              "    23496,\n",
              "    13,\n",
              "    398,\n",
              "    1329,\n",
              "    78,\n",
              "    13,\n",
              "    51214],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.37958436853745403,\n",
              "   'compression_ratio': 1.4973262032085561,\n",
              "   'no_speech_prob': 0.0034814004320651293},\n",
              "  {'id': 151,\n",
              "   'seek': 133240,\n",
              "   'start': 1333.4,\n",
              "   'end': 1344.4,\n",
              "   'text': ' O otra cosa que teníamos en Python y que era súper interesante y no logramos hacer con ricos y vos relic tres.',\n",
              "   'tokens': [50414,\n",
              "    422,\n",
              "    13623,\n",
              "    10163,\n",
              "    631,\n",
              "    2064,\n",
              "    16275,\n",
              "    465,\n",
              "    15329,\n",
              "    288,\n",
              "    631,\n",
              "    4249,\n",
              "    43282,\n",
              "    36396,\n",
              "    288,\n",
              "    572,\n",
              "    450,\n",
              "    1342,\n",
              "    329,\n",
              "    6720,\n",
              "    416,\n",
              "    367,\n",
              "    9940,\n",
              "    288,\n",
              "    13845,\n",
              "    1039,\n",
              "    299,\n",
              "    15890,\n",
              "    13,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.31584290613102006,\n",
              "   'compression_ratio': 1.5449735449735449,\n",
              "   'no_speech_prob': 0.040811292827129364},\n",
              "  {'id': 152,\n",
              "   'seek': 133240,\n",
              "   'start': 1344.4,\n",
              "   'end': 1350.4,\n",
              "   'text': ' En un entorno productivo hacer monitoring es súper importante medir.',\n",
              "   'tokens': [50964,\n",
              "    2193,\n",
              "    517,\n",
              "    948,\n",
              "    21998,\n",
              "    1674,\n",
              "    6340,\n",
              "    6720,\n",
              "    6002,\n",
              "    278,\n",
              "    785,\n",
              "    43282,\n",
              "    9416,\n",
              "    1205,\n",
              "    347,\n",
              "    13,\n",
              "    51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.31584290613102006,\n",
              "   'compression_ratio': 1.5449735449735449,\n",
              "   'no_speech_prob': 0.040811292827129364},\n",
              "  {'id': 153,\n",
              "   'seek': 133240,\n",
              "   'start': 1350.4,\n",
              "   'end': 1357.4,\n",
              "   'text': ' Hay que medir todo lo que se pueda. En mercado de libre nos gusta medir mucho y medimos cada cosa que sucede.',\n",
              "   'tokens': [51264,\n",
              "    8721,\n",
              "    631,\n",
              "    1205,\n",
              "    347,\n",
              "    5149,\n",
              "    450,\n",
              "    631,\n",
              "    369,\n",
              "    31907,\n",
              "    13,\n",
              "    2193,\n",
              "    24775,\n",
              "    368,\n",
              "    29976,\n",
              "    3269,\n",
              "    20576,\n",
              "    1205,\n",
              "    347,\n",
              "    9824,\n",
              "    288,\n",
              "    1205,\n",
              "    8372,\n",
              "    8411,\n",
              "    10163,\n",
              "    631,\n",
              "    459,\n",
              "    29815,\n",
              "    13,\n",
              "    51614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.31584290613102006,\n",
              "   'compression_ratio': 1.5449735449735449,\n",
              "   'no_speech_prob': 0.040811292827129364},\n",
              "  {'id': 154,\n",
              "   'seek': 135740,\n",
              "   'start': 1358.4,\n",
              "   'end': 1365.4,\n",
              "   'text': ' Si val de NES, nos queremos medir por cada rico, es que sale cuánto tiempo tardó en ir y volver al NES.',\n",
              "   'tokens': [50414,\n",
              "    4909,\n",
              "    1323,\n",
              "    368,\n",
              "    37212,\n",
              "    11,\n",
              "    3269,\n",
              "    26813,\n",
              "    1205,\n",
              "    347,\n",
              "    1515,\n",
              "    8411,\n",
              "    367,\n",
              "    2789,\n",
              "    11,\n",
              "    785,\n",
              "    631,\n",
              "    8680,\n",
              "    44256,\n",
              "    78,\n",
              "    11772,\n",
              "    21057,\n",
              "    812,\n",
              "    465,\n",
              "    3418,\n",
              "    288,\n",
              "    33998,\n",
              "    419,\n",
              "    37212,\n",
              "    13,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27670523994847346,\n",
              "   'compression_ratio': 1.688259109311741,\n",
              "   'no_speech_prob': 0.38001593947410583},\n",
              "  {'id': 155,\n",
              "   'seek': 135740,\n",
              "   'start': 1365.4,\n",
              "   'end': 1369.4,\n",
              "   'text': ' Si hay una conexión cuánto tiempo se tardó en establecer esa conexión.',\n",
              "   'tokens': [50764,\n",
              "    4909,\n",
              "    4842,\n",
              "    2002,\n",
              "    49509,\n",
              "    2560,\n",
              "    44256,\n",
              "    78,\n",
              "    11772,\n",
              "    369,\n",
              "    21057,\n",
              "    812,\n",
              "    465,\n",
              "    37444,\n",
              "    1776,\n",
              "    11342,\n",
              "    49509,\n",
              "    2560,\n",
              "    13,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27670523994847346,\n",
              "   'compression_ratio': 1.688259109311741,\n",
              "   'no_speech_prob': 0.38001593947410583},\n",
              "  {'id': 156,\n",
              "   'seek': 135740,\n",
              "   'start': 1369.4,\n",
              "   'end': 1376.4,\n",
              "   'text': ' Si el Payload cuánto tiempo tardó, todos esos detalles en librerías de bajo nivel como parical podíamos obtener las y en el de alto nivel,',\n",
              "   'tokens': [50964,\n",
              "    4909,\n",
              "    806,\n",
              "    11431,\n",
              "    2907,\n",
              "    44256,\n",
              "    78,\n",
              "    11772,\n",
              "    21057,\n",
              "    812,\n",
              "    11,\n",
              "    6321,\n",
              "    22411,\n",
              "    1141,\n",
              "    37927,\n",
              "    465,\n",
              "    4939,\n",
              "    260,\n",
              "    10025,\n",
              "    368,\n",
              "    30139,\n",
              "    24423,\n",
              "    2617,\n",
              "    971,\n",
              "    804,\n",
              "    2497,\n",
              "    16275,\n",
              "    28326,\n",
              "    260,\n",
              "    2439,\n",
              "    288,\n",
              "    465,\n",
              "    806,\n",
              "    368,\n",
              "    21275,\n",
              "    24423,\n",
              "    11,\n",
              "    51314],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27670523994847346,\n",
              "   'compression_ratio': 1.688259109311741,\n",
              "   'no_speech_prob': 0.38001593947410583},\n",
              "  {'id': 157,\n",
              "   'seek': 135740,\n",
              "   'start': 1376.4,\n",
              "   'end': 1380.4,\n",
              "   'text': ' realmente teníamos de entrar a muyificar el código en la librería y era bastante complejo.',\n",
              "   'tokens': [51314,\n",
              "    14446,\n",
              "    2064,\n",
              "    16275,\n",
              "    368,\n",
              "    20913,\n",
              "    257,\n",
              "    5323,\n",
              "    25625,\n",
              "    806,\n",
              "    44195,\n",
              "    465,\n",
              "    635,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    288,\n",
              "    4249,\n",
              "    14651,\n",
              "    44424,\n",
              "    5134,\n",
              "    13,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27670523994847346,\n",
              "   'compression_ratio': 1.688259109311741,\n",
              "   'no_speech_prob': 0.38001593947410583},\n",
              "  {'id': 158,\n",
              "   'seek': 138040,\n",
              "   'start': 1380.4,\n",
              "   'end': 1391.4,\n",
              "   'text': ' Entonces hay un poco gran y veíamos como la ventaja de poder monitorir muchísimo mejor los microservicios que te veníamos y era otra cosa a favor que nos decíamos que tenemos aquí por este camino.',\n",
              "   'tokens': [50364,\n",
              "    15097,\n",
              "    4842,\n",
              "    517,\n",
              "    10639,\n",
              "    9370,\n",
              "    288,\n",
              "    1241,\n",
              "    16275,\n",
              "    2617,\n",
              "    635,\n",
              "    6931,\n",
              "    12908,\n",
              "    368,\n",
              "    8152,\n",
              "    6002,\n",
              "    347,\n",
              "    44722,\n",
              "    11479,\n",
              "    1750,\n",
              "    15547,\n",
              "    1978,\n",
              "    26817,\n",
              "    631,\n",
              "    535,\n",
              "    6138,\n",
              "    16275,\n",
              "    288,\n",
              "    4249,\n",
              "    13623,\n",
              "    10163,\n",
              "    257,\n",
              "    2294,\n",
              "    631,\n",
              "    3269,\n",
              "    979,\n",
              "    16275,\n",
              "    631,\n",
              "    9914,\n",
              "    6661,\n",
              "    1515,\n",
              "    4065,\n",
              "    34124,\n",
              "    13,\n",
              "    50914],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.39661366888817323,\n",
              "   'compression_ratio': 1.4154929577464788,\n",
              "   'no_speech_prob': 0.03616102784872055},\n",
              "  {'id': 159,\n",
              "   'seek': 139140,\n",
              "   'start': 1392.4,\n",
              "   'end': 1397.4,\n",
              "   'text': ' Si oto.',\n",
              "   'tokens': [50414, 4909, 277, 1353, 13, 50664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.46215145111083983,\n",
              "   'compression_ratio': 1.6018099547511313,\n",
              "   'no_speech_prob': 0.1706283986568451},\n",
              "  {'id': 160,\n",
              "   'seek': 139140,\n",
              "   'start': 1397.4,\n",
              "   'end': 1405.4,\n",
              "   'text': ' Insay, un poco lo que veníamos charlando, lo que veníamos contando. Ricos desde alto nivel, está buenísimo para empezar.',\n",
              "   'tokens': [50664,\n",
              "    9442,\n",
              "    320,\n",
              "    11,\n",
              "    517,\n",
              "    10639,\n",
              "    450,\n",
              "    631,\n",
              "    6138,\n",
              "    16275,\n",
              "    1290,\n",
              "    16201,\n",
              "    11,\n",
              "    450,\n",
              "    631,\n",
              "    6138,\n",
              "    16275,\n",
              "    660,\n",
              "    1806,\n",
              "    13,\n",
              "    497,\n",
              "    9940,\n",
              "    10188,\n",
              "    21275,\n",
              "    24423,\n",
              "    11,\n",
              "    3192,\n",
              "    30037,\n",
              "    49889,\n",
              "    1690,\n",
              "    31168,\n",
              "    13,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.46215145111083983,\n",
              "   'compression_ratio': 1.6018099547511313,\n",
              "   'no_speech_prob': 0.1706283986568451},\n",
              "  {'id': 161,\n",
              "   'seek': 139140,\n",
              "   'start': 1405.4,\n",
              "   'end': 1411.4,\n",
              "   'text': ' Está buenísimo si una cedata science tiene que hacer algunas búsqueda.',\n",
              "   'tokens': [51064,\n",
              "    27304,\n",
              "    30037,\n",
              "    49889,\n",
              "    1511,\n",
              "    2002,\n",
              "    269,\n",
              "    292,\n",
              "    3274,\n",
              "    3497,\n",
              "    7066,\n",
              "    631,\n",
              "    6720,\n",
              "    27316,\n",
              "    272,\n",
              "    10227,\n",
              "    358,\n",
              "    8801,\n",
              "    13,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.46215145111083983,\n",
              "   'compression_ratio': 1.6018099547511313,\n",
              "   'no_speech_prob': 0.1706283986568451},\n",
              "  {'id': 162,\n",
              "   'seek': 139140,\n",
              "   'start': 1411.4,\n",
              "   'end': 1418.4,\n",
              "   'text': ' No quiero un mail que me diga después che, mi giste paico de buenísimo, mirad, tenía que hacer un rico google para sacar algo estuve tres días.',\n",
              "   'tokens': [51364,\n",
              "    883,\n",
              "    16811,\n",
              "    517,\n",
              "    10071,\n",
              "    631,\n",
              "    385,\n",
              "    2528,\n",
              "    64,\n",
              "    15283,\n",
              "    947,\n",
              "    11,\n",
              "    2752,\n",
              "    290,\n",
              "    8375,\n",
              "    2502,\n",
              "    2789,\n",
              "    368,\n",
              "    30037,\n",
              "    49889,\n",
              "    11,\n",
              "    3149,\n",
              "    345,\n",
              "    11,\n",
              "    23718,\n",
              "    631,\n",
              "    6720,\n",
              "    517,\n",
              "    41529,\n",
              "    20742,\n",
              "    1690,\n",
              "    43823,\n",
              "    8655,\n",
              "    871,\n",
              "    31564,\n",
              "    15890,\n",
              "    19527,\n",
              "    13,\n",
              "    51714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.46215145111083983,\n",
              "   'compression_ratio': 1.6018099547511313,\n",
              "   'no_speech_prob': 0.1706283986568451},\n",
              "  {'id': 163,\n",
              "   'seek': 141840,\n",
              "   'start': 1419.4,\n",
              "   'end': 1427.4,\n",
              "   'text': ' No estamos vendiendo eso. Ricos es un excelente herramienta para utilizarla en el contexto que se tiene que utilizar.',\n",
              "   'tokens': [50414,\n",
              "    883,\n",
              "    10382,\n",
              "    10169,\n",
              "    7304,\n",
              "    7287,\n",
              "    13,\n",
              "    497,\n",
              "    9940,\n",
              "    785,\n",
              "    517,\n",
              "    24015,\n",
              "    1576,\n",
              "    38271,\n",
              "    64,\n",
              "    1690,\n",
              "    24060,\n",
              "    875,\n",
              "    465,\n",
              "    806,\n",
              "    47685,\n",
              "    631,\n",
              "    369,\n",
              "    7066,\n",
              "    631,\n",
              "    24060,\n",
              "    13,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.15785971632948867,\n",
              "   'compression_ratio': 1.7174721189591078,\n",
              "   'no_speech_prob': 0.15800835192203522},\n",
              "  {'id': 164,\n",
              "   'seek': 141840,\n",
              "   'start': 1427.4,\n",
              "   'end': 1436.4,\n",
              "   'text': ' Hay opciones de optimizaciones, hay que leerla, a mí me he dado mucho la atención que la opción de optimización de esto decision en Ricos está en uso avanzado.',\n",
              "   'tokens': [50814,\n",
              "    8721,\n",
              "    999,\n",
              "    23469,\n",
              "    368,\n",
              "    5028,\n",
              "    590,\n",
              "    9188,\n",
              "    11,\n",
              "    4842,\n",
              "    631,\n",
              "    34172,\n",
              "    875,\n",
              "    11,\n",
              "    257,\n",
              "    14692,\n",
              "    385,\n",
              "    415,\n",
              "    29568,\n",
              "    9824,\n",
              "    635,\n",
              "    33488,\n",
              "    631,\n",
              "    635,\n",
              "    999,\n",
              "    5687,\n",
              "    368,\n",
              "    5028,\n",
              "    27603,\n",
              "    368,\n",
              "    7433,\n",
              "    3537,\n",
              "    465,\n",
              "    497,\n",
              "    9940,\n",
              "    3192,\n",
              "    465,\n",
              "    22728,\n",
              "    42444,\n",
              "    1573,\n",
              "    13,\n",
              "    51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.15785971632948867,\n",
              "   'compression_ratio': 1.7174721189591078,\n",
              "   'no_speech_prob': 0.15800835192203522},\n",
              "  {'id': 165,\n",
              "   'seek': 141840,\n",
              "   'start': 1436.4,\n",
              "   'end': 1445.4,\n",
              "   'text': ' Personalmente considero que no están avanzados, me parece bastante sencillo poder utilizar un feature como eso, capaz que entender en el fondo que lo que hace puede ser complejo,',\n",
              "   'tokens': [51264,\n",
              "    25317,\n",
              "    4082,\n",
              "    1949,\n",
              "    78,\n",
              "    631,\n",
              "    572,\n",
              "    10368,\n",
              "    42444,\n",
              "    4181,\n",
              "    11,\n",
              "    385,\n",
              "    14120,\n",
              "    14651,\n",
              "    46749,\n",
              "    78,\n",
              "    8152,\n",
              "    24060,\n",
              "    517,\n",
              "    4111,\n",
              "    2617,\n",
              "    7287,\n",
              "    11,\n",
              "    35453,\n",
              "    631,\n",
              "    20054,\n",
              "    465,\n",
              "    806,\n",
              "    38101,\n",
              "    631,\n",
              "    450,\n",
              "    631,\n",
              "    10032,\n",
              "    8919,\n",
              "    816,\n",
              "    44424,\n",
              "    5134,\n",
              "    11,\n",
              "    51714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.15785971632948867,\n",
              "   'compression_ratio': 1.7174721189591078,\n",
              "   'no_speech_prob': 0.15800835192203522},\n",
              "  {'id': 166,\n",
              "   'seek': 144540,\n",
              "   'start': 1446.4,\n",
              "   'end': 1449.4,\n",
              "   'text': ' pero como feature de la librería es algo relativamente básico.',\n",
              "   'tokens': [50414,\n",
              "    4768,\n",
              "    2617,\n",
              "    4111,\n",
              "    368,\n",
              "    635,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    785,\n",
              "    8655,\n",
              "    21960,\n",
              "    3439,\n",
              "    25545,\n",
              "    2789,\n",
              "    13,\n",
              "    50564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.382984504699707,\n",
              "   'compression_ratio': 1.6554621848739495,\n",
              "   'no_speech_prob': 0.034038934856653214},\n",
              "  {'id': 167,\n",
              "   'seek': 144540,\n",
              "   'start': 1449.4,\n",
              "   'end': 1458.4,\n",
              "   'text': ' Como toda optimización, siempre, avoy de early optimization, early optimization, is the root of all evil, dijo algún viejo pop de la informática.',\n",
              "   'tokens': [50564,\n",
              "    11913,\n",
              "    11687,\n",
              "    5028,\n",
              "    27603,\n",
              "    11,\n",
              "    12758,\n",
              "    11,\n",
              "    1305,\n",
              "    939,\n",
              "    368,\n",
              "    2440,\n",
              "    19618,\n",
              "    11,\n",
              "    2440,\n",
              "    19618,\n",
              "    11,\n",
              "    307,\n",
              "    264,\n",
              "    5593,\n",
              "    295,\n",
              "    439,\n",
              "    6724,\n",
              "    11,\n",
              "    27024,\n",
              "    26300,\n",
              "    4941,\n",
              "    5134,\n",
              "    1665,\n",
              "    368,\n",
              "    635,\n",
              "    1356,\n",
              "    23432,\n",
              "    13,\n",
              "    51014],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.382984504699707,\n",
              "   'compression_ratio': 1.6554621848739495,\n",
              "   'no_speech_prob': 0.034038934856653214},\n",
              "  {'id': 168,\n",
              "   'seek': 144540,\n",
              "   'start': 1458.4,\n",
              "   'end': 1467.4,\n",
              "   'text': ' Bueno, no acabamos de optimizar la entrada, entonces si a camismo estamos viendo que hay formas de optimizar las maneras de ricos, tengo la en cuenta de función de su caso de uso.',\n",
              "   'tokens': [51014,\n",
              "    16046,\n",
              "    11,\n",
              "    572,\n",
              "    13281,\n",
              "    2151,\n",
              "    368,\n",
              "    5028,\n",
              "    9736,\n",
              "    635,\n",
              "    37119,\n",
              "    11,\n",
              "    13003,\n",
              "    1511,\n",
              "    257,\n",
              "    1945,\n",
              "    271,\n",
              "    3280,\n",
              "    10382,\n",
              "    34506,\n",
              "    631,\n",
              "    4842,\n",
              "    33463,\n",
              "    368,\n",
              "    5028,\n",
              "    9736,\n",
              "    2439,\n",
              "    587,\n",
              "    6985,\n",
              "    368,\n",
              "    367,\n",
              "    9940,\n",
              "    11,\n",
              "    13989,\n",
              "    635,\n",
              "    465,\n",
              "    17868,\n",
              "    368,\n",
              "    43735,\n",
              "    368,\n",
              "    459,\n",
              "    9666,\n",
              "    368,\n",
              "    22728,\n",
              "    13,\n",
              "    51464],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.382984504699707,\n",
              "   'compression_ratio': 1.6554621848739495,\n",
              "   'no_speech_prob': 0.034038934856653214},\n",
              "  {'id': 169,\n",
              "   'seek': 146740,\n",
              "   'start': 1468.4,\n",
              "   'end': 1478.4,\n",
              "   'text': ' Después las buenas prácticas ingenierías aplican para todos, las prácticas que conocemos, de no optimizar antes de tiempo, de empezar,',\n",
              "   'tokens': [50414,\n",
              "    40995,\n",
              "    2439,\n",
              "    43852,\n",
              "    27300,\n",
              "    349,\n",
              "    9150,\n",
              "    21600,\n",
              "    811,\n",
              "    10025,\n",
              "    18221,\n",
              "    282,\n",
              "    1690,\n",
              "    6321,\n",
              "    11,\n",
              "    2439,\n",
              "    27300,\n",
              "    349,\n",
              "    9150,\n",
              "    631,\n",
              "    33029,\n",
              "    38173,\n",
              "    11,\n",
              "    368,\n",
              "    572,\n",
              "    5028,\n",
              "    9736,\n",
              "    11014,\n",
              "    368,\n",
              "    11772,\n",
              "    11,\n",
              "    368,\n",
              "    31168,\n",
              "    11,\n",
              "    50914],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.26149687943635164,\n",
              "   'compression_ratio': 1.721311475409836,\n",
              "   'no_speech_prob': 0.04015285521745682},\n",
              "  {'id': 170,\n",
              "   'seek': 146740,\n",
              "   'start': 1478.4,\n",
              "   'end': 1486.4,\n",
              "   'text': ' esto es algo que me lo discuta, a mí me gusta empezar a desarrollar pensando que está todo bien y después pensar en las cosas que pueden fallar,',\n",
              "   'tokens': [50914,\n",
              "    7433,\n",
              "    785,\n",
              "    8655,\n",
              "    631,\n",
              "    385,\n",
              "    450,\n",
              "    2983,\n",
              "    12093,\n",
              "    11,\n",
              "    257,\n",
              "    14692,\n",
              "    385,\n",
              "    20576,\n",
              "    31168,\n",
              "    257,\n",
              "    32501,\n",
              "    289,\n",
              "    34525,\n",
              "    631,\n",
              "    3192,\n",
              "    5149,\n",
              "    3610,\n",
              "    288,\n",
              "    15283,\n",
              "    18321,\n",
              "    465,\n",
              "    2439,\n",
              "    12218,\n",
              "    631,\n",
              "    14714,\n",
              "    2100,\n",
              "    289,\n",
              "    11,\n",
              "    51314],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.26149687943635164,\n",
              "   'compression_ratio': 1.721311475409836,\n",
              "   'no_speech_prob': 0.04015285521745682},\n",
              "  {'id': 171,\n",
              "   'seek': 146740,\n",
              "   'start': 1486.4,\n",
              "   'end': 1492.4,\n",
              "   'text': ' creo que una charla hace unos días, de 100 todos los contrarios, a mí me gusta hacer optimista y después ir agregando complejidad.',\n",
              "   'tokens': [51314,\n",
              "    14336,\n",
              "    631,\n",
              "    2002,\n",
              "    1290,\n",
              "    875,\n",
              "    10032,\n",
              "    17780,\n",
              "    19527,\n",
              "    11,\n",
              "    368,\n",
              "    2319,\n",
              "    6321,\n",
              "    1750,\n",
              "    660,\n",
              "    5352,\n",
              "    2717,\n",
              "    11,\n",
              "    257,\n",
              "    14692,\n",
              "    385,\n",
              "    20576,\n",
              "    6720,\n",
              "    5028,\n",
              "    5236,\n",
              "    288,\n",
              "    15283,\n",
              "    3418,\n",
              "    623,\n",
              "    3375,\n",
              "    1806,\n",
              "    44424,\n",
              "    73,\n",
              "    4580,\n",
              "    13,\n",
              "    51614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.26149687943635164,\n",
              "   'compression_ratio': 1.721311475409836,\n",
              "   'no_speech_prob': 0.04015285521745682},\n",
              "  {'id': 172,\n",
              "   'seek': 149240,\n",
              "   'start': 1493.4,\n",
              "   'end': 1498.4,\n",
              "   'text': ' Entonces, esas buenas prácticas que hay que hemos estudiado sirven para los macros y para los micros también, en este caso.',\n",
              "   'tokens': [50414,\n",
              "    15097,\n",
              "    11,\n",
              "    23388,\n",
              "    43852,\n",
              "    27300,\n",
              "    349,\n",
              "    9150,\n",
              "    631,\n",
              "    4842,\n",
              "    631,\n",
              "    15396,\n",
              "    13542,\n",
              "    72,\n",
              "    1573,\n",
              "    4735,\n",
              "    553,\n",
              "    1690,\n",
              "    1750,\n",
              "    7912,\n",
              "    2635,\n",
              "    288,\n",
              "    1690,\n",
              "    1750,\n",
              "    3123,\n",
              "    2635,\n",
              "    6407,\n",
              "    11,\n",
              "    465,\n",
              "    4065,\n",
              "    9666,\n",
              "    13,\n",
              "    50664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.26876941094031703,\n",
              "   'compression_ratio': 1.7037037037037037,\n",
              "   'no_speech_prob': 0.03961082175374031},\n",
              "  {'id': 173,\n",
              "   'seek': 149240,\n",
              "   'start': 1500.4,\n",
              "   'end': 1512.4,\n",
              "   'text': ' Entonces bueno, les mostramos lo que estamos haciendo, les contamos que encontramos formas de optimizarlo, entonces ahora le queremos contarlo el próximo paso, no el final, sino el próximo paso,',\n",
              "   'tokens': [50764,\n",
              "    15097,\n",
              "    11974,\n",
              "    11,\n",
              "    1512,\n",
              "    881,\n",
              "    30227,\n",
              "    450,\n",
              "    631,\n",
              "    10382,\n",
              "    20509,\n",
              "    11,\n",
              "    1512,\n",
              "    660,\n",
              "    2151,\n",
              "    631,\n",
              "    45049,\n",
              "    33463,\n",
              "    368,\n",
              "    5028,\n",
              "    9736,\n",
              "    752,\n",
              "    11,\n",
              "    13003,\n",
              "    9923,\n",
              "    476,\n",
              "    26813,\n",
              "    27045,\n",
              "    752,\n",
              "    806,\n",
              "    21177,\n",
              "    29212,\n",
              "    11,\n",
              "    572,\n",
              "    806,\n",
              "    2572,\n",
              "    11,\n",
              "    18108,\n",
              "    806,\n",
              "    21177,\n",
              "    29212,\n",
              "    11,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.26876941094031703,\n",
              "   'compression_ratio': 1.7037037037037037,\n",
              "   'no_speech_prob': 0.03961082175374031},\n",
              "  {'id': 174,\n",
              "   'seek': 151240,\n",
              "   'start': 1513.4,\n",
              "   'end': 1524.4,\n",
              "   'text': ' que hicimos en Mercado Libre con todo esto o por lo menos en el marco nuestros equipos, primero lo queremos esta filmina de marketing, es un poco para que entienda la cuestión de envergadura y de escala,',\n",
              "   'tokens': [50414,\n",
              "    631,\n",
              "    23697,\n",
              "    8372,\n",
              "    465,\n",
              "    18897,\n",
              "    1573,\n",
              "    15834,\n",
              "    265,\n",
              "    416,\n",
              "    5149,\n",
              "    7433,\n",
              "    277,\n",
              "    1515,\n",
              "    450,\n",
              "    8902,\n",
              "    465,\n",
              "    806,\n",
              "    1849,\n",
              "    1291,\n",
              "    24099,\n",
              "    5037,\n",
              "    329,\n",
              "    11,\n",
              "    21289,\n",
              "    450,\n",
              "    26813,\n",
              "    5283,\n",
              "    1387,\n",
              "    76,\n",
              "    1426,\n",
              "    368,\n",
              "    6370,\n",
              "    11,\n",
              "    785,\n",
              "    517,\n",
              "    10639,\n",
              "    1690,\n",
              "    631,\n",
              "    948,\n",
              "    30498,\n",
              "    635,\n",
              "    50216,\n",
              "    368,\n",
              "    465,\n",
              "    331,\n",
              "    70,\n",
              "    25154,\n",
              "    288,\n",
              "    368,\n",
              "    4721,\n",
              "    5159,\n",
              "    11,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3190767841954385,\n",
              "   'compression_ratio': 1.6745283018867925,\n",
              "   'no_speech_prob': 0.5144519209861755},\n",
              "  {'id': 175,\n",
              "   'seek': 151240,\n",
              "   'start': 1524.4,\n",
              "   'end': 1533.4,\n",
              "   'text': ' que realmente en nuestro caso, porque tiene sentido hacer lo que hicimos, lo que lo podemos demostrar, en Mercado Libre hay 6 mil busques por segundo,',\n",
              "   'tokens': [50964,\n",
              "    631,\n",
              "    14446,\n",
              "    465,\n",
              "    14726,\n",
              "    9666,\n",
              "    11,\n",
              "    4021,\n",
              "    7066,\n",
              "    19850,\n",
              "    6720,\n",
              "    450,\n",
              "    631,\n",
              "    23697,\n",
              "    8372,\n",
              "    11,\n",
              "    450,\n",
              "    631,\n",
              "    450,\n",
              "    12234,\n",
              "    41556,\n",
              "    5352,\n",
              "    11,\n",
              "    465,\n",
              "    18897,\n",
              "    1573,\n",
              "    15834,\n",
              "    265,\n",
              "    4842,\n",
              "    1386,\n",
              "    1962,\n",
              "    1255,\n",
              "    7519,\n",
              "    1515,\n",
              "    17954,\n",
              "    11,\n",
              "    51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3190767841954385,\n",
              "   'compression_ratio': 1.6745283018867925,\n",
              "   'no_speech_prob': 0.5144519209861755},\n",
              "  {'id': 176,\n",
              "   'seek': 153340,\n",
              "   'start': 1533.4,\n",
              "   'end': 1549.4,\n",
              "   'text': ' una búsqueda desde el browser dispara un montón de ricos, una de esos ricos, adentro nuestro sistema se multiplica, entonces imagínese el volumen de transacciones con los envíos, con las compras, con cada uno de los pago a través de milones de Mercado Pago, cada item que se crea cada usuario que entra,',\n",
              "   'tokens': [50364,\n",
              "    2002,\n",
              "    272,\n",
              "    10227,\n",
              "    358,\n",
              "    8801,\n",
              "    10188,\n",
              "    806,\n",
              "    11185,\n",
              "    14548,\n",
              "    64,\n",
              "    517,\n",
              "    45259,\n",
              "    368,\n",
              "    367,\n",
              "    9940,\n",
              "    11,\n",
              "    2002,\n",
              "    368,\n",
              "    22411,\n",
              "    367,\n",
              "    9940,\n",
              "    11,\n",
              "    614,\n",
              "    317,\n",
              "    340,\n",
              "    14726,\n",
              "    13245,\n",
              "    369,\n",
              "    12788,\n",
              "    2262,\n",
              "    11,\n",
              "    13003,\n",
              "    2576,\n",
              "    10973,\n",
              "    1130,\n",
              "    806,\n",
              "    1996,\n",
              "    16988,\n",
              "    368,\n",
              "    1145,\n",
              "    8476,\n",
              "    5411,\n",
              "    416,\n",
              "    1750,\n",
              "    2267,\n",
              "    870,\n",
              "    329,\n",
              "    11,\n",
              "    416,\n",
              "    2439,\n",
              "    715,\n",
              "    3906,\n",
              "    11,\n",
              "    416,\n",
              "    8411,\n",
              "    8526,\n",
              "    368,\n",
              "    1750,\n",
              "    280,\n",
              "    6442,\n",
              "    257,\n",
              "    24463,\n",
              "    368,\n",
              "    1962,\n",
              "    2213,\n",
              "    368,\n",
              "    18897,\n",
              "    1573,\n",
              "    430,\n",
              "    6442,\n",
              "    11,\n",
              "    8411,\n",
              "    3174,\n",
              "    631,\n",
              "    369,\n",
              "    1197,\n",
              "    64,\n",
              "    8411,\n",
              "    32247,\n",
              "    4912,\n",
              "    631,\n",
              "    22284,\n",
              "    11,\n",
              "    51164],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.22600143750508625,\n",
              "   'compression_ratio': 1.7743190661478598,\n",
              "   'no_speech_prob': 0.14023646712303162},\n",
              "  {'id': 177,\n",
              "   'seek': 153340,\n",
              "   'start': 1549.4,\n",
              "   'end': 1557.4,\n",
              "   'text': ' son literalmente millones de ricos por segundo, que se multiplican dentro nuestro sistema, probablemente se no sea el caso de uso de todos ustedes,',\n",
              "   'tokens': [51164,\n",
              "    1872,\n",
              "    20411,\n",
              "    4082,\n",
              "    22416,\n",
              "    368,\n",
              "    367,\n",
              "    9940,\n",
              "    1515,\n",
              "    17954,\n",
              "    11,\n",
              "    631,\n",
              "    369,\n",
              "    12788,\n",
              "    8914,\n",
              "    10856,\n",
              "    14726,\n",
              "    13245,\n",
              "    11,\n",
              "    21759,\n",
              "    4082,\n",
              "    369,\n",
              "    572,\n",
              "    4158,\n",
              "    806,\n",
              "    9666,\n",
              "    368,\n",
              "    22728,\n",
              "    368,\n",
              "    6321,\n",
              "    17110,\n",
              "    11,\n",
              "    51564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.22600143750508625,\n",
              "   'compression_ratio': 1.7743190661478598,\n",
              "   'no_speech_prob': 0.14023646712303162},\n",
              "  {'id': 178,\n",
              "   'seek': 155740,\n",
              "   'start': 1557.4,\n",
              "   'end': 1571.4,\n",
              "   'text': ' lo cual no significa que les escala, la que esté trabajando, no sea importante considerar esto lo mismo, pero para nosotros que venimos en el empresa más chica, que en Mercado Libre del Quirio nos encontramos con este escala y el día de hoy sigue siendo impresionante,',\n",
              "   'tokens': [50364,\n",
              "    450,\n",
              "    10911,\n",
              "    572,\n",
              "    19957,\n",
              "    631,\n",
              "    1512,\n",
              "    4721,\n",
              "    5159,\n",
              "    11,\n",
              "    635,\n",
              "    631,\n",
              "    34584,\n",
              "    40473,\n",
              "    11,\n",
              "    572,\n",
              "    4158,\n",
              "    9416,\n",
              "    1949,\n",
              "    289,\n",
              "    7433,\n",
              "    450,\n",
              "    12461,\n",
              "    11,\n",
              "    4768,\n",
              "    1690,\n",
              "    13863,\n",
              "    631,\n",
              "    6138,\n",
              "    8372,\n",
              "    465,\n",
              "    806,\n",
              "    22682,\n",
              "    3573,\n",
              "    417,\n",
              "    2262,\n",
              "    11,\n",
              "    631,\n",
              "    465,\n",
              "    18897,\n",
              "    1573,\n",
              "    15834,\n",
              "    265,\n",
              "    1103,\n",
              "    2326,\n",
              "    347,\n",
              "    1004,\n",
              "    3269,\n",
              "    45049,\n",
              "    416,\n",
              "    4065,\n",
              "    4721,\n",
              "    5159,\n",
              "    288,\n",
              "    806,\n",
              "    12271,\n",
              "    368,\n",
              "    13775,\n",
              "    34532,\n",
              "    31423,\n",
              "    35672,\n",
              "    313,\n",
              "    2879,\n",
              "    11,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.29302308165911334,\n",
              "   'compression_ratio': 1.641732283464567,\n",
              "   'no_speech_prob': 0.14984269440174103},\n",
              "  {'id': 179,\n",
              "   'seek': 155740,\n",
              "   'start': 1571.4,\n",
              "   'end': 1578.4,\n",
              "   'text': ' porque lo vemos en el día de día, entonces quédimos con todo esto, sabemos que podemos optimizar la forma de conectar microsaricios en Python,',\n",
              "   'tokens': [51064,\n",
              "    4021,\n",
              "    450,\n",
              "    20909,\n",
              "    465,\n",
              "    806,\n",
              "    12271,\n",
              "    368,\n",
              "    12271,\n",
              "    11,\n",
              "    13003,\n",
              "    421,\n",
              "    7811,\n",
              "    8372,\n",
              "    416,\n",
              "    5149,\n",
              "    7433,\n",
              "    11,\n",
              "    27200,\n",
              "    631,\n",
              "    12234,\n",
              "    5028,\n",
              "    9736,\n",
              "    635,\n",
              "    8366,\n",
              "    368,\n",
              "    30458,\n",
              "    289,\n",
              "    15547,\n",
              "    289,\n",
              "    299,\n",
              "    2717,\n",
              "    465,\n",
              "    15329,\n",
              "    11,\n",
              "    51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.29302308165911334,\n",
              "   'compression_ratio': 1.641732283464567,\n",
              "   'no_speech_prob': 0.14984269440174103},\n",
              "  {'id': 180,\n",
              "   'seek': 157840,\n",
              "   'start': 1579.4,\n",
              "   'end': 1588.4,\n",
              "   'text': ' básicamente hicimos una librería, una rest client, una abstractión de la capa de comunicación HTTP,',\n",
              "   'tokens': [50414,\n",
              "    48282,\n",
              "    23697,\n",
              "    8372,\n",
              "    2002,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    11,\n",
              "    2002,\n",
              "    1472,\n",
              "    6423,\n",
              "    11,\n",
              "    2002,\n",
              "    12649,\n",
              "    2560,\n",
              "    368,\n",
              "    635,\n",
              "    1410,\n",
              "    64,\n",
              "    368,\n",
              "    31710,\n",
              "    3482,\n",
              "    33283,\n",
              "    11,\n",
              "    50864],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.26661273411342074,\n",
              "   'compression_ratio': 1.407185628742515,\n",
              "   'no_speech_prob': 0.2778228521347046},\n",
              "  {'id': 181,\n",
              "   'seek': 157840,\n",
              "   'start': 1588.4,\n",
              "   'end': 1596.4,\n",
              "   'text': ' algo que podría haber hecho desde el inicio, lo que pasa es que esa rico es tan fácil, no veíamos la necesidad de hacerlo raper.',\n",
              "   'tokens': [50864,\n",
              "    8655,\n",
              "    631,\n",
              "    27246,\n",
              "    15811,\n",
              "    13064,\n",
              "    10188,\n",
              "    806,\n",
              "    294,\n",
              "    18322,\n",
              "    11,\n",
              "    450,\n",
              "    631,\n",
              "    20260,\n",
              "    785,\n",
              "    631,\n",
              "    11342,\n",
              "    367,\n",
              "    2789,\n",
              "    785,\n",
              "    7603,\n",
              "    17474,\n",
              "    11,\n",
              "    572,\n",
              "    1241,\n",
              "    16275,\n",
              "    635,\n",
              "    11909,\n",
              "    4580,\n",
              "    368,\n",
              "    32039,\n",
              "    367,\n",
              "    2332,\n",
              "    13,\n",
              "    51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.26661273411342074,\n",
              "   'compression_ratio': 1.407185628742515,\n",
              "   'no_speech_prob': 0.2778228521347046},\n",
              "  {'id': 182,\n",
              "   'seek': 159640,\n",
              "   'start': 1596.4,\n",
              "   'end': 1606.4,\n",
              "   'text': ' Yo recuerdo entre en un proyecto el primer día y dije, bueno, 5 mil ricos, voy a tener 2 mil ricos, esto lo hizo una prueba en mi máquina esta bandar,',\n",
              "   'tokens': [50364,\n",
              "    7616,\n",
              "    850,\n",
              "    22412,\n",
              "    3962,\n",
              "    465,\n",
              "    517,\n",
              "    32285,\n",
              "    806,\n",
              "    12595,\n",
              "    12271,\n",
              "    288,\n",
              "    39414,\n",
              "    11,\n",
              "    11974,\n",
              "    11,\n",
              "    1025,\n",
              "    1962,\n",
              "    367,\n",
              "    9940,\n",
              "    11,\n",
              "    7552,\n",
              "    257,\n",
              "    11640,\n",
              "    568,\n",
              "    1962,\n",
              "    367,\n",
              "    9940,\n",
              "    11,\n",
              "    7433,\n",
              "    450,\n",
              "    28803,\n",
              "    2002,\n",
              "    48241,\n",
              "    465,\n",
              "    2752,\n",
              "    49360,\n",
              "    5283,\n",
              "    4116,\n",
              "    289,\n",
              "    11,\n",
              "    50864],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.35376409466347,\n",
              "   'compression_ratio': 1.4910714285714286,\n",
              "   'no_speech_prob': 0.41679665446281433},\n",
              "  {'id': 183,\n",
              "   'seek': 159640,\n",
              "   'start': 1606.4,\n",
              "   'end': 1617.4,\n",
              "   'text': ' después salió a producción, tenía 200 mil ricos por segundo, entonces ahí me di cuenta que ahí me va a discutirme el che para hay que hacer cosas con esto, no es tan sencillo.',\n",
              "   'tokens': [50864,\n",
              "    15283,\n",
              "    1845,\n",
              "    7138,\n",
              "    257,\n",
              "    48586,\n",
              "    11,\n",
              "    23718,\n",
              "    2331,\n",
              "    1962,\n",
              "    367,\n",
              "    9940,\n",
              "    1515,\n",
              "    17954,\n",
              "    11,\n",
              "    13003,\n",
              "    12571,\n",
              "    385,\n",
              "    1026,\n",
              "    17868,\n",
              "    631,\n",
              "    12571,\n",
              "    385,\n",
              "    2773,\n",
              "    257,\n",
              "    42085,\n",
              "    347,\n",
              "    1398,\n",
              "    806,\n",
              "    947,\n",
              "    1690,\n",
              "    4842,\n",
              "    631,\n",
              "    6720,\n",
              "    12218,\n",
              "    416,\n",
              "    7433,\n",
              "    11,\n",
              "    572,\n",
              "    785,\n",
              "    7603,\n",
              "    46749,\n",
              "    78,\n",
              "    13,\n",
              "    51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.35376409466347,\n",
              "   'compression_ratio': 1.4910714285714286,\n",
              "   'no_speech_prob': 0.41679665446281433},\n",
              "  {'id': 184,\n",
              "   'seek': 161740,\n",
              "   'start': 1618.4,\n",
              "   'end': 1628.4,\n",
              "   'text': ' En Mercado Libre no funciona el approach naive de entrada, no funciona nunca, de entrada tienes que pensar entre 10 mil y 50 mil ricos por minuto,',\n",
              "   'tokens': [50414,\n",
              "    2193,\n",
              "    18897,\n",
              "    1573,\n",
              "    15834,\n",
              "    265,\n",
              "    572,\n",
              "    26210,\n",
              "    806,\n",
              "    3109,\n",
              "    29052,\n",
              "    368,\n",
              "    37119,\n",
              "    11,\n",
              "    572,\n",
              "    26210,\n",
              "    13768,\n",
              "    11,\n",
              "    368,\n",
              "    37119,\n",
              "    20716,\n",
              "    631,\n",
              "    18321,\n",
              "    3962,\n",
              "    1266,\n",
              "    1962,\n",
              "    288,\n",
              "    2625,\n",
              "    1962,\n",
              "    367,\n",
              "    9940,\n",
              "    1515,\n",
              "    923,\n",
              "    8262,\n",
              "    11,\n",
              "    50914],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3202735053168403,\n",
              "   'compression_ratio': 1.5934959349593496,\n",
              "   'no_speech_prob': 0.25901466608047485},\n",
              "  {'id': 185,\n",
              "   'seek': 161740,\n",
              "   'start': 1628.4,\n",
              "   'end': 1633.4,\n",
              "   'text': ' el 10K de repb, el 50K de repb, es algo que para nosotros todavía es chico, cuando queremos probar infraestructuras, por ejemplo,',\n",
              "   'tokens': [50914,\n",
              "    806,\n",
              "    1266,\n",
              "    42,\n",
              "    368,\n",
              "    1085,\n",
              "    65,\n",
              "    11,\n",
              "    806,\n",
              "    2625,\n",
              "    42,\n",
              "    368,\n",
              "    1085,\n",
              "    65,\n",
              "    11,\n",
              "    785,\n",
              "    8655,\n",
              "    631,\n",
              "    1690,\n",
              "    13863,\n",
              "    28388,\n",
              "    785,\n",
              "    417,\n",
              "    2789,\n",
              "    11,\n",
              "    7767,\n",
              "    26813,\n",
              "    1239,\n",
              "    289,\n",
              "    23654,\n",
              "    43056,\n",
              "    12907,\n",
              "    11,\n",
              "    1515,\n",
              "    13358,\n",
              "    11,\n",
              "    51164],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3202735053168403,\n",
              "   'compression_ratio': 1.5934959349593496,\n",
              "   'no_speech_prob': 0.25901466608047485},\n",
              "  {'id': 186,\n",
              "   'seek': 161740,\n",
              "   'start': 1633.4,\n",
              "   'end': 1640.4,\n",
              "   'text': ' ahora un API de 600, 700K de repb, son APIs que se les está pegando fuerte, pero no son la más grande del sitio,',\n",
              "   'tokens': [51164,\n",
              "    9923,\n",
              "    517,\n",
              "    9362,\n",
              "    368,\n",
              "    11849,\n",
              "    11,\n",
              "    15204,\n",
              "    42,\n",
              "    368,\n",
              "    1085,\n",
              "    65,\n",
              "    11,\n",
              "    1872,\n",
              "    21445,\n",
              "    631,\n",
              "    369,\n",
              "    1512,\n",
              "    3192,\n",
              "    17199,\n",
              "    1806,\n",
              "    37129,\n",
              "    11,\n",
              "    4768,\n",
              "    572,\n",
              "    1872,\n",
              "    635,\n",
              "    3573,\n",
              "    8883,\n",
              "    1103,\n",
              "    40621,\n",
              "    11,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3202735053168403,\n",
              "   'compression_ratio': 1.5934959349593496,\n",
              "   'no_speech_prob': 0.25901466608047485},\n",
              "  {'id': 187,\n",
              "   'seek': 164040,\n",
              "   'start': 1640.4,\n",
              "   'end': 1646.4,\n",
              "   'text': ' se nos meten las escalas grandes, cuando estamos en la máquina de la ring nos metemos al medio de casi todos los flujos importantes del negocio,',\n",
              "   'tokens': [50364,\n",
              "    369,\n",
              "    3269,\n",
              "    1131,\n",
              "    268,\n",
              "    2439,\n",
              "    17871,\n",
              "    296,\n",
              "    16640,\n",
              "    11,\n",
              "    7767,\n",
              "    10382,\n",
              "    465,\n",
              "    635,\n",
              "    49360,\n",
              "    368,\n",
              "    635,\n",
              "    4875,\n",
              "    3269,\n",
              "    1131,\n",
              "    4485,\n",
              "    419,\n",
              "    22123,\n",
              "    368,\n",
              "    22567,\n",
              "    6321,\n",
              "    1750,\n",
              "    932,\n",
              "    4579,\n",
              "    329,\n",
              "    27963,\n",
              "    1103,\n",
              "    26722,\n",
              "    8529,\n",
              "    11,\n",
              "    50664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3799382723294772,\n",
              "   'compression_ratio': 1.6900826446280992,\n",
              "   'no_speech_prob': 0.04668627306818962},\n",
              "  {'id': 188,\n",
              "   'seek': 164040,\n",
              "   'start': 1646.4,\n",
              "   'end': 1652.4,\n",
              "   'text': ' perdiciendo, categorizando, recomendando, entonces por más que hay mucho go dando vuelta en la compañía,',\n",
              "   'tokens': [50664,\n",
              "    12611,\n",
              "    299,\n",
              "    7304,\n",
              "    11,\n",
              "    19250,\n",
              "    590,\n",
              "    1806,\n",
              "    11,\n",
              "    40292,\n",
              "    1806,\n",
              "    11,\n",
              "    13003,\n",
              "    1515,\n",
              "    3573,\n",
              "    631,\n",
              "    4842,\n",
              "    9824,\n",
              "    352,\n",
              "    29854,\n",
              "    41542,\n",
              "    465,\n",
              "    635,\n",
              "    29953,\n",
              "    2686,\n",
              "    11,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3799382723294772,\n",
              "   'compression_ratio': 1.6900826446280992,\n",
              "   'no_speech_prob': 0.04668627306818962},\n",
              "  {'id': 189,\n",
              "   'seek': 164040,\n",
              "   'start': 1652.4,\n",
              "   'end': 1659.4,\n",
              "   'text': ' pero utilizar estas cosas es mucho jable en el lógica de negocios, Python de repente con una capitalía muy grande, apalancado por la máquina de la ring,',\n",
              "   'tokens': [50964,\n",
              "    4768,\n",
              "    24060,\n",
              "    13897,\n",
              "    12218,\n",
              "    785,\n",
              "    9824,\n",
              "    361,\n",
              "    712,\n",
              "    465,\n",
              "    806,\n",
              "    48475,\n",
              "    2262,\n",
              "    368,\n",
              "    26722,\n",
              "    23132,\n",
              "    11,\n",
              "    15329,\n",
              "    368,\n",
              "    42884,\n",
              "    416,\n",
              "    2002,\n",
              "    4238,\n",
              "    2686,\n",
              "    5323,\n",
              "    8883,\n",
              "    11,\n",
              "    1882,\n",
              "    304,\n",
              "    4463,\n",
              "    1573,\n",
              "    1515,\n",
              "    635,\n",
              "    49360,\n",
              "    368,\n",
              "    635,\n",
              "    4875,\n",
              "    11,\n",
              "    51314],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3799382723294772,\n",
              "   'compression_ratio': 1.6900826446280992,\n",
              "   'no_speech_prob': 0.04668627306818962},\n",
              "  {'id': 190,\n",
              "   'seek': 165940,\n",
              "   'start': 1659.4,\n",
              "   'end': 1678.4,\n",
              "   'text': ' entonces lo que hicimos hace poco es esta una librería para que los desarrolladores, ahora instancia una librería un res client que es conder todos los detalles de implementación y toda la lógica de negocios relacionada a conectar micro servicios de la compañía',\n",
              "   'tokens': [50364,\n",
              "    13003,\n",
              "    450,\n",
              "    631,\n",
              "    23697,\n",
              "    8372,\n",
              "    10032,\n",
              "    10639,\n",
              "    785,\n",
              "    5283,\n",
              "    2002,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    1690,\n",
              "    631,\n",
              "    1750,\n",
              "    32501,\n",
              "    11856,\n",
              "    11,\n",
              "    9923,\n",
              "    1058,\n",
              "    22862,\n",
              "    2002,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    517,\n",
              "    725,\n",
              "    6423,\n",
              "    631,\n",
              "    785,\n",
              "    416,\n",
              "    1068,\n",
              "    6321,\n",
              "    1750,\n",
              "    1141,\n",
              "    37927,\n",
              "    368,\n",
              "    4445,\n",
              "    3482,\n",
              "    288,\n",
              "    11687,\n",
              "    635,\n",
              "    48475,\n",
              "    2262,\n",
              "    368,\n",
              "    26722,\n",
              "    23132,\n",
              "    27189,\n",
              "    1538,\n",
              "    257,\n",
              "    30458,\n",
              "    289,\n",
              "    4532,\n",
              "    42722,\n",
              "    368,\n",
              "    635,\n",
              "    29953,\n",
              "    2686,\n",
              "    51314],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.33963400667363947,\n",
              "   'compression_ratio': 1.6255506607929515,\n",
              "   'no_speech_prob': 0.05333614721894264},\n",
              "  {'id': 191,\n",
              "   'seek': 165940,\n",
              "   'start': 1680.4,\n",
              "   'end': 1685.4,\n",
              "   'text': ' y obviamente ya que nos gustaba tanto el interfaz rico, si intentamos hacer algo, realmente parecido.',\n",
              "   'tokens': [51414,\n",
              "    288,\n",
              "    36325,\n",
              "    2478,\n",
              "    631,\n",
              "    3269,\n",
              "    9679,\n",
              "    5509,\n",
              "    10331,\n",
              "    806,\n",
              "    14510,\n",
              "    921,\n",
              "    41529,\n",
              "    11,\n",
              "    1511,\n",
              "    8446,\n",
              "    2151,\n",
              "    6720,\n",
              "    8655,\n",
              "    11,\n",
              "    14446,\n",
              "    7448,\n",
              "    17994,\n",
              "    13,\n",
              "    51664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.33963400667363947,\n",
              "   'compression_ratio': 1.6255506607929515,\n",
              "   'no_speech_prob': 0.05333614721894264},\n",
              "  {'id': 192,\n",
              "   'seek': 168540,\n",
              "   'start': 1685.4,\n",
              "   'end': 1699.4,\n",
              "   'text': ' Oúo, hay varios desafíos, toda la comunidad patónica que está trabajando, están muy familiarizadas con rico, entonces no fue solamente hacer una buena interfaz parecida a la de rico, es para esta herramienta,',\n",
              "   'tokens': [50364,\n",
              "    422,\n",
              "    2481,\n",
              "    78,\n",
              "    11,\n",
              "    4842,\n",
              "    33665,\n",
              "    34587,\n",
              "    870,\n",
              "    329,\n",
              "    11,\n",
              "    11687,\n",
              "    635,\n",
              "    35695,\n",
              "    1947,\n",
              "    1801,\n",
              "    2262,\n",
              "    631,\n",
              "    3192,\n",
              "    40473,\n",
              "    11,\n",
              "    10368,\n",
              "    5323,\n",
              "    4963,\n",
              "    590,\n",
              "    6872,\n",
              "    416,\n",
              "    41529,\n",
              "    11,\n",
              "    13003,\n",
              "    572,\n",
              "    9248,\n",
              "    27814,\n",
              "    6720,\n",
              "    2002,\n",
              "    25710,\n",
              "    14510,\n",
              "    921,\n",
              "    7448,\n",
              "    37200,\n",
              "    257,\n",
              "    635,\n",
              "    368,\n",
              "    41529,\n",
              "    11,\n",
              "    785,\n",
              "    1690,\n",
              "    5283,\n",
              "    38271,\n",
              "    64,\n",
              "    11,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.24096776671328787,\n",
              "   'compression_ratio': 1.795053003533569,\n",
              "   'no_speech_prob': 0.016650332137942314},\n",
              "  {'id': 193,\n",
              "   'seek': 168540,\n",
              "   'start': 1699.4,\n",
              "   'end': 1712.4,\n",
              "   'text': ' sino que después nos encontramos que todas las herramientas que hay alrededor de rico es como rico es mo, para testiarla nos dejaban de servir, entonces también tuvimos que desarrollar herramientas para testiar nuestro res client que sean parecidas en lo que la comunidad estaba acostumbrada,',\n",
              "   'tokens': [51064,\n",
              "    18108,\n",
              "    631,\n",
              "    15283,\n",
              "    3269,\n",
              "    45049,\n",
              "    631,\n",
              "    10906,\n",
              "    2439,\n",
              "    38271,\n",
              "    296,\n",
              "    631,\n",
              "    4842,\n",
              "    43663,\n",
              "    368,\n",
              "    41529,\n",
              "    785,\n",
              "    2617,\n",
              "    41529,\n",
              "    785,\n",
              "    705,\n",
              "    11,\n",
              "    1690,\n",
              "    1500,\n",
              "    9448,\n",
              "    875,\n",
              "    3269,\n",
              "    21259,\n",
              "    18165,\n",
              "    368,\n",
              "    29463,\n",
              "    11,\n",
              "    13003,\n",
              "    6407,\n",
              "    38177,\n",
              "    8372,\n",
              "    631,\n",
              "    32501,\n",
              "    289,\n",
              "    38271,\n",
              "    296,\n",
              "    1690,\n",
              "    1500,\n",
              "    9448,\n",
              "    14726,\n",
              "    725,\n",
              "    6423,\n",
              "    631,\n",
              "    37670,\n",
              "    7448,\n",
              "    66,\n",
              "    11382,\n",
              "    465,\n",
              "    450,\n",
              "    631,\n",
              "    635,\n",
              "    35695,\n",
              "    17544,\n",
              "    44126,\n",
              "    449,\n",
              "    1443,\n",
              "    1538,\n",
              "    11,\n",
              "    51714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.24096776671328787,\n",
              "   'compression_ratio': 1.795053003533569,\n",
              "   'no_speech_prob': 0.016650332137942314},\n",
              "  {'id': 194,\n",
              "   'seek': 171240,\n",
              "   'start': 1712.4,\n",
              "   'end': 1726.4,\n",
              "   'text': ' o sea, no fue trivial de sentarse una, dos semanas y grabía algo, sino que realmente hubo que sentarse, hacer y queñaría, diseñarlo, pensarlo, probarlo ir y volver, y algunas cosas interesantes que sucedieron,',\n",
              "   'tokens': [50364,\n",
              "    277,\n",
              "    4158,\n",
              "    11,\n",
              "    572,\n",
              "    9248,\n",
              "    26703,\n",
              "    368,\n",
              "    2279,\n",
              "    11668,\n",
              "    2002,\n",
              "    11,\n",
              "    4491,\n",
              "    42507,\n",
              "    288,\n",
              "    4444,\n",
              "    2686,\n",
              "    8655,\n",
              "    11,\n",
              "    18108,\n",
              "    631,\n",
              "    14446,\n",
              "    11838,\n",
              "    78,\n",
              "    631,\n",
              "    2279,\n",
              "    11668,\n",
              "    11,\n",
              "    6720,\n",
              "    288,\n",
              "    631,\n",
              "    2791,\n",
              "    21178,\n",
              "    11,\n",
              "    3814,\n",
              "    2791,\n",
              "    19457,\n",
              "    11,\n",
              "    18321,\n",
              "    752,\n",
              "    11,\n",
              "    1239,\n",
              "    19457,\n",
              "    3418,\n",
              "    288,\n",
              "    33998,\n",
              "    11,\n",
              "    288,\n",
              "    27316,\n",
              "    12218,\n",
              "    20157,\n",
              "    9327,\n",
              "    631,\n",
              "    41928,\n",
              "    14440,\n",
              "    11,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.24931141081310454,\n",
              "   'compression_ratio': 1.6446280991735538,\n",
              "   'no_speech_prob': 0.35527536273002625},\n",
              "  {'id': 195,\n",
              "   'seek': 171240,\n",
              "   'start': 1726.4,\n",
              "   'end': 1739.4,\n",
              "   'text': ' hoy por una cuestión de que uno no puede aplicar un cambio masivamente en toda la compañía, porque es muy riesgoso, el res client, nosotros vamos agregando lo que llamamos en jeans,',\n",
              "   'tokens': [51064,\n",
              "    13775,\n",
              "    1515,\n",
              "    2002,\n",
              "    50216,\n",
              "    368,\n",
              "    631,\n",
              "    8526,\n",
              "    572,\n",
              "    8919,\n",
              "    18221,\n",
              "    289,\n",
              "    517,\n",
              "    28731,\n",
              "    2300,\n",
              "    23957,\n",
              "    465,\n",
              "    11687,\n",
              "    635,\n",
              "    29953,\n",
              "    2686,\n",
              "    11,\n",
              "    4021,\n",
              "    785,\n",
              "    5323,\n",
              "    23932,\n",
              "    70,\n",
              "    9869,\n",
              "    11,\n",
              "    806,\n",
              "    725,\n",
              "    6423,\n",
              "    11,\n",
              "    13863,\n",
              "    5295,\n",
              "    623,\n",
              "    3375,\n",
              "    1806,\n",
              "    450,\n",
              "    631,\n",
              "    16848,\n",
              "    2151,\n",
              "    465,\n",
              "    18880,\n",
              "    11,\n",
              "    51714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.24931141081310454,\n",
              "   'compression_ratio': 1.6446280991735538,\n",
              "   'no_speech_prob': 0.35527536273002625},\n",
              "  {'id': 196,\n",
              "   'seek': 173940,\n",
              "   'start': 1739.4,\n",
              "   'end': 1757.4,\n",
              "   'text': ' que básicamente empezamos con un rico es en el fondo, que estamos seguro que andaba con sesión, despagaramos un relipter y de a poquito fuimos migrando algunas apicas, usan esta implementación y después anpaiculi, simulos mismos, fuimos migrando, y fue muy interesante ver como equipos hacían los diploi y decían,',\n",
              "   'tokens': [50364,\n",
              "    631,\n",
              "    48282,\n",
              "    18730,\n",
              "    2151,\n",
              "    416,\n",
              "    517,\n",
              "    41529,\n",
              "    785,\n",
              "    465,\n",
              "    806,\n",
              "    38101,\n",
              "    11,\n",
              "    631,\n",
              "    10382,\n",
              "    31424,\n",
              "    631,\n",
              "    293,\n",
              "    5509,\n",
              "    416,\n",
              "    5385,\n",
              "    2560,\n",
              "    11,\n",
              "    730,\n",
              "    79,\n",
              "    29124,\n",
              "    2151,\n",
              "    517,\n",
              "    1039,\n",
              "    647,\n",
              "    391,\n",
              "    288,\n",
              "    368,\n",
              "    257,\n",
              "    28229,\n",
              "    8536,\n",
              "    8372,\n",
              "    6186,\n",
              "    19845,\n",
              "    27316,\n",
              "    1882,\n",
              "    9150,\n",
              "    11,\n",
              "    505,\n",
              "    282,\n",
              "    5283,\n",
              "    4445,\n",
              "    3482,\n",
              "    288,\n",
              "    15283,\n",
              "    364,\n",
              "    79,\n",
              "    1301,\n",
              "    2444,\n",
              "    72,\n",
              "    11,\n",
              "    1034,\n",
              "    28348,\n",
              "    47458,\n",
              "    11,\n",
              "    8536,\n",
              "    8372,\n",
              "    6186,\n",
              "    19845,\n",
              "    11,\n",
              "    288,\n",
              "    9248,\n",
              "    5323,\n",
              "    36396,\n",
              "    1306,\n",
              "    2617,\n",
              "    5037,\n",
              "    329,\n",
              "    46093,\n",
              "    11084,\n",
              "    1750,\n",
              "    11432,\n",
              "    4869,\n",
              "    288,\n",
              "    979,\n",
              "    11084,\n",
              "    11,\n",
              "    51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.42294114056755516,\n",
              "   'compression_ratio': 1.5714285714285714,\n",
              "   'no_speech_prob': 0.10504596680402756},\n",
              "  {'id': 197,\n",
              "   'seek': 175740,\n",
              "   'start': 1757.4,\n",
              "   'end': 1775.4,\n",
              "   'text': ' mira no sé que hicimos, no es súper súper rápidora, nosotros estamos haciendo de a H, me parece que está funcionando esto, pero esto que se lo cuento como chiste es el valor de poder tener herramientas de la compañía que impacten en toda la compañía con un solo cambio,',\n",
              "   'tokens': [50364,\n",
              "    30286,\n",
              "    572,\n",
              "    7910,\n",
              "    631,\n",
              "    23697,\n",
              "    8372,\n",
              "    11,\n",
              "    572,\n",
              "    785,\n",
              "    43282,\n",
              "    43282,\n",
              "    18213,\n",
              "    327,\n",
              "    3252,\n",
              "    11,\n",
              "    13863,\n",
              "    10382,\n",
              "    20509,\n",
              "    368,\n",
              "    257,\n",
              "    389,\n",
              "    11,\n",
              "    385,\n",
              "    14120,\n",
              "    631,\n",
              "    3192,\n",
              "    14186,\n",
              "    1806,\n",
              "    7433,\n",
              "    11,\n",
              "    4768,\n",
              "    7433,\n",
              "    631,\n",
              "    369,\n",
              "    450,\n",
              "    2702,\n",
              "    15467,\n",
              "    2617,\n",
              "    417,\n",
              "    8375,\n",
              "    785,\n",
              "    806,\n",
              "    15367,\n",
              "    368,\n",
              "    8152,\n",
              "    11640,\n",
              "    38271,\n",
              "    296,\n",
              "    368,\n",
              "    635,\n",
              "    29953,\n",
              "    2686,\n",
              "    631,\n",
              "    2712,\n",
              "    268,\n",
              "    465,\n",
              "    11687,\n",
              "    635,\n",
              "    29953,\n",
              "    2686,\n",
              "    416,\n",
              "    517,\n",
              "    6944,\n",
              "    28731,\n",
              "    11,\n",
              "    51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.36232696754344995,\n",
              "   'compression_ratio': 1.5444444444444445,\n",
              "   'no_speech_prob': 0.417703241109848},\n",
              "  {'id': 198,\n",
              "   'seek': 177540,\n",
              "   'start': 1775.4,\n",
              "   'end': 1787.4,\n",
              "   'text': ' nosotros hacemos una nueva versión de esta librería y estamos impactando en todos los micros servicios que están en Python, que si no lo hubiéramos hecho tendríamos que haber hecho que decía delito que decir che bueno esta línea ahora cambia por esta 70,',\n",
              "   'tokens': [50364,\n",
              "    13863,\n",
              "    33839,\n",
              "    2002,\n",
              "    28963,\n",
              "    47248,\n",
              "    368,\n",
              "    5283,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    288,\n",
              "    10382,\n",
              "    2712,\n",
              "    1806,\n",
              "    465,\n",
              "    6321,\n",
              "    1750,\n",
              "    15547,\n",
              "    42722,\n",
              "    631,\n",
              "    10368,\n",
              "    465,\n",
              "    15329,\n",
              "    11,\n",
              "    631,\n",
              "    1511,\n",
              "    572,\n",
              "    450,\n",
              "    11838,\n",
              "    72,\n",
              "    4198,\n",
              "    2151,\n",
              "    13064,\n",
              "    3928,\n",
              "    81,\n",
              "    16275,\n",
              "    631,\n",
              "    15811,\n",
              "    13064,\n",
              "    631,\n",
              "    37599,\n",
              "    1103,\n",
              "    3528,\n",
              "    631,\n",
              "    10235,\n",
              "    947,\n",
              "    11974,\n",
              "    5283,\n",
              "    37452,\n",
              "    9923,\n",
              "    18751,\n",
              "    654,\n",
              "    1515,\n",
              "    5283,\n",
              "    5285,\n",
              "    11,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.33436012268066406,\n",
              "   'compression_ratio': 1.6334661354581674,\n",
              "   'no_speech_prob': 0.24759230017662048},\n",
              "  {'id': 199,\n",
              "   'seek': 177540,\n",
              "   'start': 1787.4,\n",
              "   'end': 1795.4,\n",
              "   'text': ' entonces tomar decisión y diseñar y queñaría es parte de comunicar micros a servicio, no es solamente una cuestión de optimizar la performance.',\n",
              "   'tokens': [50964,\n",
              "    13003,\n",
              "    22048,\n",
              "    18206,\n",
              "    2560,\n",
              "    288,\n",
              "    3814,\n",
              "    2791,\n",
              "    289,\n",
              "    288,\n",
              "    631,\n",
              "    2791,\n",
              "    289,\n",
              "    2686,\n",
              "    785,\n",
              "    6975,\n",
              "    368,\n",
              "    11040,\n",
              "    7953,\n",
              "    15547,\n",
              "    257,\n",
              "    43078,\n",
              "    11,\n",
              "    572,\n",
              "    785,\n",
              "    27814,\n",
              "    2002,\n",
              "    50216,\n",
              "    368,\n",
              "    5028,\n",
              "    9736,\n",
              "    635,\n",
              "    3389,\n",
              "    13,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.33436012268066406,\n",
              "   'compression_ratio': 1.6334661354581674,\n",
              "   'no_speech_prob': 0.24759230017662048},\n",
              "  {'id': 200,\n",
              "   'seek': 179540,\n",
              "   'start': 1795.4,\n",
              "   'end': 1804.4,\n",
              "   'text': ' Bueno luego que llevamos con partidos este es un caso de uso propio es parte de lo que lo que nos sirvió, tiene sus prois sus contras,',\n",
              "   'tokens': [50364,\n",
              "    16046,\n",
              "    17222,\n",
              "    631,\n",
              "    27124,\n",
              "    2151,\n",
              "    416,\n",
              "    644,\n",
              "    7895,\n",
              "    4065,\n",
              "    785,\n",
              "    517,\n",
              "    9666,\n",
              "    368,\n",
              "    22728,\n",
              "    40098,\n",
              "    785,\n",
              "    6975,\n",
              "    368,\n",
              "    450,\n",
              "    631,\n",
              "    450,\n",
              "    631,\n",
              "    3269,\n",
              "    4735,\n",
              "    4917,\n",
              "    812,\n",
              "    11,\n",
              "    7066,\n",
              "    3291,\n",
              "    447,\n",
              "    271,\n",
              "    3291,\n",
              "    660,\n",
              "    3906,\n",
              "    11,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3446509319802989,\n",
              "   'compression_ratio': 1.7579908675799087,\n",
              "   'no_speech_prob': 0.09525888413190842},\n",
              "  {'id': 201,\n",
              "   'seek': 179540,\n",
              "   'start': 1804.4,\n",
              "   'end': 1815.4,\n",
              "   'text': ' porque ahora esta librería le tiene que mantener a alguien, si el sistema de recomendación en el mercado libre encuentro un bug o una limitación de esta librería obviamente alguien lo tiene que resolver y ese alguien en este caso somos nosotros,',\n",
              "   'tokens': [50814,\n",
              "    4021,\n",
              "    9923,\n",
              "    5283,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    476,\n",
              "    7066,\n",
              "    631,\n",
              "    42759,\n",
              "    257,\n",
              "    25814,\n",
              "    11,\n",
              "    1511,\n",
              "    806,\n",
              "    13245,\n",
              "    368,\n",
              "    40292,\n",
              "    3482,\n",
              "    465,\n",
              "    806,\n",
              "    24775,\n",
              "    29976,\n",
              "    23708,\n",
              "    340,\n",
              "    517,\n",
              "    7426,\n",
              "    277,\n",
              "    2002,\n",
              "    4948,\n",
              "    3482,\n",
              "    368,\n",
              "    5283,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    36325,\n",
              "    25814,\n",
              "    450,\n",
              "    7066,\n",
              "    631,\n",
              "    34480,\n",
              "    288,\n",
              "    10167,\n",
              "    25814,\n",
              "    465,\n",
              "    4065,\n",
              "    9666,\n",
              "    25244,\n",
              "    13863,\n",
              "    11,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3446509319802989,\n",
              "   'compression_ratio': 1.7579908675799087,\n",
              "   'no_speech_prob': 0.09525888413190842},\n",
              "  {'id': 202,\n",
              "   'seek': 181540,\n",
              "   'start': 1815.4,\n",
              "   'end': 1827.4,\n",
              "   'text': ' entonces de nuevo depende el caso de uso hay que responsabilizarse por las herramientas que hacemos y como dice Rudy los pros son muchísimos, las contras no tantas como para que nos animamos, lo pues la tenemos en marcha.',\n",
              "   'tokens': [50364,\n",
              "    13003,\n",
              "    368,\n",
              "    18591,\n",
              "    47091,\n",
              "    806,\n",
              "    9666,\n",
              "    368,\n",
              "    22728,\n",
              "    4842,\n",
              "    631,\n",
              "    29829,\n",
              "    9736,\n",
              "    405,\n",
              "    1515,\n",
              "    2439,\n",
              "    38271,\n",
              "    296,\n",
              "    631,\n",
              "    33839,\n",
              "    288,\n",
              "    2617,\n",
              "    10313,\n",
              "    38690,\n",
              "    1750,\n",
              "    6267,\n",
              "    1872,\n",
              "    29353,\n",
              "    8372,\n",
              "    11,\n",
              "    2439,\n",
              "    660,\n",
              "    3906,\n",
              "    572,\n",
              "    12095,\n",
              "    296,\n",
              "    2617,\n",
              "    1690,\n",
              "    631,\n",
              "    3269,\n",
              "    2383,\n",
              "    2151,\n",
              "    11,\n",
              "    450,\n",
              "    11059,\n",
              "    635,\n",
              "    9914,\n",
              "    465,\n",
              "    8368,\n",
              "    64,\n",
              "    13,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.31486376400651606,\n",
              "   'compression_ratio': 1.460122699386503,\n",
              "   'no_speech_prob': 0.36615028977394104},\n",
              "  {'id': 203,\n",
              "   'seek': 181540,\n",
              "   'start': 1829.4,\n",
              "   'end': 1830.4,\n",
              "   'text': ' Muchas gracias.',\n",
              "   'tokens': [51064, 35669, 16611, 13, 51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.31486376400651606,\n",
              "   'compression_ratio': 1.460122699386503,\n",
              "   'no_speech_prob': 0.36615028977394104}],\n",
              " 'language': 'es'}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9C-_1d9OSqr"
      },
      "outputs": [],
      "source": [
        "df_transcribes = pd.read_csv('/content/PyCon-co audios/all_transcribes.csv',sep='|')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuS8PxakOdq9",
        "outputId": "08eee277-2eda-42a8-d4e8-78f7c6f6c294"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5873, 12)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_transcribes.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWMYeMeiPkkV",
        "outputId": "b879b5c1-dbaf-4b48-9e8f-e465691c12ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['title', 'url', 'path', 'views', 'author', 'publish_date', 'keywords',\n",
              "       'channel_id', 'position', 'start', 'end', 'text'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_transcribes.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6WGfdH04RvkZ",
        "outputId": "92deab29-5b69-40ae-92eb-6435a45f7713"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2cde2b27-9122-4d85-bc39-84763c51ed26\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "      <th>path</th>\n",
              "      <th>views</th>\n",
              "      <th>author</th>\n",
              "      <th>publish_date</th>\n",
              "      <th>keywords</th>\n",
              "      <th>channel_id</th>\n",
              "      <th>position</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lorena Aldana - Using Python to listen to your...</td>\n",
              "      <td>https://www.youtube.com/watch?v=YrCSME1jT6U</td>\n",
              "      <td>PyCon-co audios/audios/Lorena Aldana - Using P...</td>\n",
              "      <td>200</td>\n",
              "      <td>PyCon Colombia</td>\n",
              "      <td>2021-09-09</td>\n",
              "      <td>[]</td>\n",
              "      <td>UCjor6U0ZF5zGAYLJJt9gr0A</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>86.32</td>\n",
              "      <td>Música. . Entonces, quisiera comenzar por con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lorena Aldana - Using Python to listen to your...</td>\n",
              "      <td>https://www.youtube.com/watch?v=YrCSME1jT6U</td>\n",
              "      <td>PyCon-co audios/audios/Lorena Aldana - Using P...</td>\n",
              "      <td>200</td>\n",
              "      <td>PyCon Colombia</td>\n",
              "      <td>2021-09-09</td>\n",
              "      <td>[]</td>\n",
              "      <td>UCjor6U0ZF5zGAYLJJt9gr0A</td>\n",
              "      <td>2</td>\n",
              "      <td>86.32</td>\n",
              "      <td>92.60</td>\n",
              "      <td>palabra listen, escuchar y acá de pronto si t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lorena Aldana - Using Python to listen to your...</td>\n",
              "      <td>https://www.youtube.com/watch?v=YrCSME1jT6U</td>\n",
              "      <td>PyCon-co audios/audios/Lorena Aldana - Using P...</td>\n",
              "      <td>200</td>\n",
              "      <td>PyCon Colombia</td>\n",
              "      <td>2021-09-09</td>\n",
              "      <td>[]</td>\n",
              "      <td>UCjor6U0ZF5zGAYLJJt9gr0A</td>\n",
              "      <td>3</td>\n",
              "      <td>92.60</td>\n",
              "      <td>97.40</td>\n",
              "      <td>se los recomiendo vamos a estar escuchando al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lorena Aldana - Using Python to listen to your...</td>\n",
              "      <td>https://www.youtube.com/watch?v=YrCSME1jT6U</td>\n",
              "      <td>PyCon-co audios/audios/Lorena Aldana - Using P...</td>\n",
              "      <td>200</td>\n",
              "      <td>PyCon Colombia</td>\n",
              "      <td>2021-09-09</td>\n",
              "      <td>[]</td>\n",
              "      <td>UCjor6U0ZF5zGAYLJJt9gr0A</td>\n",
              "      <td>4</td>\n",
              "      <td>97.40</td>\n",
              "      <td>103.08</td>\n",
              "      <td>tienen audígonos no se preocupen no hay probl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lorena Aldana - Using Python to listen to your...</td>\n",
              "      <td>https://www.youtube.com/watch?v=YrCSME1jT6U</td>\n",
              "      <td>PyCon-co audios/audios/Lorena Aldana - Using P...</td>\n",
              "      <td>200</td>\n",
              "      <td>PyCon Colombia</td>\n",
              "      <td>2021-09-09</td>\n",
              "      <td>[]</td>\n",
              "      <td>UCjor6U0ZF5zGAYLJJt9gr0A</td>\n",
              "      <td>5</td>\n",
              "      <td>103.08</td>\n",
              "      <td>106.36</td>\n",
              "      <td>sería una buena idea, si les, digamos, a la m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5868</th>\n",
              "      <td>Interview Rodolfo Edelmann &amp; Carlos de la Torr...</td>\n",
              "      <td>https://www.youtube.com/watch?v=IvKQkp2CYqs</td>\n",
              "      <td>PyCon-co audios/audios/Interview Rodolfo Edelm...</td>\n",
              "      <td>274</td>\n",
              "      <td>PyCon Colombia</td>\n",
              "      <td>2020-04-21</td>\n",
              "      <td>[]</td>\n",
              "      <td>UCjor6U0ZF5zGAYLJJt9gr0A</td>\n",
              "      <td>78</td>\n",
              "      <td>753.68</td>\n",
              "      <td>759.76</td>\n",
              "      <td>para los estudiantes y estando en actividades...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5869</th>\n",
              "      <td>Interview Rodolfo Edelmann &amp; Carlos de la Torr...</td>\n",
              "      <td>https://www.youtube.com/watch?v=IvKQkp2CYqs</td>\n",
              "      <td>PyCon-co audios/audios/Interview Rodolfo Edelm...</td>\n",
              "      <td>274</td>\n",
              "      <td>PyCon Colombia</td>\n",
              "      <td>2020-04-21</td>\n",
              "      <td>[]</td>\n",
              "      <td>UCjor6U0ZF5zGAYLJJt9gr0A</td>\n",
              "      <td>79</td>\n",
              "      <td>759.76</td>\n",
              "      <td>765.88</td>\n",
              "      <td>por ahí de cuestiones más académicas. Entonce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5870</th>\n",
              "      <td>Interview Rodolfo Edelmann &amp; Carlos de la Torr...</td>\n",
              "      <td>https://www.youtube.com/watch?v=IvKQkp2CYqs</td>\n",
              "      <td>PyCon-co audios/audios/Interview Rodolfo Edelm...</td>\n",
              "      <td>274</td>\n",
              "      <td>PyCon Colombia</td>\n",
              "      <td>2020-04-21</td>\n",
              "      <td>[]</td>\n",
              "      <td>UCjor6U0ZF5zGAYLJJt9gr0A</td>\n",
              "      <td>80</td>\n",
              "      <td>765.88</td>\n",
              "      <td>771.44</td>\n",
              "      <td>las comunidades, no solamente tecnología, en ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5871</th>\n",
              "      <td>Interview Rodolfo Edelmann &amp; Carlos de la Torr...</td>\n",
              "      <td>https://www.youtube.com/watch?v=IvKQkp2CYqs</td>\n",
              "      <td>PyCon-co audios/audios/Interview Rodolfo Edelm...</td>\n",
              "      <td>274</td>\n",
              "      <td>PyCon Colombia</td>\n",
              "      <td>2020-04-21</td>\n",
              "      <td>[]</td>\n",
              "      <td>UCjor6U0ZF5zGAYLJJt9gr0A</td>\n",
              "      <td>81</td>\n",
              "      <td>771.44</td>\n",
              "      <td>780.24</td>\n",
              "      <td>Genial, que bueno saber todo eso, contar con ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5872</th>\n",
              "      <td>Interview Rodolfo Edelmann &amp; Carlos de la Torr...</td>\n",
              "      <td>https://www.youtube.com/watch?v=IvKQkp2CYqs</td>\n",
              "      <td>PyCon-co audios/audios/Interview Rodolfo Edelm...</td>\n",
              "      <td>274</td>\n",
              "      <td>PyCon Colombia</td>\n",
              "      <td>2020-04-21</td>\n",
              "      <td>[]</td>\n",
              "      <td>UCjor6U0ZF5zGAYLJJt9gr0A</td>\n",
              "      <td>82</td>\n",
              "      <td>780.24</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Por favor, nosotros nos encanta y muchas grac...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5873 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cde2b27-9122-4d85-bc39-84763c51ed26')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2cde2b27-9122-4d85-bc39-84763c51ed26 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2cde2b27-9122-4d85-bc39-84763c51ed26');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  title  \\\n",
              "0     Lorena Aldana - Using Python to listen to your...   \n",
              "1     Lorena Aldana - Using Python to listen to your...   \n",
              "2     Lorena Aldana - Using Python to listen to your...   \n",
              "3     Lorena Aldana - Using Python to listen to your...   \n",
              "4     Lorena Aldana - Using Python to listen to your...   \n",
              "...                                                 ...   \n",
              "5868  Interview Rodolfo Edelmann & Carlos de la Torr...   \n",
              "5869  Interview Rodolfo Edelmann & Carlos de la Torr...   \n",
              "5870  Interview Rodolfo Edelmann & Carlos de la Torr...   \n",
              "5871  Interview Rodolfo Edelmann & Carlos de la Torr...   \n",
              "5872  Interview Rodolfo Edelmann & Carlos de la Torr...   \n",
              "\n",
              "                                              url  \\\n",
              "0     https://www.youtube.com/watch?v=YrCSME1jT6U   \n",
              "1     https://www.youtube.com/watch?v=YrCSME1jT6U   \n",
              "2     https://www.youtube.com/watch?v=YrCSME1jT6U   \n",
              "3     https://www.youtube.com/watch?v=YrCSME1jT6U   \n",
              "4     https://www.youtube.com/watch?v=YrCSME1jT6U   \n",
              "...                                           ...   \n",
              "5868  https://www.youtube.com/watch?v=IvKQkp2CYqs   \n",
              "5869  https://www.youtube.com/watch?v=IvKQkp2CYqs   \n",
              "5870  https://www.youtube.com/watch?v=IvKQkp2CYqs   \n",
              "5871  https://www.youtube.com/watch?v=IvKQkp2CYqs   \n",
              "5872  https://www.youtube.com/watch?v=IvKQkp2CYqs   \n",
              "\n",
              "                                                   path  views  \\\n",
              "0     PyCon-co audios/audios/Lorena Aldana - Using P...    200   \n",
              "1     PyCon-co audios/audios/Lorena Aldana - Using P...    200   \n",
              "2     PyCon-co audios/audios/Lorena Aldana - Using P...    200   \n",
              "3     PyCon-co audios/audios/Lorena Aldana - Using P...    200   \n",
              "4     PyCon-co audios/audios/Lorena Aldana - Using P...    200   \n",
              "...                                                 ...    ...   \n",
              "5868  PyCon-co audios/audios/Interview Rodolfo Edelm...    274   \n",
              "5869  PyCon-co audios/audios/Interview Rodolfo Edelm...    274   \n",
              "5870  PyCon-co audios/audios/Interview Rodolfo Edelm...    274   \n",
              "5871  PyCon-co audios/audios/Interview Rodolfo Edelm...    274   \n",
              "5872  PyCon-co audios/audios/Interview Rodolfo Edelm...    274   \n",
              "\n",
              "              author publish_date keywords                channel_id  \\\n",
              "0     PyCon Colombia   2021-09-09       []  UCjor6U0ZF5zGAYLJJt9gr0A   \n",
              "1     PyCon Colombia   2021-09-09       []  UCjor6U0ZF5zGAYLJJt9gr0A   \n",
              "2     PyCon Colombia   2021-09-09       []  UCjor6U0ZF5zGAYLJJt9gr0A   \n",
              "3     PyCon Colombia   2021-09-09       []  UCjor6U0ZF5zGAYLJJt9gr0A   \n",
              "4     PyCon Colombia   2021-09-09       []  UCjor6U0ZF5zGAYLJJt9gr0A   \n",
              "...              ...          ...      ...                       ...   \n",
              "5868  PyCon Colombia   2020-04-21       []  UCjor6U0ZF5zGAYLJJt9gr0A   \n",
              "5869  PyCon Colombia   2020-04-21       []  UCjor6U0ZF5zGAYLJJt9gr0A   \n",
              "5870  PyCon Colombia   2020-04-21       []  UCjor6U0ZF5zGAYLJJt9gr0A   \n",
              "5871  PyCon Colombia   2020-04-21       []  UCjor6U0ZF5zGAYLJJt9gr0A   \n",
              "5872  PyCon Colombia   2020-04-21       []  UCjor6U0ZF5zGAYLJJt9gr0A   \n",
              "\n",
              "      position   start     end  \\\n",
              "0            1    0.00   86.32   \n",
              "1            2   86.32   92.60   \n",
              "2            3   92.60   97.40   \n",
              "3            4   97.40  103.08   \n",
              "4            5  103.08  106.36   \n",
              "...        ...     ...     ...   \n",
              "5868        78  753.68  759.76   \n",
              "5869        79  759.76  765.88   \n",
              "5870        80  765.88  771.44   \n",
              "5871        81  771.44  780.24   \n",
              "5872        82  780.24     NaN   \n",
              "\n",
              "                                                   text  \n",
              "0      Música. . Entonces, quisiera comenzar por con...  \n",
              "1      palabra listen, escuchar y acá de pronto si t...  \n",
              "2      se los recomiendo vamos a estar escuchando al...  \n",
              "3      tienen audígonos no se preocupen no hay probl...  \n",
              "4      sería una buena idea, si les, digamos, a la m...  \n",
              "...                                                 ...  \n",
              "5868   para los estudiantes y estando en actividades...  \n",
              "5869   por ahí de cuestiones más académicas. Entonce...  \n",
              "5870   las comunidades, no solamente tecnología, en ...  \n",
              "5871   Genial, que bueno saber todo eso, contar con ...  \n",
              "5872   Por favor, nosotros nos encanta y muchas grac...  \n",
              "\n",
              "[5873 rows x 12 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_transcribes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ5EHnGFQA_Q",
        "outputId": "61c4b84f-18ff-4958-9a78-052c9da88438"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1958/1958 [00:03<00:00, 543.74it/s]\n"
          ]
        }
      ],
      "source": [
        "new_data = []\n",
        "\n",
        "window= 6\n",
        "stride = 3\n",
        "\n",
        "for i in tqdm(range(0,len(df_transcribes),stride)):\n",
        "    i_end = min(len(df_transcribes)-1, i+window)\n",
        "    if df_transcribes.iloc[i]['title'] != df_transcribes.iloc[i_end]['title']:\n",
        "        continue\n",
        "    text = ' '.join(df_transcribes[i:i_end]['text'])\n",
        "    new_data.append({\n",
        "        'start': df_transcribes.iloc[i]['start'],\n",
        "        'end': df_transcribes.iloc[i_end]['end'],\n",
        "        'title': df_transcribes.iloc[i]['title'],\n",
        "        'views': df_transcribes.iloc[i]['views'],\n",
        "        'publish_date': df_transcribes.iloc[i]['publish_date'],\n",
        "        'keywords': df_transcribes.iloc[i]['keywords'],\n",
        "        'text':text,\n",
        "        'id': df_transcribes.iloc[i]['position'],\n",
        "        'url': df_transcribes.iloc[i]['url']\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHP9ejfdR4WU"
      },
      "outputs": [],
      "source": [
        "df_overlap = pd.DataFrame(new_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5DZ683uTvKn"
      },
      "source": [
        "## Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "7tuREO74TxGB",
        "outputId": "631237e0-f997-4d05-825b-a5adcd5ea5a6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5503b3a5-0017-458d-a63f-1933064c6f12\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>title</th>\n",
              "      <th>views</th>\n",
              "      <th>publish_date</th>\n",
              "      <th>keywords</th>\n",
              "      <th>text</th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>126.20</td>\n",
              "      <td>Lorena Aldana - Using Python to listen to your...</td>\n",
              "      <td>200</td>\n",
              "      <td>2021-09-09</td>\n",
              "      <td>[]</td>\n",
              "      <td>Música. . Entonces, quisiera comenzar por con...</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.youtube.com/watch?v=YrCSME1jT6U</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>97.40</td>\n",
              "      <td>187.00</td>\n",
              "      <td>Lorena Aldana - Using Python to listen to your...</td>\n",
              "      <td>200</td>\n",
              "      <td>2021-09-09</td>\n",
              "      <td>[]</td>\n",
              "      <td>tienen audígonos no se preocupen no hay probl...</td>\n",
              "      <td>4</td>\n",
              "      <td>https://www.youtube.com/watch?v=YrCSME1jT6U</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>117.56</td>\n",
              "      <td>204.00</td>\n",
              "      <td>Lorena Aldana - Using Python to listen to your...</td>\n",
              "      <td>200</td>\n",
              "      <td>2021-09-09</td>\n",
              "      <td>[]</td>\n",
              "      <td>Entonces, bueno, para dar una introducción, l...</td>\n",
              "      <td>7</td>\n",
              "      <td>https://www.youtube.com/watch?v=YrCSME1jT6U</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>136.32</td>\n",
              "      <td>305.88</td>\n",
              "      <td>Lorena Aldana - Using Python to listen to your...</td>\n",
              "      <td>200</td>\n",
              "      <td>2021-09-09</td>\n",
              "      <td>[]</td>\n",
              "      <td>Básicamente con el estetoscopio viene la idea...</td>\n",
              "      <td>10</td>\n",
              "      <td>https://www.youtube.com/watch?v=YrCSME1jT6U</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>199.00</td>\n",
              "      <td>319.00</td>\n",
              "      <td>Lorena Aldana - Using Python to listen to your...</td>\n",
              "      <td>200</td>\n",
              "      <td>2021-09-09</td>\n",
              "      <td>[]</td>\n",
              "      <td>estos sonidos que producen ciertos dispositiv...</td>\n",
              "      <td>13</td>\n",
              "      <td>https://www.youtube.com/watch?v=YrCSME1jT6U</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5503b3a5-0017-458d-a63f-1933064c6f12')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5503b3a5-0017-458d-a63f-1933064c6f12 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5503b3a5-0017-458d-a63f-1933064c6f12');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    start     end                                              title  views  \\\n",
              "0    0.00  126.20  Lorena Aldana - Using Python to listen to your...    200   \n",
              "1   97.40  187.00  Lorena Aldana - Using Python to listen to your...    200   \n",
              "2  117.56  204.00  Lorena Aldana - Using Python to listen to your...    200   \n",
              "3  136.32  305.88  Lorena Aldana - Using Python to listen to your...    200   \n",
              "4  199.00  319.00  Lorena Aldana - Using Python to listen to your...    200   \n",
              "\n",
              "  publish_date keywords                                               text  \\\n",
              "0   2021-09-09       []   Música. . Entonces, quisiera comenzar por con...   \n",
              "1   2021-09-09       []   tienen audígonos no se preocupen no hay probl...   \n",
              "2   2021-09-09       []   Entonces, bueno, para dar una introducción, l...   \n",
              "3   2021-09-09       []   Básicamente con el estetoscopio viene la idea...   \n",
              "4   2021-09-09       []   estos sonidos que producen ciertos dispositiv...   \n",
              "\n",
              "   id                                          url  \n",
              "0   1  https://www.youtube.com/watch?v=YrCSME1jT6U  \n",
              "1   4  https://www.youtube.com/watch?v=YrCSME1jT6U  \n",
              "2   7  https://www.youtube.com/watch?v=YrCSME1jT6U  \n",
              "3  10  https://www.youtube.com/watch?v=YrCSME1jT6U  \n",
              "4  13  https://www.youtube.com/watch?v=YrCSME1jT6U  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_overlap.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqlfwYPKT2sx"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIvVS5xIUJob"
      },
      "outputs": [],
      "source": [
        "sentences  = ['Este es un ejemplo','Este es otro ejemplo']\n",
        "embeddings = model.encode(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvS7eDqUUXi-",
        "outputId": "28975212-5beb-467e-c688-02f1e65b8c1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(embeddings[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465,
          "referenced_widgets": [
            "26e04c84978f4ab082bd29299e8b7a08",
            "4898ab50f3bf4a6592a6edf2b75bd211",
            "351d6711a1ce49c88c41871dab78ae64",
            "afcf44bf2da84ea28d421156fe07cb50",
            "8f881a6d2e444513a5f96007b1145a2e",
            "a3bfbe26fe094e97a03fae13d52042c2",
            "45197204b2df4fae8541399fd94bc406",
            "b9e6df11aa0d40ec9c04f0b92686acee",
            "d79d7db8da4a441ba2e5e0d02c00ffad",
            "50a3618f978c492abdbe7f272929b9b3",
            "d498b38ef1c84eb4b254237a17a32e02",
            "759a65d765bd42afa77e3466a191613d",
            "222e08c89c0b4599a77175ae02c09c16",
            "72d7cbabf7064ddcbb4e82b86915e39d",
            "6e81f16296f448b4978d9fe898cb1615",
            "387f185d607c415ba42ce50ddcc584e9",
            "73d0e622d3f84863827e1273fef6c684",
            "308a8f8c78bd41dbb2f548b4e07ddf07",
            "32d72c61c8314dc59d4b7953baaa2002",
            "85000de91c7b4f669bb6b411b5ea4531",
            "efe1a4b169f14305a9b84743ab90b826",
            "2d4c74bac8144dccb904e6396418d3bc",
            "22be04a7d8e24141ad3fe8ced195021f",
            "45ee93cd586e40eb8afec03531939e90",
            "918328ddfc854adfa20231f9cceb31eb",
            "9e3c0eb680d542fcb5cfc4f39f56d97d",
            "829f48a7b782488bb20fd9d43dea9a4a",
            "eb0bc34d326346f2828308197ae8bce1",
            "785fd2f4254f4c38b1d874838d364b88",
            "0fa5612d7d634da38d9c338f67d049de",
            "8282c6f713de44bc87f67de89fd3c9f0",
            "aeeb32f61e274a56a9df758dd362510d",
            "e5a8aa0d571a4eca8baa96dbe8592274",
            "841d0f415ede4a4a85b32b7b08f87291",
            "5dd2deec14e94decaa60a475509f6891",
            "f66bdf6112dd4810901ba830d37a39d9",
            "929d4a0f0c6c4bdeb59126f843192528",
            "ad46b1363b194f9db6dba17459c854ce",
            "dd31b40118404dd08b93ecef206d940e",
            "843a174d5e1c47c7897d0364d0b9352e",
            "12bd483163b34852bc1e40490601800a",
            "2ba86f9a1aa346888e65e9dbf8029fad",
            "b4684b02d4e94be1bdbe6371037a4263",
            "368cb94574034d7eb103eadccca12317",
            "ef0d7338c45a4214be597d4b47f8ac68",
            "2988b40fb93a4ce69081aa19ad9e9724",
            "c60808fcbf5b45c2a4ade36daa4a7669",
            "c47129ec7c1b461195ab18d64d602c9b",
            "1453633cccf243cd9f9e84f519d4ca05",
            "d730eb0dae4643ad9ad0d7ff2681d21b",
            "ba45247509d043fbae44e968f48fd470",
            "59d490914e874f729ca0dfbabb92cd71",
            "a1aaf00878f640cea7c8cbe687f1b469",
            "eafdd315fca8499ab362a17ebc577a58",
            "c252ae8aa250469b8726ad95e71ef14a",
            "37144b5873924ffba58d5b0049b401e4",
            "e26b2c5001524659a6c72ccfd89ce89a",
            "234454a344104b709e933bd41bff282c",
            "3b801fe5316a4ed3b6c5817f7b3b3b90",
            "7b4b6e8394314abeb4e93cbfc7c582e8",
            "421102b5f5a64a95bd006eff364033b3",
            "b641867c71d54cff80509af127dd0245",
            "be0298c1928c41e891fbcd65d5d77815",
            "569e8fd83ffa4933b39496277992af72",
            "69a5f68d078a4717a776763213839d37",
            "e41e4020a2704575a869f655345d2573",
            "ac499ff5fbd345168575e885b8e02b5b",
            "b421ddb8b58b4a7c989c15d7a120415f",
            "c601a96874ab4768a361a525ab414692",
            "852d084fe309498c8b71aec76ff1ba5f",
            "d582e4563c444a4f846ef843b42dc622",
            "97c4905b4051421cb529e7c66c25dda5",
            "29eeecc11a33409eb261c73b9eadee7c",
            "3923e9d36cc449dda0c8766e729bb0a7",
            "d30095c0dfa2496e807f3af1829ca3ad",
            "df6476c48ce542f38c257a545bccfdc9",
            "8ed85da85ccd4e6e89d504f83c015cf2",
            "bd8a823d3edc4feeadb15bc9ee64087a",
            "4aeca1137dfe475db13db385564dcdb7",
            "a60f476c9a074d91a884e413a9cc498c",
            "cccd192ee6ff4862a939f8c5494895f0",
            "66dee458b9d345a5a6d054e2ab689b65",
            "c7407efac95b4245a4e671ca441559bf",
            "3594ebf0f1684a05b7b95585f38f8e01",
            "d3e2b794f087466e92a4a2fc7049d4f3",
            "aa4359de6b7a46bc8e9e2a24c11f33ff",
            "5523296b4ac4445489b036602baf73c8",
            "c263b664eccd4cb1ba95440804412dd9",
            "58975e33660c4740a2811edc54518bdc",
            "be08516923a34b52b8e56f85ba35a628",
            "50802336e9c3405191f45dfa71fb65bd",
            "93fdc5d52a984575ac0d1664fd1d9946",
            "3b9c09f7456a49dda54078bf7ce60d31",
            "e9fcfd32515e4f969de3fc0e38383448",
            "3e29f9a280a44119a866cee8cb7517da",
            "b2f84621f11843ce87e8faccdf23a0ab",
            "591f64b90ddd4f68978ffd2b824892db",
            "f8530af9fe3949c2bcf88469fed1e134",
            "616a073868a747e3b2f88989327988c1",
            "b91d53982536420e833279e97cfc1d21",
            "976332ba14d14f58b4f31666e8b96347",
            "66e6f65cb7a44eaba8eceb188b7c9410",
            "85e5ec1a3c9947f3b19228b615ca1bee",
            "f6beb6e1880048f0a63a5f7e233940e8",
            "e540adcf581f41d291ca46b70c769ccb",
            "716c56f60df74258882a887eb697a1f3",
            "4744df8dc0514adea7e07f5e6cac9dd3",
            "a48e6d4a9a8343608fb4d054e6daf86f",
            "418ee9d4a15b4ea6b18fce44d6dee0c9",
            "5ac45f1c030d437f92c7ecde5e6e857d",
            "1a52230fd7124c52a7888cd005d57e1f",
            "1b5cb186945d44be93e58043cb6357a7",
            "722d3a0e57e94d72a4a94e43295f91a4",
            "b8aba4e3bb3a4187938aa91b67d6879c",
            "214a53348e2745cbab44cbc75386cf27",
            "f6a7a222991147f598a1f2d725da96cb",
            "eb83616403a44f0eaf11177d8c6335a6",
            "b270b44656344ea0aa868fd0d57ec166",
            "b190ea7550a3493fa6c65bbe5335bc9d",
            "1319f19dfa3d4a70b47184bb23278dcc",
            "6e858e5d0cd84ef8b168427f421d1943",
            "e24c5c58df074edaa1083602cb6a60b5",
            "83f1fef632464a8f81126ebca737721c",
            "99efae8af15045aca20f7ce9c5d851d9",
            "ecd9eaf92ee4427c83fda67bc43d9838",
            "1a4786e2f5f644af91ab2ea7b501ffdb",
            "a2ed4b9c73cb4427a1c6907e24fe5ff1",
            "50ffb1a72e3d4f33bdc012c802a3cefa",
            "6f8a9f535eab4099a12ca07c74111d3b",
            "753a4a798e5b4a43be17aeec44dc5b55",
            "8ac7c22f3c594b6ca0c5f84c713ba050",
            "bc510462c1834bac89a0aa49078a1892",
            "21e4f779fb084abd8e37bd28562e572b",
            "c3dc24725af24d8d9c933818639e23c7",
            "eb097afedab449eeb39562b2e1f106a1",
            "ec1811502c104eb3aeae86dba6eb0485",
            "50fb05e56fdf4d7099723463b698a555",
            "43bf2f5a97dc4540a9fdc54275e897cb",
            "42ff97b7428841909f6f53eb073ed960",
            "0602da154779406cb10b88543b34004c",
            "9e3cab98d3fc4fefaebf83b2800075ef",
            "c04fb076ff744a278fa1c3f304e85067",
            "c93e39c69cd34e7e9f66b2d3e9c66f12",
            "f612c25637144ccabe08f16ff27d6501",
            "2cb1f14a3709485f9eb1dcc0dabcad0e",
            "e0746f0508774f499334cbb30f346dfb",
            "5903908fc8124652a321b6ea4253a0e6",
            "68cbe6529ffb4fcb9ad03d1c3d998883",
            "23bab90ef14a46608e3bc2d204b168c2",
            "df9945cebb3043eb83681bdb7f4c17c7",
            "dd4c45b892a54e7180d5d320208a1246",
            "a141b4c443ec46428460e6d60ad663c4",
            "845637bd7fde40f0ba4a18ca31455ae6",
            "e5408791f01d4ef78feb06bc52442045"
          ]
        },
        "id": "5vmYhZATT-Vk",
        "outputId": "68ac087d-5d13-4a89-bb6e-a8e969bf83fc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26e04c84978f4ab082bd29299e8b7a08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)e9125/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "759a65d765bd42afa77e3466a191613d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22be04a7d8e24141ad3fe8ced195021f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)7e55de9125/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "841d0f415ede4a4a85b32b7b08f87291",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef0d7338c45a4214be597d4b47f8ac68",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37144b5873924ffba58d5b0049b401e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)125/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac499ff5fbd345168575e885b8e02b5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd8a823d3edc4feeadb15bc9ee64087a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58975e33660c4740a2811edc54518bdc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b91d53982536420e833279e97cfc1d21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)e9125/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a52230fd7124c52a7888cd005d57e1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e24c5c58df074edaa1083602cb6a60b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)9125/train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21e4f779fb084abd8e37bd28562e572b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)7e55de9125/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f612c25637144ccabe08f16ff27d6501",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-rY6CNiUItw"
      },
      "outputs": [],
      "source": [
        "embeddings = model.encode(df_overlap['text'],batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwUkr926U-kM"
      },
      "outputs": [],
      "source": [
        "df_overlap['embeddings'] = embeddings.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdGkAD4VVJ9j"
      },
      "outputs": [],
      "source": [
        "query = model.encode(['que es machine learning'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4mYt-LrVXmQ"
      },
      "outputs": [],
      "source": [
        "df_overlap['similarity'] = df_overlap['embeddings'].apply(lambda x : util.cos_sim(x,query[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KqCH3o5XVp7l",
        "outputId": "fd2e8e20-0a47-4258-8fc8-e860dbbe82cb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1e4e0dad-6a71-4922-b6cd-df95dcfe8cac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>title</th>\n",
              "      <th>views</th>\n",
              "      <th>publish_date</th>\n",
              "      <th>keywords</th>\n",
              "      <th>text</th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>embeddings</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>992</th>\n",
              "      <td>788.48</td>\n",
              "      <td>808.16</td>\n",
              "      <td>Sebastián Arango - Enhancing Data Privacy thro...</td>\n",
              "      <td>208</td>\n",
              "      <td>2020-03-06</td>\n",
              "      <td>[]</td>\n",
              "      <td>posean.  Entonces, ¿qué es realmente el apren...</td>\n",
              "      <td>138</td>\n",
              "      <td>https://www.youtube.com/watch?v=mEPw36JE_8w</td>\n",
              "      <td>[0.017229102551937103, -0.04375387355685234, -...</td>\n",
              "      <td>[[tensor(0.6721)]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>89.04</td>\n",
              "      <td>109.32</td>\n",
              "      <td>Rodolfo Edelmann &amp; Carlos de la Torre - Conect...</td>\n",
              "      <td>503</td>\n",
              "      <td>2020-04-20</td>\n",
              "      <td>[]</td>\n",
              "      <td>Ahora en Mercado Libre estamos, como hizo Rud...</td>\n",
              "      <td>5</td>\n",
              "      <td>https://www.youtube.com/watch?v=N3czkxo2JJw</td>\n",
              "      <td>[-0.012716985307633877, 0.01819167099893093, -...</td>\n",
              "      <td>[[tensor(0.6704)]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1863</th>\n",
              "      <td>61.08</td>\n",
              "      <td>178.00</td>\n",
              "      <td>Rafael Carrascosa - Software engineering for m...</td>\n",
              "      <td>503</td>\n",
              "      <td>2021-08-05</td>\n",
              "      <td>[]</td>\n",
              "      <td>El que se llama la.  El que se llama la.  El ...</td>\n",
              "      <td>35</td>\n",
              "      <td>https://www.youtube.com/watch?v=OVe1GzubDP8</td>\n",
              "      <td>[-0.05274017155170441, -0.019284287467598915, ...</td>\n",
              "      <td>[[tensor(0.6415)]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1876</th>\n",
              "      <td>714.40</td>\n",
              "      <td>779.00</td>\n",
              "      <td>Rafael Carrascosa - Software engineering for m...</td>\n",
              "      <td>503</td>\n",
              "      <td>2021-08-05</td>\n",
              "      <td>[]</td>\n",
              "      <td>estas y otras, en Mercado Libre tenemos proce...</td>\n",
              "      <td>74</td>\n",
              "      <td>https://www.youtube.com/watch?v=OVe1GzubDP8</td>\n",
              "      <td>[-0.02382172830402851, 0.037150848656892776, -...</td>\n",
              "      <td>[[tensor(0.6105)]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1864</th>\n",
              "      <td>64.08</td>\n",
              "      <td>205.98</td>\n",
              "      <td>Rafael Carrascosa - Software engineering for m...</td>\n",
              "      <td>503</td>\n",
              "      <td>2021-08-05</td>\n",
              "      <td>[]</td>\n",
              "      <td>El que se llama la. El que se llama la. El qu...</td>\n",
              "      <td>38</td>\n",
              "      <td>https://www.youtube.com/watch?v=OVe1GzubDP8</td>\n",
              "      <td>[-0.057171739637851715, -0.005716548301279545,...</td>\n",
              "      <td>[[tensor(0.6085)]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1872</th>\n",
              "      <td>335.00</td>\n",
              "      <td>617.00</td>\n",
              "      <td>Rafael Carrascosa - Software engineering for m...</td>\n",
              "      <td>503</td>\n",
              "      <td>2021-08-05</td>\n",
              "      <td>[]</td>\n",
              "      <td>Para planificar y estimar un proyecto que tie...</td>\n",
              "      <td>62</td>\n",
              "      <td>https://www.youtube.com/watch?v=OVe1GzubDP8</td>\n",
              "      <td>[-0.04295634850859642, 0.01834726333618164, 0....</td>\n",
              "      <td>[[tensor(0.5897)]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>964</th>\n",
              "      <td>326.20</td>\n",
              "      <td>367.00</td>\n",
              "      <td>Sebastián Arango - Enhancing Data Privacy thro...</td>\n",
              "      <td>208</td>\n",
              "      <td>2020-03-06</td>\n",
              "      <td>[]</td>\n",
              "      <td>haga posible identificar al usuario esté tota...</td>\n",
              "      <td>54</td>\n",
              "      <td>https://www.youtube.com/watch?v=mEPw36JE_8w</td>\n",
              "      <td>[-0.03910747542977333, -0.0779929831624031, -0...</td>\n",
              "      <td>[[tensor(0.5723)]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>800.20</td>\n",
              "      <td>817.00</td>\n",
              "      <td>Sebastián Arango - Enhancing Data Privacy thro...</td>\n",
              "      <td>208</td>\n",
              "      <td>2020-03-06</td>\n",
              "      <td>[]</td>\n",
              "      <td>nuevo, Machine Learning.  De hecho, utiliza l...</td>\n",
              "      <td>141</td>\n",
              "      <td>https://www.youtube.com/watch?v=mEPw36JE_8w</td>\n",
              "      <td>[0.055914122611284256, -0.0326554998755455, -0...</td>\n",
              "      <td>[[tensor(0.5699)]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1873</th>\n",
              "      <td>397.00</td>\n",
              "      <td>643.52</td>\n",
              "      <td>Rafael Carrascosa - Software engineering for m...</td>\n",
              "      <td>503</td>\n",
              "      <td>2021-08-05</td>\n",
              "      <td>[]</td>\n",
              "      <td>El primero es la herramienta de factibilidad ...</td>\n",
              "      <td>65</td>\n",
              "      <td>https://www.youtube.com/watch?v=OVe1GzubDP8</td>\n",
              "      <td>[-0.01800951361656189, 0.038617558777332306, -...</td>\n",
              "      <td>[[tensor(0.5664)]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1886</th>\n",
              "      <td>253.56</td>\n",
              "      <td>304.12</td>\n",
              "      <td>Interview Rodolfo Edelmann &amp; Carlos de la Torr...</td>\n",
              "      <td>274</td>\n",
              "      <td>2020-04-21</td>\n",
              "      <td>[]</td>\n",
              "      <td>lo que es el Machine Learning en la organizac...</td>\n",
              "      <td>18</td>\n",
              "      <td>https://www.youtube.com/watch?v=IvKQkp2CYqs</td>\n",
              "      <td>[0.04165314510464668, -0.005298386327922344, -...</td>\n",
              "      <td>[[tensor(0.5547)]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e4e0dad-6a71-4922-b6cd-df95dcfe8cac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e4e0dad-6a71-4922-b6cd-df95dcfe8cac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e4e0dad-6a71-4922-b6cd-df95dcfe8cac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       start     end                                              title  \\\n",
              "992   788.48  808.16  Sebastián Arango - Enhancing Data Privacy thro...   \n",
              "292    89.04  109.32  Rodolfo Edelmann & Carlos de la Torre - Conect...   \n",
              "1863   61.08  178.00  Rafael Carrascosa - Software engineering for m...   \n",
              "1876  714.40  779.00  Rafael Carrascosa - Software engineering for m...   \n",
              "1864   64.08  205.98  Rafael Carrascosa - Software engineering for m...   \n",
              "1872  335.00  617.00  Rafael Carrascosa - Software engineering for m...   \n",
              "964   326.20  367.00  Sebastián Arango - Enhancing Data Privacy thro...   \n",
              "993   800.20  817.00  Sebastián Arango - Enhancing Data Privacy thro...   \n",
              "1873  397.00  643.52  Rafael Carrascosa - Software engineering for m...   \n",
              "1886  253.56  304.12  Interview Rodolfo Edelmann & Carlos de la Torr...   \n",
              "\n",
              "      views publish_date keywords  \\\n",
              "992     208   2020-03-06       []   \n",
              "292     503   2020-04-20       []   \n",
              "1863    503   2021-08-05       []   \n",
              "1876    503   2021-08-05       []   \n",
              "1864    503   2021-08-05       []   \n",
              "1872    503   2021-08-05       []   \n",
              "964     208   2020-03-06       []   \n",
              "993     208   2020-03-06       []   \n",
              "1873    503   2021-08-05       []   \n",
              "1886    274   2020-04-21       []   \n",
              "\n",
              "                                                   text   id  \\\n",
              "992    posean.  Entonces, ¿qué es realmente el apren...  138   \n",
              "292    Ahora en Mercado Libre estamos, como hizo Rud...    5   \n",
              "1863   El que se llama la.  El que se llama la.  El ...   35   \n",
              "1876   estas y otras, en Mercado Libre tenemos proce...   74   \n",
              "1864   El que se llama la. El que se llama la. El qu...   38   \n",
              "1872   Para planificar y estimar un proyecto que tie...   62   \n",
              "964    haga posible identificar al usuario esté tota...   54   \n",
              "993    nuevo, Machine Learning.  De hecho, utiliza l...  141   \n",
              "1873   El primero es la herramienta de factibilidad ...   65   \n",
              "1886   lo que es el Machine Learning en la organizac...   18   \n",
              "\n",
              "                                              url  \\\n",
              "992   https://www.youtube.com/watch?v=mEPw36JE_8w   \n",
              "292   https://www.youtube.com/watch?v=N3czkxo2JJw   \n",
              "1863  https://www.youtube.com/watch?v=OVe1GzubDP8   \n",
              "1876  https://www.youtube.com/watch?v=OVe1GzubDP8   \n",
              "1864  https://www.youtube.com/watch?v=OVe1GzubDP8   \n",
              "1872  https://www.youtube.com/watch?v=OVe1GzubDP8   \n",
              "964   https://www.youtube.com/watch?v=mEPw36JE_8w   \n",
              "993   https://www.youtube.com/watch?v=mEPw36JE_8w   \n",
              "1873  https://www.youtube.com/watch?v=OVe1GzubDP8   \n",
              "1886  https://www.youtube.com/watch?v=IvKQkp2CYqs   \n",
              "\n",
              "                                             embeddings          similarity  \n",
              "992   [0.017229102551937103, -0.04375387355685234, -...  [[tensor(0.6721)]]  \n",
              "292   [-0.012716985307633877, 0.01819167099893093, -...  [[tensor(0.6704)]]  \n",
              "1863  [-0.05274017155170441, -0.019284287467598915, ...  [[tensor(0.6415)]]  \n",
              "1876  [-0.02382172830402851, 0.037150848656892776, -...  [[tensor(0.6105)]]  \n",
              "1864  [-0.057171739637851715, -0.005716548301279545,...  [[tensor(0.6085)]]  \n",
              "1872  [-0.04295634850859642, 0.01834726333618164, 0....  [[tensor(0.5897)]]  \n",
              "964   [-0.03910747542977333, -0.0779929831624031, -0...  [[tensor(0.5723)]]  \n",
              "993   [0.055914122611284256, -0.0326554998755455, -0...  [[tensor(0.5699)]]  \n",
              "1873  [-0.01800951361656189, 0.038617558777332306, -...  [[tensor(0.5664)]]  \n",
              "1886  [0.04165314510464668, -0.005298386327922344, -...  [[tensor(0.5547)]]  "
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_overlap.sort_values('similarity',ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLN70UitXZ6t"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "\n",
        "client = chromadb.Client()\n",
        "collection = client.create_collection('pycon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQ6F2mekXjwX"
      },
      "outputs": [],
      "source": [
        "df_overlap['id_database'] = df_overlap.apply(lambda x : str(hash(x['title']))+ '-'+ str(x['id']),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2dpcz6nX7hy"
      },
      "outputs": [],
      "source": [
        "collection.add(\n",
        "    ids= df_overlap['id_database'].tolist(),\n",
        "    embeddings= df_overlap['embeddings'].tolist(),\n",
        "    metadatas= df_overlap[['start','end','text','views','publish_date','url']].to_dict('records')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NXaz6eiZK6A"
      },
      "outputs": [],
      "source": [
        "content = collection.query(\n",
        "    query_texts=['data visualization','inteligencia artificial'],\n",
        "    n_results=5\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuRDmJajZbv0",
        "outputId": "308b85da-1b04-4665-82e5-b25189d8924b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ids': [['-7197006188288390196-32',\n",
              "   '-4816308460378474192-103',\n",
              "   '-4816308460378474192-100',\n",
              "   '6702413160318715901-457',\n",
              "   '6702413160318715901-454'],\n",
              "  ['2798893731107084338-5',\n",
              "   '-8406772746904429018-398',\n",
              "   '-8406772746904429018-401',\n",
              "   '-5961273752038882282-8',\n",
              "   '-8406772746904429018-425']],\n",
              " 'embeddings': None,\n",
              " 'documents': [[None, None, None, None, None], [None, None, None, None, None]],\n",
              " 'metadatas': [[{'start': 239.78,\n",
              "    'end': 277.2,\n",
              "    'text': ' So I like this kind of graph because it represents more or less the timelines we have been seeing  from the cloud world.  Some years ago, for instance, I got the opportunity to install a real server in the sense of I  got the machine in front of me. And I needed to install the operating system,  put in this server behind a rack or a firewall.  And it was a nightmare, because I was a developer, not',\n",
              "    'views': 175,\n",
              "    'publish_date': '2019-07-20',\n",
              "    'url': 'https://www.youtube.com/watch?v=YkI-B8cArRI'},\n",
              "   {'start': 919.1,\n",
              "    'end': 998.9,\n",
              "    'text': \" example we did is the earthquake in Mexico. Our accelerometers, even if the  vehicle is off and the device is sleeping, can wake up when they detect a force. So you're going to see it here, how they are, most of them, the vehicle is sleeping and when it gets to the critical hour of the earthquake, they wake up and you will see a lot more vehicles moving. Here you see also the chart. Actually,  for this one we only use Python to develop these maps and charts and the analysis. Just  before going into the dataset of Bogota, I wanted to talk a little bit about a similar  project we did in Spain. In Spain we have something called Accident Black Spot. That's when in a year you have more than three victims in accidents in an area. So we got a data set of those areas. We had the details on the most common accident in that area, on the number of casualties, and  we categorized them by that. So I did here just some analysis comparing the erratic driving\",\n",
              "    'views': 543,\n",
              "    'publish_date': '2019-07-25',\n",
              "    'url': 'https://www.youtube.com/watch?v=E_rPy0h5fXI'},\n",
              "   {'start': 902.32,\n",
              "    'end': 962.44,\n",
              "    'text': \" before, one week before on the top and after the  Hurricane Harvey. So we can see there is an 88% less of activity after the  hurricane. This is a huge impact for business and customers in that area. Another  example we did is the earthquake in Mexico. Our accelerometers, even if the  vehicle is off and the device is sleeping, can wake up when they detect a force. So you're going to see it here, how they are, most of them, the vehicle is sleeping and when it gets to the critical hour of the earthquake, they wake up and you will see a lot more vehicles moving. Here you see also the chart. Actually,  for this one we only use Python to develop these maps and charts and the analysis. Just\",\n",
              "    'views': 543,\n",
              "    'publish_date': '2019-07-25',\n",
              "    'url': 'https://www.youtube.com/watch?v=E_rPy0h5fXI'},\n",
              "   {'start': 2016.12,\n",
              "    'end': 2066.64,\n",
              "    'text': ' So what we did at the end was just like sharing the insight that we both have, and then put  that in the first part of the graph.  Remember that I told you this was really low consumption RAM?  All that data cleaning was there. But actually, finding what was dirty was a task for both the engineering and the data scientists.  Okay, thanks. Thanks for your talk. Do you know other Python library to extract and transform on information  for your project? Well, I guess that depends for this particular project. Maybe, well,',\n",
              "    'views': 110,\n",
              "    'publish_date': '2019-05-24',\n",
              "    'url': 'https://www.youtube.com/watch?v=c8y2yS_p8wM'},\n",
              "   {'start': 2005.68,\n",
              "    'end': 2032.0,\n",
              "    'text': ' And as I told you before, both the data science team and the engineering team were working  like separated, and we both identified problems with the data, about equality, cleaning and  everything.  So what we did at the end was just like sharing the insight that we both have, and then put  that in the first part of the graph.  Remember that I told you this was really low consumption RAM?',\n",
              "    'views': 110,\n",
              "    'publish_date': '2019-05-24',\n",
              "    'url': 'https://www.youtube.com/watch?v=c8y2yS_p8wM'}],\n",
              "  [{'start': 89.04,\n",
              "    'end': 109.32,\n",
              "    'text': ' Ahora en Mercado Libre estamos, como hizo Rudy,  armando la infraestructura para ejecutar Machine Learning en  producción y a escala.  Bueno, queremos entonces contarles un poquito de qué va  a ser la charla.  Primero que todos, para entender el motivo de la charla,',\n",
              "    'views': 503,\n",
              "    'publish_date': '2020-04-20',\n",
              "    'url': 'https://www.youtube.com/watch?v=N3czkxo2JJw'},\n",
              "   {'start': 2498.18,\n",
              "    'end': 2540.92,\n",
              "    'text': \" is what I try and encourage.  This is kind of the balance, right?  Like scientists are amazing people,  their job is to observe and question, right? Like science is mostly about theory and asking why and how can we do this? Computer scientists especially, like right now, there's computer scientists around the world working on some incredible problems that will affect you in about 15 to 20 years. Like they're doing amazing research into type systems, into algorithms, into P  equals NP, into proofs, and all sorts of other things I don't even know about. AI is where,  obviously, machine learning is where these two meet very strongly. And it's an amazing\",\n",
              "    'views': 587,\n",
              "    'publish_date': '2020-02-19',\n",
              "    'url': 'https://www.youtube.com/watch?v=862xL6jm_PQ'},\n",
              "   {'start': 2504.84,\n",
              "    'end': 2599.3,\n",
              "    'text': \" their job is to observe and question, right? Like science is mostly about theory and asking why and how can we do this? Computer scientists especially, like right now, there's computer scientists around the world working on some incredible problems that will affect you in about 15 to 20 years. Like they're doing amazing research into type systems, into algorithms, into P  equals NP, into proofs, and all sorts of other things I don't even know about. AI is where,  obviously, machine learning is where these two meet very strongly. And it's an amazing  piece and a lot of their work is fantastically important as they're analysing. Engineers  are much more practical. Engineers take problems, they build solutions, they invent the solutions. I bet you that every single large project ever has someone who's gone, I'll just hammer it in. They've just got on engines to make sure they work fine. It looks really hacky, but it's perfectly fine. That stuff's rated for like a good 20 or 30 flights. It's a case of understanding when to do things a quick way and when to do things the slow way and the correct way. Part of this is like all software we write has consequences. You may not think about it like, you know,  you're not putting up writing software for self-driving cars or that does money transactions or that handles people's like, you know,\",\n",
              "    'views': 587,\n",
              "    'publish_date': '2020-02-19',\n",
              "    'url': 'https://www.youtube.com/watch?v=862xL6jm_PQ'},\n",
              "   {'start': 120.68,\n",
              "    'end': 180.72,\n",
              "    'text': \" appreciate. And also automation gives us a very repeatable and predictable way to perform actions on these servers. If we were to do these things manually, it would be hard to do it exactly the same way every time, right? So it would also not scale, because we have a limited number of engineers, and we have a very large number of servers, and that keeps growing every time. So, we have a very large number of engineers, and we have a very large number of servers, and that keeps growing every time. So, we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number also not scale because we have a limited number of  engineers and we have a very large number of servers and that keeps growing every time.  So using automation, which effectively means writing code to do things on the infrastructure,  also fits in well with everything else we do because if we're writing code for managing  our servers, we can use the same tools that  we normally use for doing other type of development. So that means that we can also use the same\",\n",
              "    'views': 152,\n",
              "    'publish_date': '2018-12-26',\n",
              "    'url': 'https://www.youtube.com/watch?v=5rgZQw0F0w0'},\n",
              "   {'start': 2649.24,\n",
              "    'end': nan,\n",
              "    'text': \" the big algorithm works and to like analyze a piece of code  and break it apart and just understand what's going on  in there is super important.  You have to understand when to be that person,  and when to be the person with the hammer, right?  When to be the person, how it'll be fine,\",\n",
              "    'views': 587,\n",
              "    'publish_date': '2020-02-19',\n",
              "    'url': 'https://www.youtube.com/watch?v=862xL6jm_PQ'}]],\n",
              " 'distances': [[0.9789426326751709,\n",
              "   1.0385767221450806,\n",
              "   1.12004816532135,\n",
              "   1.1203632354736328,\n",
              "   1.12346351146698],\n",
              "  [1.25662362575531,\n",
              "   1.3554996252059937,\n",
              "   1.3682520389556885,\n",
              "   1.3966959714889526,\n",
              "   1.4245736598968506]]}"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "content"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0602da154779406cb10b88543b34004c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fa5612d7d634da38d9c338f67d049de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12bd483163b34852bc1e40490601800a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1319f19dfa3d4a70b47184bb23278dcc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1453633cccf243cd9f9e84f519d4ca05": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a4786e2f5f644af91ab2ea7b501ffdb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a52230fd7124c52a7888cd005d57e1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b5cb186945d44be93e58043cb6357a7",
              "IPY_MODEL_722d3a0e57e94d72a4a94e43295f91a4",
              "IPY_MODEL_b8aba4e3bb3a4187938aa91b67d6879c"
            ],
            "layout": "IPY_MODEL_214a53348e2745cbab44cbc75386cf27"
          }
        },
        "1b5cb186945d44be93e58043cb6357a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6a7a222991147f598a1f2d725da96cb",
            "placeholder": "​",
            "style": "IPY_MODEL_eb83616403a44f0eaf11177d8c6335a6",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "214a53348e2745cbab44cbc75386cf27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21e4f779fb084abd8e37bd28562e572b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3dc24725af24d8d9c933818639e23c7",
              "IPY_MODEL_eb097afedab449eeb39562b2e1f106a1",
              "IPY_MODEL_ec1811502c104eb3aeae86dba6eb0485"
            ],
            "layout": "IPY_MODEL_50fb05e56fdf4d7099723463b698a555"
          }
        },
        "222e08c89c0b4599a77175ae02c09c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73d0e622d3f84863827e1273fef6c684",
            "placeholder": "​",
            "style": "IPY_MODEL_308a8f8c78bd41dbb2f548b4e07ddf07",
            "value": "Downloading (…)_Pooling/config.json: 100%"
          }
        },
        "22be04a7d8e24141ad3fe8ced195021f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45ee93cd586e40eb8afec03531939e90",
              "IPY_MODEL_918328ddfc854adfa20231f9cceb31eb",
              "IPY_MODEL_9e3c0eb680d542fcb5cfc4f39f56d97d"
            ],
            "layout": "IPY_MODEL_829f48a7b782488bb20fd9d43dea9a4a"
          }
        },
        "234454a344104b709e933bd41bff282c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be0298c1928c41e891fbcd65d5d77815",
            "max": 39265,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_569e8fd83ffa4933b39496277992af72",
            "value": 39265
          }
        },
        "23bab90ef14a46608e3bc2d204b168c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26e04c84978f4ab082bd29299e8b7a08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4898ab50f3bf4a6592a6edf2b75bd211",
              "IPY_MODEL_351d6711a1ce49c88c41871dab78ae64",
              "IPY_MODEL_afcf44bf2da84ea28d421156fe07cb50"
            ],
            "layout": "IPY_MODEL_8f881a6d2e444513a5f96007b1145a2e"
          }
        },
        "2988b40fb93a4ce69081aa19ad9e9724": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d730eb0dae4643ad9ad0d7ff2681d21b",
            "placeholder": "​",
            "style": "IPY_MODEL_ba45247509d043fbae44e968f48fd470",
            "value": "Downloading (…)ce_transformers.json: 100%"
          }
        },
        "29eeecc11a33409eb261c73b9eadee7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ba86f9a1aa346888e65e9dbf8029fad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cb1f14a3709485f9eb1dcc0dabcad0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23bab90ef14a46608e3bc2d204b168c2",
            "placeholder": "​",
            "style": "IPY_MODEL_df9945cebb3043eb83681bdb7f4c17c7",
            "value": "Downloading (…)5de9125/modules.json: 100%"
          }
        },
        "2d4c74bac8144dccb904e6396418d3bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "308a8f8c78bd41dbb2f548b4e07ddf07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32d72c61c8314dc59d4b7953baaa2002": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "351d6711a1ce49c88c41871dab78ae64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9e6df11aa0d40ec9c04f0b92686acee",
            "max": 1175,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d79d7db8da4a441ba2e5e0d02c00ffad",
            "value": 1175
          }
        },
        "3594ebf0f1684a05b7b95585f38f8e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "368cb94574034d7eb103eadccca12317": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37144b5873924ffba58d5b0049b401e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e26b2c5001524659a6c72ccfd89ce89a",
              "IPY_MODEL_234454a344104b709e933bd41bff282c",
              "IPY_MODEL_3b801fe5316a4ed3b6c5817f7b3b3b90"
            ],
            "layout": "IPY_MODEL_7b4b6e8394314abeb4e93cbfc7c582e8"
          }
        },
        "387f185d607c415ba42ce50ddcc584e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3923e9d36cc449dda0c8766e729bb0a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b801fe5316a4ed3b6c5817f7b3b3b90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69a5f68d078a4717a776763213839d37",
            "placeholder": "​",
            "style": "IPY_MODEL_e41e4020a2704575a869f655345d2573",
            "value": " 39.3k/39.3k [00:00&lt;00:00, 2.08MB/s]"
          }
        },
        "3b9c09f7456a49dda54078bf7ce60d31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e29f9a280a44119a866cee8cb7517da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "418ee9d4a15b4ea6b18fce44d6dee0c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "421102b5f5a64a95bd006eff364033b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42ff97b7428841909f6f53eb073ed960": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43bf2f5a97dc4540a9fdc54275e897cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45197204b2df4fae8541399fd94bc406": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45ee93cd586e40eb8afec03531939e90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb0bc34d326346f2828308197ae8bce1",
            "placeholder": "​",
            "style": "IPY_MODEL_785fd2f4254f4c38b1d874838d364b88",
            "value": "Downloading (…)7e55de9125/README.md: 100%"
          }
        },
        "4744df8dc0514adea7e07f5e6cac9dd3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4898ab50f3bf4a6592a6edf2b75bd211": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3bfbe26fe094e97a03fae13d52042c2",
            "placeholder": "​",
            "style": "IPY_MODEL_45197204b2df4fae8541399fd94bc406",
            "value": "Downloading (…)e9125/.gitattributes: 100%"
          }
        },
        "4aeca1137dfe475db13db385564dcdb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7407efac95b4245a4e671ca441559bf",
            "placeholder": "​",
            "style": "IPY_MODEL_3594ebf0f1684a05b7b95585f38f8e01",
            "value": "Downloading (…)nce_bert_config.json: 100%"
          }
        },
        "50802336e9c3405191f45dfa71fb65bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2f84621f11843ce87e8faccdf23a0ab",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_591f64b90ddd4f68978ffd2b824892db",
            "value": 112
          }
        },
        "50a3618f978c492abdbe7f272929b9b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50fb05e56fdf4d7099723463b698a555": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50ffb1a72e3d4f33bdc012c802a3cefa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5523296b4ac4445489b036602baf73c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "569e8fd83ffa4933b39496277992af72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58975e33660c4740a2811edc54518bdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be08516923a34b52b8e56f85ba35a628",
              "IPY_MODEL_50802336e9c3405191f45dfa71fb65bd",
              "IPY_MODEL_93fdc5d52a984575ac0d1664fd1d9946"
            ],
            "layout": "IPY_MODEL_3b9c09f7456a49dda54078bf7ce60d31"
          }
        },
        "5903908fc8124652a321b6ea4253a0e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_845637bd7fde40f0ba4a18ca31455ae6",
            "placeholder": "​",
            "style": "IPY_MODEL_e5408791f01d4ef78feb06bc52442045",
            "value": " 349/349 [00:00&lt;00:00, 16.6kB/s]"
          }
        },
        "591f64b90ddd4f68978ffd2b824892db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59d490914e874f729ca0dfbabb92cd71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ac45f1c030d437f92c7ecde5e6e857d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dd2deec14e94decaa60a475509f6891": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd31b40118404dd08b93ecef206d940e",
            "placeholder": "​",
            "style": "IPY_MODEL_843a174d5e1c47c7897d0364d0b9352e",
            "value": "Downloading (…)55de9125/config.json: 100%"
          }
        },
        "616a073868a747e3b2f88989327988c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66dee458b9d345a5a6d054e2ab689b65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66e6f65cb7a44eaba8eceb188b7c9410": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4744df8dc0514adea7e07f5e6cac9dd3",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a48e6d4a9a8343608fb4d054e6daf86f",
            "value": 466247
          }
        },
        "68cbe6529ffb4fcb9ad03d1c3d998883": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69a5f68d078a4717a776763213839d37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e81f16296f448b4978d9fe898cb1615": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efe1a4b169f14305a9b84743ab90b826",
            "placeholder": "​",
            "style": "IPY_MODEL_2d4c74bac8144dccb904e6396418d3bc",
            "value": " 190/190 [00:00&lt;00:00, 14.4kB/s]"
          }
        },
        "6e858e5d0cd84ef8b168427f421d1943": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f8a9f535eab4099a12ca07c74111d3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "716c56f60df74258882a887eb697a1f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "722d3a0e57e94d72a4a94e43295f91a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b270b44656344ea0aa868fd0d57ec166",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b190ea7550a3493fa6c65bbe5335bc9d",
            "value": 350
          }
        },
        "72d7cbabf7064ddcbb4e82b86915e39d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32d72c61c8314dc59d4b7953baaa2002",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85000de91c7b4f669bb6b411b5ea4531",
            "value": 190
          }
        },
        "73d0e622d3f84863827e1273fef6c684": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "753a4a798e5b4a43be17aeec44dc5b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "759a65d765bd42afa77e3466a191613d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_222e08c89c0b4599a77175ae02c09c16",
              "IPY_MODEL_72d7cbabf7064ddcbb4e82b86915e39d",
              "IPY_MODEL_6e81f16296f448b4978d9fe898cb1615"
            ],
            "layout": "IPY_MODEL_387f185d607c415ba42ce50ddcc584e9"
          }
        },
        "785fd2f4254f4c38b1d874838d364b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b4b6e8394314abeb4e93cbfc7c582e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8282c6f713de44bc87f67de89fd3c9f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "829f48a7b782488bb20fd9d43dea9a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83f1fef632464a8f81126ebca737721c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2ed4b9c73cb4427a1c6907e24fe5ff1",
            "placeholder": "​",
            "style": "IPY_MODEL_50ffb1a72e3d4f33bdc012c802a3cefa",
            "value": "Downloading (…)9125/train_script.py: 100%"
          }
        },
        "841d0f415ede4a4a85b32b7b08f87291": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5dd2deec14e94decaa60a475509f6891",
              "IPY_MODEL_f66bdf6112dd4810901ba830d37a39d9",
              "IPY_MODEL_929d4a0f0c6c4bdeb59126f843192528"
            ],
            "layout": "IPY_MODEL_ad46b1363b194f9db6dba17459c854ce"
          }
        },
        "843a174d5e1c47c7897d0364d0b9352e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "845637bd7fde40f0ba4a18ca31455ae6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85000de91c7b4f669bb6b411b5ea4531": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "852d084fe309498c8b71aec76ff1ba5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df6476c48ce542f38c257a545bccfdc9",
            "placeholder": "​",
            "style": "IPY_MODEL_8ed85da85ccd4e6e89d504f83c015cf2",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 342MB/s]"
          }
        },
        "85e5ec1a3c9947f3b19228b615ca1bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_418ee9d4a15b4ea6b18fce44d6dee0c9",
            "placeholder": "​",
            "style": "IPY_MODEL_5ac45f1c030d437f92c7ecde5e6e857d",
            "value": " 466k/466k [00:00&lt;00:00, 29.9MB/s]"
          }
        },
        "8ac7c22f3c594b6ca0c5f84c713ba050": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ed85da85ccd4e6e89d504f83c015cf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f881a6d2e444513a5f96007b1145a2e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "918328ddfc854adfa20231f9cceb31eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fa5612d7d634da38d9c338f67d049de",
            "max": 10610,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8282c6f713de44bc87f67de89fd3c9f0",
            "value": 10610
          }
        },
        "929d4a0f0c6c4bdeb59126f843192528": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4684b02d4e94be1bdbe6371037a4263",
            "placeholder": "​",
            "style": "IPY_MODEL_368cb94574034d7eb103eadccca12317",
            "value": " 612/612 [00:00&lt;00:00, 48.2kB/s]"
          }
        },
        "93fdc5d52a984575ac0d1664fd1d9946": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8530af9fe3949c2bcf88469fed1e134",
            "placeholder": "​",
            "style": "IPY_MODEL_616a073868a747e3b2f88989327988c1",
            "value": " 112/112 [00:00&lt;00:00, 8.58kB/s]"
          }
        },
        "976332ba14d14f58b4f31666e8b96347": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e540adcf581f41d291ca46b70c769ccb",
            "placeholder": "​",
            "style": "IPY_MODEL_716c56f60df74258882a887eb697a1f3",
            "value": "Downloading (…)e9125/tokenizer.json: 100%"
          }
        },
        "97c4905b4051421cb529e7c66c25dda5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99efae8af15045aca20f7ce9c5d851d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f8a9f535eab4099a12ca07c74111d3b",
            "max": 13156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_753a4a798e5b4a43be17aeec44dc5b55",
            "value": 13156
          }
        },
        "9e3c0eb680d542fcb5cfc4f39f56d97d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aeeb32f61e274a56a9df758dd362510d",
            "placeholder": "​",
            "style": "IPY_MODEL_e5a8aa0d571a4eca8baa96dbe8592274",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 480kB/s]"
          }
        },
        "9e3cab98d3fc4fefaebf83b2800075ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a141b4c443ec46428460e6d60ad663c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1aaf00878f640cea7c8cbe687f1b469": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2ed4b9c73cb4427a1c6907e24fe5ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3bfbe26fe094e97a03fae13d52042c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a48e6d4a9a8343608fb4d054e6daf86f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a60f476c9a074d91a884e413a9cc498c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3e2b794f087466e92a4a2fc7049d4f3",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa4359de6b7a46bc8e9e2a24c11f33ff",
            "value": 53
          }
        },
        "aa4359de6b7a46bc8e9e2a24c11f33ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac499ff5fbd345168575e885b8e02b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b421ddb8b58b4a7c989c15d7a120415f",
              "IPY_MODEL_c601a96874ab4768a361a525ab414692",
              "IPY_MODEL_852d084fe309498c8b71aec76ff1ba5f"
            ],
            "layout": "IPY_MODEL_d582e4563c444a4f846ef843b42dc622"
          }
        },
        "ad46b1363b194f9db6dba17459c854ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeeb32f61e274a56a9df758dd362510d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afcf44bf2da84ea28d421156fe07cb50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50a3618f978c492abdbe7f272929b9b3",
            "placeholder": "​",
            "style": "IPY_MODEL_d498b38ef1c84eb4b254237a17a32e02",
            "value": " 1.18k/1.18k [00:00&lt;00:00, 70.4kB/s]"
          }
        },
        "b190ea7550a3493fa6c65bbe5335bc9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b270b44656344ea0aa868fd0d57ec166": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2f84621f11843ce87e8faccdf23a0ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b421ddb8b58b4a7c989c15d7a120415f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97c4905b4051421cb529e7c66c25dda5",
            "placeholder": "​",
            "style": "IPY_MODEL_29eeecc11a33409eb261c73b9eadee7c",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "b4684b02d4e94be1bdbe6371037a4263": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b641867c71d54cff80509af127dd0245": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8aba4e3bb3a4187938aa91b67d6879c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1319f19dfa3d4a70b47184bb23278dcc",
            "placeholder": "​",
            "style": "IPY_MODEL_6e858e5d0cd84ef8b168427f421d1943",
            "value": " 350/350 [00:00&lt;00:00, 14.7kB/s]"
          }
        },
        "b91d53982536420e833279e97cfc1d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_976332ba14d14f58b4f31666e8b96347",
              "IPY_MODEL_66e6f65cb7a44eaba8eceb188b7c9410",
              "IPY_MODEL_85e5ec1a3c9947f3b19228b615ca1bee"
            ],
            "layout": "IPY_MODEL_f6beb6e1880048f0a63a5f7e233940e8"
          }
        },
        "b9e6df11aa0d40ec9c04f0b92686acee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba45247509d043fbae44e968f48fd470": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc510462c1834bac89a0aa49078a1892": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd8a823d3edc4feeadb15bc9ee64087a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4aeca1137dfe475db13db385564dcdb7",
              "IPY_MODEL_a60f476c9a074d91a884e413a9cc498c",
              "IPY_MODEL_cccd192ee6ff4862a939f8c5494895f0"
            ],
            "layout": "IPY_MODEL_66dee458b9d345a5a6d054e2ab689b65"
          }
        },
        "be0298c1928c41e891fbcd65d5d77815": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be08516923a34b52b8e56f85ba35a628": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9fcfd32515e4f969de3fc0e38383448",
            "placeholder": "​",
            "style": "IPY_MODEL_3e29f9a280a44119a866cee8cb7517da",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "c04fb076ff744a278fa1c3f304e85067": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c252ae8aa250469b8726ad95e71ef14a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c263b664eccd4cb1ba95440804412dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3dc24725af24d8d9c933818639e23c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43bf2f5a97dc4540a9fdc54275e897cb",
            "placeholder": "​",
            "style": "IPY_MODEL_42ff97b7428841909f6f53eb073ed960",
            "value": "Downloading (…)7e55de9125/vocab.txt: 100%"
          }
        },
        "c47129ec7c1b461195ab18d64d602c9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eafdd315fca8499ab362a17ebc577a58",
            "placeholder": "​",
            "style": "IPY_MODEL_c252ae8aa250469b8726ad95e71ef14a",
            "value": " 116/116 [00:00&lt;00:00, 4.47kB/s]"
          }
        },
        "c601a96874ab4768a361a525ab414692": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3923e9d36cc449dda0c8766e729bb0a7",
            "max": 90888945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d30095c0dfa2496e807f3af1829ca3ad",
            "value": 90888945
          }
        },
        "c60808fcbf5b45c2a4ade36daa4a7669": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59d490914e874f729ca0dfbabb92cd71",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1aaf00878f640cea7c8cbe687f1b469",
            "value": 116
          }
        },
        "c7407efac95b4245a4e671ca441559bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c93e39c69cd34e7e9f66b2d3e9c66f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cccd192ee6ff4862a939f8c5494895f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5523296b4ac4445489b036602baf73c8",
            "placeholder": "​",
            "style": "IPY_MODEL_c263b664eccd4cb1ba95440804412dd9",
            "value": " 53.0/53.0 [00:00&lt;00:00, 3.46kB/s]"
          }
        },
        "d30095c0dfa2496e807f3af1829ca3ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3e2b794f087466e92a4a2fc7049d4f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d498b38ef1c84eb4b254237a17a32e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d582e4563c444a4f846ef843b42dc622": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d730eb0dae4643ad9ad0d7ff2681d21b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d79d7db8da4a441ba2e5e0d02c00ffad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd31b40118404dd08b93ecef206d940e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd4c45b892a54e7180d5d320208a1246": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df6476c48ce542f38c257a545bccfdc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df9945cebb3043eb83681bdb7f4c17c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0746f0508774f499334cbb30f346dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd4c45b892a54e7180d5d320208a1246",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a141b4c443ec46428460e6d60ad663c4",
            "value": 349
          }
        },
        "e24c5c58df074edaa1083602cb6a60b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83f1fef632464a8f81126ebca737721c",
              "IPY_MODEL_99efae8af15045aca20f7ce9c5d851d9",
              "IPY_MODEL_ecd9eaf92ee4427c83fda67bc43d9838"
            ],
            "layout": "IPY_MODEL_1a4786e2f5f644af91ab2ea7b501ffdb"
          }
        },
        "e26b2c5001524659a6c72ccfd89ce89a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_421102b5f5a64a95bd006eff364033b3",
            "placeholder": "​",
            "style": "IPY_MODEL_b641867c71d54cff80509af127dd0245",
            "value": "Downloading (…)125/data_config.json: 100%"
          }
        },
        "e41e4020a2704575a869f655345d2573": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5408791f01d4ef78feb06bc52442045": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e540adcf581f41d291ca46b70c769ccb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5a8aa0d571a4eca8baa96dbe8592274": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9fcfd32515e4f969de3fc0e38383448": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eafdd315fca8499ab362a17ebc577a58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb097afedab449eeb39562b2e1f106a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0602da154779406cb10b88543b34004c",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e3cab98d3fc4fefaebf83b2800075ef",
            "value": 231508
          }
        },
        "eb0bc34d326346f2828308197ae8bce1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb83616403a44f0eaf11177d8c6335a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec1811502c104eb3aeae86dba6eb0485": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c04fb076ff744a278fa1c3f304e85067",
            "placeholder": "​",
            "style": "IPY_MODEL_c93e39c69cd34e7e9f66b2d3e9c66f12",
            "value": " 232k/232k [00:00&lt;00:00, 14.6MB/s]"
          }
        },
        "ecd9eaf92ee4427c83fda67bc43d9838": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ac7c22f3c594b6ca0c5f84c713ba050",
            "placeholder": "​",
            "style": "IPY_MODEL_bc510462c1834bac89a0aa49078a1892",
            "value": " 13.2k/13.2k [00:00&lt;00:00, 716kB/s]"
          }
        },
        "ef0d7338c45a4214be597d4b47f8ac68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2988b40fb93a4ce69081aa19ad9e9724",
              "IPY_MODEL_c60808fcbf5b45c2a4ade36daa4a7669",
              "IPY_MODEL_c47129ec7c1b461195ab18d64d602c9b"
            ],
            "layout": "IPY_MODEL_1453633cccf243cd9f9e84f519d4ca05"
          }
        },
        "efe1a4b169f14305a9b84743ab90b826": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f612c25637144ccabe08f16ff27d6501": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2cb1f14a3709485f9eb1dcc0dabcad0e",
              "IPY_MODEL_e0746f0508774f499334cbb30f346dfb",
              "IPY_MODEL_5903908fc8124652a321b6ea4253a0e6"
            ],
            "layout": "IPY_MODEL_68cbe6529ffb4fcb9ad03d1c3d998883"
          }
        },
        "f66bdf6112dd4810901ba830d37a39d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12bd483163b34852bc1e40490601800a",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ba86f9a1aa346888e65e9dbf8029fad",
            "value": 612
          }
        },
        "f6a7a222991147f598a1f2d725da96cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6beb6e1880048f0a63a5f7e233940e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8530af9fe3949c2bcf88469fed1e134": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
